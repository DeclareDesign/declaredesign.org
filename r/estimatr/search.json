[{"path":[]},{"path":"https://declaredesign.org/r/estimatr/CONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Contributor Covenant Code of Conduct","text":"interest fostering open welcoming environment, contributors maintainers pledge making participation project community harassment-free experience everyone, regardless age, body size, disability, ethnicity, gender identity expression, level experience, nationality, personal appearance, race, religion, sexual identity orientation.","code":""},{"path":"https://declaredesign.org/r/estimatr/CONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Contributor Covenant Code of Conduct","text":"Examples behavior contributes creating positive environment include: Using welcoming inclusive language respectful differing viewpoints experiences Gracefully accepting constructive criticism Focusing best community Showing empathy towards community members Examples unacceptable behavior participants include: use sexualized language imagery unwelcome sexual attention advances Trolling, insulting/derogatory comments, personal political attacks Public private harassment Publishing others’ private information, physical electronic address, without explicit permission conduct reasonably considered inappropriate professional setting","code":""},{"path":"https://declaredesign.org/r/estimatr/CONDUCT.html","id":"our-responsibilities","dir":"","previous_headings":"","what":"Our Responsibilities","title":"Contributor Covenant Code of Conduct","text":"Project maintainers responsible clarifying standards acceptable behavior expected take appropriate fair corrective action response instances unacceptable behavior. Project maintainers right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct, ban temporarily permanently contributor behaviors deem inappropriate, threatening, offensive, harmful.","code":""},{"path":"https://declaredesign.org/r/estimatr/CONDUCT.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Contributor Covenant Code of Conduct","text":"Code Conduct applies within project spaces public spaces individual representing project community. Examples representing project community include using official project e-mail address, posting via official social media account, acting appointed representative online offline event. Representation project may defined clarified project maintainers.","code":""},{"path":"https://declaredesign.org/r/estimatr/CONDUCT.html","id":"enforcement","dir":"","previous_headings":"","what":"Enforcement","title":"Contributor Covenant Code of Conduct","text":"Instances abusive, harassing, otherwise unacceptable behavior may reported contacting project team abuse@declaredesign.org. complaints reviewed investigated result response deemed necessary appropriate circumstances. project team obligated maintain confidentiality regard reporter incident. details specific enforcement policies may posted separately. Project maintainers follow enforce Code Conduct good faith may face temporary permanent repercussions determined members project’s leadership.","code":""},{"path":"https://declaredesign.org/r/estimatr/CONDUCT.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributor Covenant Code of Conduct","text":"Code Conduct adapted Contributor Covenant, version 1.4, available http://contributor-covenant.org/version/1/4","code":""},{"path":"https://declaredesign.org/r/estimatr/articles/absorbing-fixed-effects.html","id":"speed-gains","dir":"Articles","previous_headings":"","what":"Speed gains","title":"Absorbing Fixed Effects with estimatr","text":"general, speed gains greatest number groups/fixed effects large relative number observations. Imagine 300 matched-pairs experiment. Speed gains considerably greater HC1 standard errors. need get hat matrix HC2, HC3, CR2 standard errors, requires inverting large matrix dummies previously avoided . HC0, HC1, CR0, CRstata standard errors require inversion.","code":"# Load packages for comparison library(microbenchmark) library(sandwich) library(lmtest)  # Create matched-pairs dataset using fabricatr set.seed(40) library(fabricatr) dat <- fabricate(   blocks = add_level(N = 300),   indiv = add_level(N = 2, z = sample(0:1), y = rnorm(N) + z) ) head(dat) ##   blocks indiv z          y ## 1    001   001 1  1.4961828 ## 2    001   002 0 -0.8595843 ## 3    002   003 1  0.1709400 ## 4    002   004 0 -0.3215731 ## 5    003   005 1 -0.3037704 ## 6    003   006 0 -1.4214866 # With HC2 microbenchmark(   `base + sandwich` = {     lo <- lm(y ~ z + factor(blocks), dat)     coeftest(lo, vcov = vcovHC(lo, type = \"HC2\"))   },   `lm_robust` = lm_robust(y ~ z + factor(blocks), dat),   `lm_robust + fes` = lm_robust(y ~ z, data = dat, fixed_effects = ~ blocks),   times = 50 ) ## Unit: milliseconds ##             expr       min        lq      mean    median        uq      max ##  base + sandwich 151.65815 156.52384 173.04432 160.03446 166.71161 416.8094 ##        lm_robust  53.82148  56.98307  65.99278  59.08743  63.26716 208.3113 ##  lm_robust + fes  31.52724  33.29191  37.97890  34.53975  36.55918 142.7598 ##  neval cld ##     50 a   ##     50  b  ##     50   c # With HC1 microbenchmark(   `base + sandwich` = {     lo <- lm(y ~ z + factor(blocks), dat)     coeftest(lo, vcov = vcovHC(lo, type = \"HC1\"))   },   `lm_robust` = lm_robust(     y ~ z + factor(blocks),     dat,     se_type = \"HC1\"   ),   `lm_robust + fes` = lm_robust(     y ~ z,      data = dat,     fixed_effects = ~ blocks,     se_type = \"HC1\"   ),   times = 50 ) ## Unit: milliseconds ##             expr        min         lq       mean     median         uq ##  base + sandwich 153.631140 162.151743 186.772826 170.193676 192.477455 ##        lm_robust  44.429484  49.419339  60.166683  52.962421  57.595097 ##  lm_robust + fes   5.347328   6.083373   8.123566   6.584969   7.438765 ##       max neval cld ##  417.0696    50 a   ##  189.5660    50  b  ##   49.4495    50   c"},{"path":"https://declaredesign.org/r/estimatr/articles/benchmarking-estimatr.html","id":"linear-regression","dir":"Articles","previous_headings":"","what":"Linear regression","title":"Benchmarking estimatr","text":"test speed estimating coefficients, standard errors, inference four different datasets (500 5000 observations; 5 50 covariates) across several different specifications. preview results comparing lm_robust() base R fitting coefficients commonly used package robust standard errors, sandwich package. two largest datasets, method almost always faster worst base R, classical standard errors. comes biggest gains, using lm_robust() get HC2 Stata-like cluster-robust standard errors roughly halve waiting time. want CR2 standard errors, lm_robust() can reduce run time factor 10!","code":""},{"path":[]},{"path":"https://declaredesign.org/r/estimatr/articles/benchmarking-estimatr.html","id":"code-that-generated-these-data","dir":"Articles","previous_headings":"","what":"Code that generated these data","title":"Benchmarking estimatr","text":"see exact comparisons, see . First, can look classical standard errors case. computations summary.lm , bit overhead. following table median time milliseconds across 50 runs estimator different data sets. However, real speed gains come robust standard errors. Let’s compare lm_robust getting “HC2” standard errors inference using coeftest sandwich packages. Stata’s clustered standard errors using tapply sandwich? original authors came generalized version CR2 errors accompanying Satterthwaite-like corrected degrees freedom package, clubSandwich, provides estimators many methods. show much faster implementation simple linear regression. instrumental variables?","code":"library(estimatr) library(microbenchmark) # Create some data sets of different sizes for testing below set.seed(42) data_size <- expand.grid(list(ns = c(500, 5000), ps = c(5, 50))) data_list <- lapply(   1:nrow(data_size),    function(i) {     n <- data_size$ns[i]     p <- data_size$ps[i]     y <- rnorm(n)     X <- matrix(rnorm(n*p), n, p)     return(data.frame(y, X))   } ) test_base <- lapply(data_list, function(dat) {   mbo <- summary(microbenchmark(     'lm_robust' = lm_robust(y ~ ., data = dat, se_type = \"classical\"),     'base' = summary(lm(y ~ ., data = dat)),     times = 200L   ),   unit = \"ms\")   return(mbo[, c(\"expr\", \"median\")]) }) library(sandwich) library(lmtest)  test_rob <- lapply(data_list, function(dat) {   mbo <- summary(microbenchmark(     'lm_robust' = lm_robust(y ~ ., data = dat, se_type = \"HC2\"),     'lm + coeftest + sandwich' = {       lmo <- lm(y ~ ., data = dat)       coeftest(lmo, vcov = vcovHC(lmo, type = \"HC2\"))     },     times = 200L   ),   unit = \"ms\")   return(mbo[, c(\"expr\", \"median\")]) }) # Commonly used function attributed mostly to M. Arai replicating Stata  # clustered SEs in R using sandwich and lmtest packages cluster_robust_se <- function(model, cluster){   M <- length(unique(cluster))   N <- length(cluster)   K <- model$rank   dfc <- (M/(M - 1)) * ((N - 1)/(N - K))   uj <- apply(estfun(model), 2, function(x) tapply(x, cluster, sum));   rcse.cov <- dfc * sandwich(model, meat = crossprod(uj)/N)   rcse.se <- coeftest(model, rcse.cov)   return(list(rcse.cov, rcse.se)) }  test_cl <- lapply(data_list, function(dat) {   cluster <- sample(nrow(dat)/5, size = nrow(dat), replace = TRUE)   mbo <- summary(microbenchmark(     'lm_robust' = lm_robust(       y ~ .,        data = dat,        clusters = cluster,        se_type = \"stata\"     ),     'lm + coeftest + sandwich' = {       lmo <- lm(y ~ ., data = dat)       cluster_robust_se(lmo, cluster)     },     times = 200L   ),   unit = \"ms\")   return(mbo[, c(\"expr\", \"median\")]) }) library(clubSandwich)  test_cr2 <- lapply(data_list, function(dat) {   cluster <- sample(nrow(dat)/5, size = nrow(dat), replace = TRUE)   mbo <- summary(microbenchmark(     'lm_robust' = lm_robust(       y ~ .,        data = dat,       clusters = cluster,        se_type = \"CR2\"     ),     'lm + clubSandwich' = {       lmo <- lm(y ~ ., data = dat)       coef_test(lmo, vcov = vcovCR(lmo, cluster = cluster, type = \"CR2\"))     },     times = 50L   ),   unit = \"ms\")   return(mbo[, c(\"expr\", \"median\")]) })  knitr::kable(create_tab(test_cr2), col.names = col_names) library(AER) library(ivpack) library(clubSandwich)  test_iv <- lapply(data_list, function(dat) {   form <- as.formula(paste0(     \"y ~ \",     paste(names(dat)[substr(names(dat), 1, 1) == \"X\"], collapse = \" + \"),     \" | \",     paste(names(dat)[substr(names(dat), 1, 1) == \"Z\"], collapse = \" + \")   ))   mbo <- summary(microbenchmark(     'iv_robust' = iv_robust(       form,        data = dat,       se_type = \"classical\"     ),     'AER::ivreg' = {       ivo <- summary(ivreg(form, data = dat))     },     times = 200L   ),   unit = \"ms\")   return(mbo[, c(\"expr\", \"median\")]) })  knitr::kable(create_tab(test_iv), col.names = col_names) test_iv_rob <- lapply(data_list, function(dat) {   form <- as.formula(paste0(     \"y ~ \",     paste(names(dat)[substr(names(dat), 1, 1) == \"X\"], collapse = \" + \"),     \" | \",     paste(names(dat)[substr(names(dat), 1, 1) == \"Z\"], collapse = \" + \")   ))   mbo <- summary(microbenchmark(     'iv_robust' = iv_robust(       form,        data = dat,       se_type = \"HC0\"     ),     'AER::ivreg + ivpack::robust.se' = {       ivo <- robust.se(ivreg(form, data = dat))     },     times = 200L   ),   unit = \"ms\")   return(mbo[, c(\"expr\", \"median\")]) })  knitr::kable(create_tab(test_iv_rob), col.names = col_names) test_iv_cl <- lapply(data_list, function(dat) {   cluster <- sample(nrow(dat)/5, size = nrow(dat), replace = TRUE)   form <- as.formula(paste0(     \"y ~ \",     paste(names(dat)[substr(names(dat), 1, 1) == \"X\"], collapse = \" + \"),     \" | \",     paste(names(dat)[substr(names(dat), 1, 1) == \"Z\"], collapse = \" + \")   ))   mbo <- summary(microbenchmark(     'iv_robust' = iv_robust(       form,        data = dat,       clusters = cluster,       se_type = \"CR2\"     ),     'AER::ivreg + clubSandwich' = {       ivo <- clubSandwich::coef_test(ivreg(form, data = dat), cluster = cluster, vcov = \"CR2\")     },     times = 50L   ),   unit = \"ms\")   return(mbo[, c(\"expr\", \"median\")]) })  knitr::kable(create_tab(test_iv_cl), col.names = col_names) sessionInfo() #> R version 3.5.0 (2018-04-23) #> Platform: x86_64-apple-darwin15.6.0 (64-bit) #> Running under: macOS High Sierra 10.13.3 #>  #> Matrix products: default #> BLAS: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRblas.0.dylib #> LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib #>  #> locale: #> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 #>  #> attached base packages: #> [1] stats     graphics  grDevices utils     datasets  methods   base      #>  #> other attached packages: #>  [1] clubSandwich_0.3.2      ivpack_1.2              #>  [3] AER_1.2-5               survival_2.41-3         #>  [5] sandwich_2.4-0          lmtest_0.9-36           #>  [7] zoo_1.8-1               car_3.0-0               #>  [9] carData_3.0-1           RcppArmadillo_0.8.500.0 #> [11] RcppEigen_0.3.3.4.0     microbenchmark_1.4-4    #> [13] estimatr_0.8.0          #>  #> loaded via a namespace (and not attached): #>  [1] zip_1.0.0         Rcpp_0.12.17      highr_0.6         #>  [4] compiler_3.5.0    pillar_1.2.3      cellranger_1.1.0  #>  [7] forcats_0.3.0     tools_3.5.0       digest_0.6.15     #> [10] evaluate_0.10.1   tibble_1.4.2      lattice_0.20-35   #> [13] texreg_1.36.23    rlang_0.2.1       openxlsx_4.1.0    #> [16] Matrix_1.2-14     curl_3.2          yaml_2.1.19       #> [19] haven_1.1.1       rio_0.5.10        stringr_1.3.1     #> [22] knitr_1.20        rprojroot_1.3-2   grid_3.5.0        #> [25] data.table_1.11.4 readxl_1.1.0      foreign_0.8-70    #> [28] rmarkdown_1.9     Formula_1.2-3     magrittr_1.5      #> [31] codetools_0.2-15  splines_3.5.0     backports_1.1.2   #> [34] htmltools_0.3.6   abind_1.4-5       stringi_1.2.2"},{"path":"https://declaredesign.org/r/estimatr/articles/emmeans-examples.html","id":"a-factorial-experiment","dir":"Articles","previous_headings":"","what":"A factorial experiment","title":"Examples with emmeans","text":"warpbreaks dataset provided base R results two-factor experiment. start fitting model Typical use emmeans() obtain predictions, marginal means thereof, via formula form ~ primary.variables | .variables: results may plotted side--side intervals interaction-style plot: particular example response transformation. transformation detected may back-transform original scale: may comparisons contrasts: Note log transformations, possible back-transform comparisons, become ratios. transformations, back-transforming possible.","code":"library(estimatr)  warp.rlm <- lm_robust(log(breaks) ~ wool * tension, data = warpbreaks) library(emmeans)  emm <- emmeans(warp.rlm, ~ tension | wool) class(emm) str(emm) emm plot(emm) emmip(emm, wool ~ tension, CIs = TRUE) confint(emm, type = \"response\") pairs(emm) # pairwise comparisons contrast(emm, \"trt.vs.ctrl\", ref = \"L\", type = \"response\", adjust = \"mvt\")"},{"path":"https://declaredesign.org/r/estimatr/articles/emmeans-examples.html","id":"rank-deficient-models","dir":"Articles","previous_headings":"","what":"Rank-deficient models","title":"Examples with emmeans","text":"Let’s create variation example one cell omitted: Note empty cell detected flagged non-estimable. additional explanation . EMMs based reference grid, defined grid created possible combinations factor levels, together mean numerical predictor. reference grid (rgi) also \"emmGrid\" object just like previous emm. grid available data frame via grid member, can verify results match predict function model: one exception empty cell. leave user exercise demonstrate use different contrasts fitting warpi.rlm, predictions except empty cell.","code":"warpi.rlm <- update(warp.rlm, subset = -(37:48)) (rgi <- ref_grid(warpi.rlm)) summary(rgi) predict(warpi.rlm, newdata = rgi@grid, se.fit = TRUE)"},{"path":"https://declaredesign.org/r/estimatr/articles/emmeans-examples.html","id":"multivariate-models","dir":"Articles","previous_headings":"","what":"Multivariate models","title":"Examples with emmeans","text":"multivariate response, treated another factor crossed factors model. illustrate, consider dataset MOats, provided emmeans: default, pseudo-factor named rep.meas, can change like: illustrates additional feature emmeans can put contrast method left side formula.","code":"MOats.rlm <- lm_robust(yield ~ Block + Variety, data = MOats) ref_grid(MOats.rlm) emmeans(MOats.rlm, pairwise ~ nitro, mult.name = \"nitro\")"},{"path":"https://declaredesign.org/r/estimatr/articles/emmeans-examples.html","id":"afterword","dir":"Articles","previous_headings":"","what":"Afterword","title":"Examples with emmeans","text":"numerous capabilities emmeans illustrated . See package’s help files vignettes. Using vignette(\"basics\", \"emmeans\") good starting point.","code":""},{"path":"https://declaredesign.org/r/estimatr/articles/estimatr-in-the-tidyverse.html","id":"getting-tidy","dir":"Articles","previous_headings":"","what":"Getting tidy","title":"estimatr in the Tidyverse","text":"first step tidyverse turning model output data can manipulate. tidy function converts lm_robust object data.frame.","code":"library(estimatr) fit <- lm_robust(Fertility ~ Agriculture + Catholic, data = swiss) tidy(fit) ##          term   estimate  std.error statistic      p.value    conf.low ## 1 (Intercept) 59.8639237 5.47384281 10.936361 3.934173e-14 48.83211840 ## 2 Agriculture  0.1095281 0.10305115  1.062852 2.936478e-01 -0.09815783 ## 3    Catholic  0.1149621 0.03854836  2.982283 4.651169e-03  0.03727301 ##    conf.high df   outcome ## 1 70.8957290 44 Fertility ## 2  0.3172141 44 Fertility ## 3  0.1926512 44 Fertility"},{"path":"https://declaredesign.org/r/estimatr/articles/estimatr-in-the-tidyverse.html","id":"data-manipulation-with-dplyr","dir":"Articles","previous_headings":"","what":"Data manipulation with dplyr","title":"estimatr in the Tidyverse","text":"regression fit data.frame, can use dplyr “verbs” data manipulation, like mutate,filter, select, summarise, group_by, arrange ().","code":"library(tidyverse)  # lm_robust and filter fit %>% tidy %>% filter(term == \"Agriculture\") ##          term  estimate std.error statistic   p.value    conf.low conf.high df ## 1 Agriculture 0.1095281 0.1030511  1.062852 0.2936478 -0.09815783 0.3172141 44 ##     outcome ## 1 Fertility # lm_robust and select fit %>% tidy %>% select(term, estimate, std.error) ##          term   estimate  std.error ## 1 (Intercept) 59.8639237 5.47384281 ## 2 Agriculture  0.1095281 0.10305115 ## 3    Catholic  0.1149621 0.03854836 # lm_robust and mutate fit %>% tidy %>% mutate(t_stat = estimate/ std.error,                         significant = p.value <= 0.05) ##          term   estimate  std.error statistic      p.value    conf.low ## 1 (Intercept) 59.8639237 5.47384281 10.936361 3.934173e-14 48.83211840 ## 2 Agriculture  0.1095281 0.10305115  1.062852 2.936478e-01 -0.09815783 ## 3    Catholic  0.1149621 0.03854836  2.982283 4.651169e-03  0.03727301 ##    conf.high df   outcome    t_stat significant ## 1 70.8957290 44 Fertility 10.936361        TRUE ## 2  0.3172141 44 Fertility  1.062852       FALSE ## 3  0.1926512 44 Fertility  2.982283        TRUE"},{"path":"https://declaredesign.org/r/estimatr/articles/estimatr-in-the-tidyverse.html","id":"data-visualization-with-ggplot2","dir":"Articles","previous_headings":"","what":"Data visualization with ggplot2","title":"estimatr in the Tidyverse","text":"ggplot2 offers number data visualization tools compatible estimatr Make coefficient plot:  Put CIs based robust variance estimates (rather “classical” variance estimates) geom_smooth stat_smooth functions.  Note functional form can include polynomials. instance, model \\(Fertility \\sim Agriculture + Agriculture^2 + Agriculture^3\\), can model following way:","code":"fit %>%    tidy %>%    filter(term != \"(Intercept)\") %>%   ggplot(aes(y = term, x = estimate)) +    geom_vline(xintercept = 0, linetype = 2) +    geom_point() +    geom_errorbarh(aes(xmin = conf.low, xmax = conf.high, height = 0.1)) +    theme_bw() library(ggplot2) ggplot(swiss, aes(x = Agriculture, y = Fertility)) +   geom_point() +   geom_smooth(method = \"lm_robust\") +   theme_bw() library(ggplot2) ggplot(swiss, aes(x = Agriculture, y = Fertility)) +   geom_point() +   geom_smooth(method = \"lm_robust\",               formula = y ~ poly(x, 3, raw = TRUE)) +   theme_bw()"},{"path":"https://declaredesign.org/r/estimatr/articles/estimatr-in-the-tidyverse.html","id":"bootstrap-using-rsample","dir":"Articles","previous_headings":"","what":"Bootstrap using rsample","title":"estimatr in the Tidyverse","text":"rsample pacakage provides tools bootstrapping: boot_out data.frame contains estimates boostrapped sample. can use dplyr functions summarize bootstraps, tidyr functions reshape estimates, GGally::ggpairs visualize .","code":"library(rsample)  boot_out <-   bootstraps(data = swiss, 500)$splits %>%   map(~ lm_robust(Fertility ~ Catholic + Agriculture, data = analysis(.))) %>%    map(tidy) %>%   bind_rows(.id = \"bootstrap_replicate\") kable(head(boot_out)) boot_out %>%   group_by(term) %>%   summarise(boot_se = sd(estimate)) ## # A tibble: 3 × 2 ##   term        boot_se ##   <chr>         <dbl> ## 1 (Intercept)  5.42   ## 2 Agriculture  0.102  ## 3 Catholic     0.0374 # To visualize the sampling distribution  library(GGally) boot_out %>%    select(bootstrap_replicate, term, estimate) %>%   spread(key = term, value = estimate) %>%   select(-bootstrap_replicate) %>%   ggpairs(lower = list(continuous = wrap(\"points\", alpha = 0.1))) +   theme_bw()"},{"path":"https://declaredesign.org/r/estimatr/articles/estimatr-in-the-tidyverse.html","id":"multiple-models-using-purrr","dir":"Articles","previous_headings":"","what":"Multiple models using purrr","title":"estimatr in the Tidyverse","text":"purrr provides tools perform operation every element vector. instance, may want estimate model different subsets data. can use map function . Alternatively, might want regress different dependent variables independent variable. map can used alongwith estimatr functions purpose well. Using ggplot2, can make coefficient plot:","code":"library(purrr)  # Running the same model for highly educated and less educated cantons/districts  two_subsets <-    swiss %>%   mutate(HighlyEducated = as.numeric(Education > 8)) %>%   split(.$HighlyEducated) %>%   map( ~ lm_robust(Fertility ~ Catholic, data = .)) %>%   map(tidy) %>%   bind_rows(.id = \"HighlyEducated\")  kable(two_subsets, digits =2) three_outcomes <-   c(\"Fertility\", \"Education\", \"Agriculture\") %>%   map(~ formula(paste0(., \" ~ Catholic\"))) %>%   map(~ lm_robust(., data = swiss)) %>%   map_df(tidy)  kable(three_outcomes, digits =2) three_outcomes %>%   filter(term == \"Catholic\") %>%   ggplot(aes(x = estimate, y = outcome)) +   geom_vline(xintercept = 0, linetype = 2) +   geom_point() +    geom_errorbarh(aes(xmin = conf.low, xmax = conf.high, height = 0.1)) +    ggtitle(\"Slopes with respect to `Catholic`\") +    theme_bw()"},{"path":"https://declaredesign.org/r/estimatr/articles/estimatr-in-the-tidyverse.html","id":"concluding-thoughts","dir":"Articles","previous_headings":"","what":"Concluding thoughts","title":"estimatr in the Tidyverse","text":"Using estimatr functions tidyverse easy model outputs turned data.frames. accomplish tidy function. , many summary visualization possibilities open . Happy tidying!","code":""},{"path":"https://declaredesign.org/r/estimatr/articles/getting-started.html","id":"estimators","dir":"Articles","previous_headings":"","what":"Estimators","title":"Getting started using estimatr","text":"current estimators provide : lm_robust - fitting linear models heteroskedasticity/cluster-robust standard errors lm_lin - wrapper lm_robust() simplify interacting centered pre-treatment covariates treatment variable iv_robust - two stage least squares estimation instrumental variables regression difference_in_means - estimating differences means appropriate standard errors unit-randomized, cluster-randomized, block-randomized, matched-pair randomized, matched-pair clustered designs horvitz_thompson - estimating average treatment effects taking consideration treatment probabilities sampling probabilities simple cluster randomized designs first create sample data demonstrate use estimators.","code":"library(estimatr)  # Example dataset to be used throughout built using fabricatr and randomizr set.seed(42) library(fabricatr) library(randomizr) dat <- fabricate(   N = 100,                        # sample size   x = runif(N, 0, 1),             # pre-treatment covariate   y0 = rnorm(N, mean = x),        # control potential outcome   y1 = y0 + 0.35,                 # treatment potential outcome   z = complete_ra(N),             # complete random assignment to treatment   y = ifelse(z, y1, y0),          # observed outcome    # We will also consider clustered data   clust = sample(rep(letters[1:20], each = 5)),   z_clust = cluster_ra(clust),   y_clust = ifelse(z_clust, y1, y0) )  head(dat)"},{"path":"https://declaredesign.org/r/estimatr/articles/getting-started.html","id":"lm_robust","dir":"Articles","previous_headings":"Estimators","what":"lm_robust","title":"Getting started using estimatr","text":"estimatr package provides lm_robust() quickly fit linear models common variance estimators degrees freedom corrections used social science. can easily estimate heteroskedastic standard errors, clustered standard errors, classical standard errors. Usage largely mimics lm(), although defaults using Eicker-Huber-White robust standard errors, specifically “HC2” standard errors. exact specifications used can found mathematical notes estimator can found reference page: lm_robust(). Users can also easily get output data.frame using tidy(). straightforward cluster-robust inference, passing name cluster variable clusters = argument. default variance estimator clusters dubbed ‘CR2’ analogous ‘HC2’ clustered case, utilizes recent advances proposed Pustejovsky Tipton (2018) correct hypotheses tests small samples work commonly specified fixed effects weights. Note lm_robust() quicker cluster variable factor! Researchers can also replicate Stata’s standard errors using se_type = argument without clusters: Furthermore, users can take advantage margins package get marginal effects, average marginal effects standard errors, . Similarly, prediction package author also provides suite software different kinds predictions. Users want regression output LaTeX HTML can use texreg package, extend output lm_robust() lm_lin() functions.","code":"lmout <- lm_robust(y ~ z + x, data = dat) summary(lmout) #>  #> Call: #> lm_robust(formula = y ~ z + x, data = dat) #>  #> Standard error type:  HC2  #>  #> Coefficients: #>             Estimate Std. Error t value Pr(>|t|) CI Lower CI Upper DF #> (Intercept)   -0.183      0.172   -1.07 2.89e-01   -0.524    0.158 97 #> z              0.206      0.185    1.11 2.70e-01   -0.163    0.574 97 #> x              1.439      0.287    5.01 2.40e-06    0.869    2.008 97 #>  #> Multiple R-squared:  0.192 , Adjusted R-squared:  0.176  #> F-statistic: 13.6 on 2 and 97 DF,  p-value: 6.05e-06 tidy(lmout) # Standard estimator with clustered assignment 'z_clust' lmout <- lm_robust(   y_clust ~ z_clust + x,   data = dat ) # With clustered standard errors lmout_cl <- lm_robust(   y_clust ~ z_clust + x,   data = dat,   clusters = clust ) tidy(lmout_cl) lmout_stata <- lm_robust(   y_clust ~ z_clust + x,   data = dat,   clusters = clust,   se_type = \"stata\" ) tidy(lmout_stata) library(margins)  lmout_int <- lm_robust(y ~ x * z, data = dat) mar_int <- margins(lmout_int, vce = \"delta\") summary(mar_int) #>  factor    AME     SE      z      p   lower  upper #>       x 1.4401 0.2886 4.9905 0.0000  0.8745 2.0057 #>       z 0.2056 0.1861 1.1048 0.2692 -0.1592 0.5704  library(prediction) prediction(lmout_int) #> Data frame with 100 predictions from #>  lm_robust(formula = y ~ x * z, data = dat) #> with average prediction: 0.6742 prediction(lmout_int, at = list(x = c(-0.5, 0.5))) #> Warning in check_values(data, at): A 'at' value for 'x' is outside observed #> data range (0.000238896580412984,0.988891728920862)! #> Data frame with 200 predictions from #>  lm_robust(formula = y ~ x * z, data = dat) #> with average predictions: #>     x       x #>  -0.5 -0.8006 #>   0.5  0.6395 library(texreg)  texreg(lmout)"},{"path":"https://declaredesign.org/r/estimatr/articles/getting-started.html","id":"lm_lin","dir":"Articles","previous_headings":"Estimators","what":"lm_lin","title":"Getting started using estimatr","text":"Adjusting pre-treatment covariates using regression estimate treatment effects common practice across scientific disciplines. However, Freedman (2008) demonstrated pre-treatment covariate adjustment biases estimates average treatment effects. response, Lin (2013) proposed alternative estimator reduce bias improve precision. Lin (2013) proposes centering pre-treatment covariates, interacting treatment variable, regressing outcome treatment, centered pre-treatment covariates, interaction terms. can require non-trivial amount data pre-processing. facilitate , provide wrapper processes data estimates model. dub estimator Lin estimator can accessed using lm_lin(). function wrapper lm_robust(), arguments work lm_robust() work . difference second argument covariates, one specifies right-sided formula pre-treatment covariates. example, can seen function reference page lm_lin formal notation can seen mathematical notes. output lm_lin() call can used methods lm_robust(), including margins package.","code":"lml_out <- lm_lin(   y ~ z,   covariates = ~ x,   data = dat ) tidy(lml_out)"},{"path":"https://declaredesign.org/r/estimatr/articles/getting-started.html","id":"iv_robust","dir":"Articles","previous_headings":"Estimators","what":"iv_robust","title":"Getting started using estimatr","text":"also implement two-stage least squares instrumental variables estimator. estimator provides simple syntax fast estimation standard errors (users can select set standard error estimators lm_robust()).","code":"# `x` is endogenous variable and `z` is the instrument iv_out <- iv_robust(y ~ x | z, data = dat) summary(iv_out) #>  #> Call: #> iv_robust(formula = y ~ x | z, data = dat) #>  #> Standard error type:  HC2  #>  #> Coefficients: #>             Estimate Std. Error t value Pr(>|t|) CI Lower CI Upper DF #> (Intercept)    -14.6        120  -0.122    0.903     -253      223 98 #> x               29.2        229   0.128    0.899     -425      483 98 #>  #> Multiple R-squared:  -67.1 , Adjusted R-squared:  -67.8  #> F-statistic: 0.0163 on 1 and 98 DF,  p-value: 0.899"},{"path":"https://declaredesign.org/r/estimatr/articles/getting-started.html","id":"difference_in_means","dir":"Articles","previous_headings":"Estimators","what":"difference_in_means","title":"Getting started using estimatr","text":"estimating differences means may seem straightforward, can become complicated designs blocks clusters. cases, estimators need average within-block effects estimates variance appropriately adjust features design. provide support unit-randomized, cluster-randomized, block-randomized, matched-pair randomized, matched-pair clustered designs. Usage similar usage regression functions. examples can seen function reference page, difference_in_means(), actual estimators used can found mathematical notes. can check design learned kind estimator used examining design output.","code":"# Simple version dim_out <- difference_in_means(   y ~ z,   data = dat ) tidy(dim_out) # Clustered version dim_out_cl <- difference_in_means(   y_clust ~ z_clust,   data = dat,   clusters = clust ) tidy(dim_out_cl) data(sleep) dim_mps <- difference_in_means(extra ~ group, data = sleep, blocks = ID) dim_mps$design #> [1] \"Matched-pair\""},{"path":"https://declaredesign.org/r/estimatr/articles/getting-started.html","id":"horvitz_thompson","dir":"Articles","previous_headings":"Estimators","what":"horvitz_thompson","title":"Getting started using estimatr","text":"Horvitz-Thompson estimators yield unbiased treatment effect estimates randomization known. particularly useful clusters different sizes randomized treatment treatment assignment complex dependencies across units probability treated. Horvitz-Thompson estimators require information probability unit treatment control, well joint probability unit treatment, control, opposite treatment conditions. estimator implement , horvitz_thompson() estimates treatment effects two-armed trials. easiest way specify design recover full set joint marginal probabilities declare randomization scheme using declare_ra() randomizr package. show examples . , technical details estimator can found references notes. can also easily estimate treatment effects cluster randomized experiment. Letting horvitz_thompson know design clustered means uses collapsed estimator variance, described Aronow Middleton (2013). can also build condition probability matrix (condition_prob_mat =) horvitz_thompson() needs declaration randomizr package—using declaration_to_conditional_pr_mat()—matrix permutations treatment vector—using permutations_to_conditional_pr_mat(). largely intended use experienced users. Note, one passes condition_prob_mat indicates clustering, specify clusters argument, collapsed estimator used.","code":"# Complete random assignment declaration crs_decl <- declare_ra(   N = nrow(dat),   prob = 0.5,   simple = FALSE )  ht_comp <- horvitz_thompson(   y ~ z,   data = dat,   ra_declaration = crs_decl ) tidy(ht_comp) # Clustered random assignment declaration crs_clust_decl <- declare_ra(   N = nrow(dat),   clusters = dat$clust,   prob = 0.5,   simple = FALSE )  ht_clust <- horvitz_thompson(   y_clust ~ z_clust,   data = dat,   ra_declaration = crs_clust_decl ) tidy(ht_clust) # arbitrary permutation matrix possible_treats <- cbind(   c(1, 1, 0, 1, 0, 0, 0, 1, 1, 0),   c(0, 1, 1, 0, 1, 1, 0, 1, 0, 1),   c(1, 0, 1, 1, 1, 1, 1, 0, 0, 0) ) arb_pr_mat <- permutations_to_condition_pr_mat(possible_treats)  # Simulating a column to be realized treatment dat <- data.frame(   z = possible_treats[, sample(ncol(possible_treats), size = 1)],   y = rnorm(nrow(possible_treats)) )  ht_arb <- horvitz_thompson(   y ~ z,   data = dat,   condition_pr_mat = arb_pr_mat ) tidy(ht_arb)"},{"path":"https://declaredesign.org/r/estimatr/articles/getting-started.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Getting started using estimatr","text":"Aronow, Peter M, Joel Middleton. 2013. “Class Unbiased Estimators Average Treatment Effect Randomized Experiments.” Journal Causal Inference 1 (1): 135–54. https://doi.org/10.1515/jci-2012-0009. Freedman, David . 2008. “Regression Adjustments Experiments Several Treatments.” Annals Applied Statistics, 176–96. https://doi.org/10.1214/07-AOAS143. Lin, Winston. 2013. “Agnostic Notes Regression Adjustments Experimental Data: Reexamining Freedman’s Critique.” Annals Applied Statistics 7 (1): 295–318. https://doi.org/10.1214/12-AOAS583. Pustejovsky, James E, Elizabeth Tipton. 2018. “Small-Sample Methods Cluster-Robust Variance Estimation Hypothesis Testing Fixed Effects Models.” Journal Business & Economic Statistics 36 (4). https://doi.org/10.1080/07350015.2016.1247004.","code":""},{"path":"https://declaredesign.org/r/estimatr/articles/mathematical-notes.html","id":"estimators","dir":"Articles","previous_headings":"","what":"Estimators","title":"Mathematical notes for estimatr","text":"current estimators provide : lm_robust - fitting linear models heteroskedasticity/cluster-robust standard errors lm_lin - wrapper lm_robust() simplify interacting centered pre-treatment covariates treatment variable iv_robust - two stage least squares estimation instrumental variables regression difference_in_means - estimating differences means appropriate standard errors unit-randomized, cluster-randomized, block-randomized, matched-pair randomized, matched-pair clustered designs horvitz_thompson - estimating average treatment effects taking consideration treatment probabilities sampling probabilities simple cluster randomized designs","code":""},{"path":"https://declaredesign.org/r/estimatr/articles/mathematical-notes.html","id":"lm_robust-notes","dir":"Articles","previous_headings":"Estimators","what":"lm_robust notes","title":"Mathematical notes for estimatr","text":"lm_robust method uses C++ library Eigen, via RcppEigen package, estimate coefficients, variance-covariance matrix, , cases, degrees freedom linear models. default estimators selected efficiency large samples low bias small samples well similarities design-based randomization estimators (Samii Aronow 2012). section outlines various kinds variance estimators one can employ within lm_robust.","code":""},{"path":"https://declaredesign.org/r/estimatr/articles/mathematical-notes.html","id":"coefficient-estimates","dir":"Articles","previous_headings":"Estimators > lm_robust notes","what":"Coefficient estimates","title":"Mathematical notes for estimatr","text":"\\[ \\widehat{\\beta} =(\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{X}^{\\top}\\mathbf{y} \\] algorithm solves least squares problem using rank-revealing column-pivoting QR factorization eliminates need invert \\((\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\) explicitly behaves much like default lm function R. However, \\(\\mathbf{X}\\) rank deficient, certain conditions QR factorization algorithm use, Eigen C++ library, drops different coefficients output default lm function. general, users avoid specifying models rank-deficiencies. fact, users certain data rank deficient, can improve speed lm_robust setting try_cholesky = TRUE. replaces QR factorization Cholesky factorization guaranteed work \\(\\mathbf{X}\\) full rank.","code":""},{"path":"https://declaredesign.org/r/estimatr/articles/mathematical-notes.html","id":"weights","dir":"Articles","previous_headings":"Estimators > lm_robust notes > Coefficient estimates","what":"Weights","title":"Mathematical notes for estimatr","text":"weights included, transform data proceed normal, following advice Romano Wolf (2017) weighted estimator attractive properties. first scaling weights sum one. multiply row design matrix \\(\\mathbf{X}\\) square root unit’s weight, \\(\\mathbf{x}_i \\sqrt{w_i}\\), outcome, \\(\\mathbf{y}_i \\sqrt{w_i}\\). results coefficients estimated follows, \\(\\mathbf{W}\\) diagonal matrix scaled weights diagonal. Weighted: \\[ \\widehat{\\beta} =(\\mathbf{X}^{\\top}\\mathbf{W}\\mathbf{X})^{-1}\\mathbf{X}^{\\top}\\mathbf{W}\\mathbf{y} \\] transformed data used analysis , \\((\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\) now \\((\\mathbf{X}^{\\top}\\mathbf{W}\\mathbf{X})^{-1}\\) \\(\\mathbf{X}\\) now \\(\\mathbf{X} \\mathrm{sqrt}[W]\\), \\(\\mathrm{sqrt}[.]\\) operator applies square root coefficients matrix. note transformation yields standard errors specifying weights using aweight Stata “classical”, “HC0”, “HC1” (“stata”) variance estimators. Furthermore, clustered case, weighted estimator “stata” cluster-robust variance also matches Stata. Thus Stata’s main robust standard error estimators, “HC1” clustered estimator, match package weights applied. Nonetheless, Stata uses slightly different Hat matrix thus “HC2” “HC3” estimates Stata weights specified may differ estimates—.","code":""},{"path":"https://declaredesign.org/r/estimatr/articles/mathematical-notes.html","id":"variance","dir":"Articles","previous_headings":"Estimators > lm_robust notes","what":"Variance","title":"Mathematical notes for estimatr","text":"addition solving OLS coefficients faster lm, provide variety robust variance estimators. outline non-clustered clustered cases. can see simulations unbiasedness classical variance estimators homoskedasticity consistency HC2 estimators heteroskedasticity simulations.","code":""},{"path":"https://declaredesign.org/r/estimatr/articles/mathematical-notes.html","id":"heteroskedasticity-robust-variance-and-degrees-of-freedom","dir":"Articles","previous_headings":"Estimators > lm_robust notes > Variance","what":"Heteroskedasticity-Robust Variance and Degrees of Freedom","title":"Mathematical notes for estimatr","text":"default variance estimator without clusters HC2 variance, first proposed MacKinnon White (1985). estimator advantage equivalent conservative randomization-based “Neyman” estimator variance (Samii Aronow 2012). Furthermore, somewhat less efficient HC1 variance estimator, default Stata, tends perform better small samples (evidence can found simulations ). \\(\\mathbf{x}_i\\) \\(\\)th row \\(\\mathbf{X}\\). \\(h_{ii} = \\mathbf{x}_i(\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{x}^{\\top}_i\\) \\(e_i = y_i - \\mathbf{x}_i\\widehat{\\beta}\\) \\(\\mathrm{diag}[.]\\) operator creates diagonal matrix vector \\(N\\) number observations \\(K\\) number elements \\(\\beta\\).","code":""},{"path":"https://declaredesign.org/r/estimatr/articles/mathematical-notes.html","id":"cluster-robust-variance-and-degrees-of-freedom","dir":"Articles","previous_headings":"Estimators > lm_robust notes > Variance","what":"Cluster-Robust Variance and Degrees of Freedom","title":"Mathematical notes for estimatr","text":"cluster-robust inference, provide several estimators essentially analogs heteroskedastic-consistent variance estimators clustered case. default CR2 variance estimator, analogous HC2 standard errors, perform quite well small samples without sacrificing much way efficiency larger samples. estimator originally proposed Bell McCaffrey (2002), although implement generalized version algorithm outlined Pustejovsky Tipton (2018); authors provide R package CR2 variance estimation, clubSandwich, applies standard errors wide variety models. good overview different cluster-robust variance estimators simulations accuracy small samples, users can see Imbens Kolesar (2016). overview use cluster-robust estimators, especially experimental setting, see Abadie et al. (2017). \\(S\\) number clusters \\(\\mathbf{X}_s\\) rows \\(\\mathbf{X}\\) belong cluster \\(s\\) \\(I_n\\) identity matrix size \\(n\\times n\\) \\(\\mathbf{e}_s\\) elements residual matrix \\(\\mathbf{e}\\) cluster \\(s\\), \\(\\mathbf{e}_s = \\mathbf{y}_s - \\mathbf{X}_s \\widehat{\\beta}\\) \\(\\mathbf{}_s\\) \\(\\mathbf{p}\\) defined notes notes CR2: variance estimator implement shown equations (4) (5) Pustejovsky Tipton (2018) equation (11), set \\(\\mathbf{\\Phi}\\) \\(\\), following Bell McCaffrey (2002). note Pustejovsky Tipton (2018) CR2 estimator Bell McCaffrey (2002) estimator identical \\(\\mathbf{B_s}\\) full rank. rank-deficient dummy variables, fixed effects, also clusters. case, original Bell McCaffrey (2002) estimator computed. can see simpler Bell McCaffrey (2002) estimator written plainly page 709 Imbens Kolesar (2016) along degrees freedom denoted \\(K_{BM}\\). CR2 variance calculation, get \\(\\mathbf{}_s\\) follows: \\[ \\begin{aligned} \\mathbf{H} &= \\mathbf{X}(\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{X}^\\top \\\\\\\\\\\\ \\mathbf{B}_s &= (I_{N} - \\mathbf{H})_s (I_{N} - \\mathbf{H})^\\top_s \\\\\\\\\\\\ \\mathbf{}_s &= \\mathbf{B}^{+1/2}_s \\end{aligned} \\] \\(\\mathbf{B}^{+1/2}_s\\) symmetric square root Moore–Penrose inverse \\(\\mathbf{B}_s\\) \\((- \\mathbf{H})_s\\) \\(N_s\\) columns correspond cluster \\(s\\). get corresponding degrees freedom, note \\[ \\mathbf{p}_s = (I_N - \\mathbf{H})^\\top_s \\mathbf{}_s \\mathbf{X}_s (\\mathbf{X}^{\\top}\\mathbf{X})^{-1} \\mathbf{z}_{k} \\] \\(\\mathbf{z}_{k}\\) vector length \\(K\\), number coefficients, \\(k\\)th element 1 elements 0. \\(k\\) signifies coefficient computing degrees freedom.","code":""},{"path":"https://declaredesign.org/r/estimatr/articles/mathematical-notes.html","id":"confidence-intervals-and-hypothesis-testing","dir":"Articles","previous_headings":"Estimators > lm_robust notes","what":"Confidence intervals and hypothesis testing","title":"Mathematical notes for estimatr","text":"\\(\\widehat{\\mathbb{V}}_k\\) \\(k\\)th diagonal element \\(\\widehat{\\mathbb{V}}\\), build confidence intervals using user specified \\(\\alpha\\) : \\[ \\mathrm{CI}^{1-\\alpha} = \\left(\\widehat{\\beta_k} + t^{df}_{\\alpha/2} \\sqrt{\\widehat{\\mathbb{V}}_k}, \\widehat{\\beta_k} + t^{df}_{1 - \\alpha/2} \\sqrt{\\widehat{\\mathbb{V}}_k}\\right) \\] also provide two-sided p-values using t-distribution aforementioned significance level \\(\\alpha\\) degrees freedom \\(df\\).","code":""},{"path":"https://declaredesign.org/r/estimatr/articles/mathematical-notes.html","id":"lm_lin-notes","dir":"Articles","previous_headings":"Estimators","what":"lm_lin notes","title":"Mathematical notes for estimatr","text":"lm_lin estimator data pre-processor lm_robust implements regression method covariate adjustment suggested Lin (2013). estimator works taking outcome treatment variable main formula (formula) takes right-sided formula pre-treatment covariates (covariates). pre-treatment covariates centered mean zero interacted treatment variable added formula passed lm_robust. words, instead fitting simple model adjusting pre-treatment covariates \\[ y_i = \\tau z_i + \\mathbf{\\beta}^\\top \\mathbf{x}_i + \\epsilon_i \\] following model \\[ y_i = \\tau z_i + \\mathbf{\\beta}^\\top \\mathbf{x}^c_i  + \\mathbf{\\gamma}^\\top \\mathbf{x}^c_i z_i + \\epsilon_i \\] \\(\\mathbf{x}^c_i\\) vector pre-treatment covariates unit \\(\\) centered mean zero \\(z_i\\) indicator treatment group. Lin (2013) proposed estimator response critique Freedman (2008) using regression adjust pre-treatment covariates bias estimates treatment effects. estimator lm_lin also works multi-valued treatments creating full set dummies treatment level interacting centered pre-treatment covariates. rest options function corresponding estimation identical lm_robust.","code":""},{"path":"https://declaredesign.org/r/estimatr/articles/mathematical-notes.html","id":"iv_robust-notes","dir":"Articles","previous_headings":"Estimators","what":"iv_robust notes","title":"Mathematical notes for estimatr","text":"iv_robust estimator uses two-stage least squares estimation.","code":""},{"path":"https://declaredesign.org/r/estimatr/articles/mathematical-notes.html","id":"coefficient-estimates-1","dir":"Articles","previous_headings":"Estimators > iv_robust notes","what":"Coefficient estimates","title":"Mathematical notes for estimatr","text":"\\[ \\widehat{\\beta}_{2SLS} =(\\mathbf{X}^{\\top}\\mathbf{P_z}\\mathbf{X})^{-1}\\mathbf{X}^{\\top}\\mathbf{P_z}\\mathbf{y}, \\] \\(\\mathbf{X}\\) endogenous regressors, \\(\\mathbf{P_Z} = \\mathbf{Z}(\\mathbf{Z}^{\\top}\\mathbf{Z})^{-1}\\mathbf{Z}^\\top\\), \\(\\mathbf{Z}\\) instruments. equivalent estimating first stage regression, \\[ \\mathbf{X} = \\mathbf{Z}\\beta_{FS} + \\mathbf{\\zeta}, \\] using first stage predicted values second stage regression, \\[ \\begin{aligned} \\widehat{\\mathbf{X}} &= \\mathbf{Z}\\widehat{\\beta}_{FS} \\\\ \\mathbf{y} &= \\widehat{\\mathbf{X}}\\beta_{2SLS} + \\mathbf{\\epsilon}. \\end{aligned} \\]","code":""},{"path":"https://declaredesign.org/r/estimatr/articles/mathematical-notes.html","id":"weighting","dir":"Articles","previous_headings":"Estimators > iv_robust notes > Coefficient estimates","what":"Weighting","title":"Mathematical notes for estimatr","text":"weights applied, use estimation strategy lm_robust first transform data square root weights proceed estimation usual.","code":""},{"path":"https://declaredesign.org/r/estimatr/articles/mathematical-notes.html","id":"variance-1","dir":"Articles","previous_headings":"Estimators > iv_robust notes","what":"Variance","title":"Mathematical notes for estimatr","text":"variances estimates iv_robust estimates lm_robust although two changes made. First, replace \\(\\mathbf{X}\\) second stage regressors, \\(\\widehat{\\mathbf{X}}\\), replace residuals, \\(e_i\\), \\(\\mathbf{y} - \\mathbf{X} \\beta_{2SLS}\\). , use residuals final coefficients endogenous, uninstrumented regressors \\(\\mathbf{X}\\). Stata default using finite sample corrections tests ivregress 2sls estimator, correspondence instrumental variables estimator can bit unclear. following table shows options Stata correspond estimators.","code":""},{"path":"https://declaredesign.org/r/estimatr/articles/mathematical-notes.html","id":"confidence-intervals-and-hypothesis-testing-1","dir":"Articles","previous_headings":"Estimators > iv_robust notes","what":"Confidence intervals and hypothesis testing","title":"Mathematical notes for estimatr","text":"\\(\\widehat{\\mathbb{V}}_k\\) \\(k\\)th diagonal element \\(\\widehat{\\mathbb{V}}\\), build confidence intervals using user specified \\(\\alpha\\) : \\[ \\mathrm{CI}^{1-\\alpha} = \\left(\\widehat{\\beta_{2SLS, k}} + t^{df}_{\\alpha/2} \\sqrt{\\widehat{\\mathbb{V}}_k}, \\widehat{\\beta_{2SLS, k}} + t^{df}_{1 - \\alpha/2} \\sqrt{\\widehat{\\mathbb{V}}_k}\\right) \\] also provide two-sided p-values using t-distribution aforementioned significance level \\(\\alpha\\) degrees freedom \\(df\\), come second-stage regression. mentioned table , results different Stata certain cases Stata uses z-tests small specified.","code":""},{"path":"https://declaredesign.org/r/estimatr/articles/mathematical-notes.html","id":"difference_in_means-notes","dir":"Articles","previous_headings":"Estimators","what":"difference_in_means notes","title":"Mathematical notes for estimatr","text":"six kinds experimental designs difference_in_means estimator can estimate treatment effects, standard errors, confidence intervals, provide p-values. list different designs along software learns design: Simple (clusters blocks unused) Clustered (clusters specified blocks ) Blocked (blocks specified clusters ) Blocked clustered (specified) two subsets blocked designs also consider: Matched-pairs (blocks specified blocks size two) Matched-pair clustered design (names specified block two clusters) Note: blocks size two blocks greater size two, default matched-pairs estimators described . design, estimator informed recent statistical literature analysis experimental data.","code":""},{"path":"https://declaredesign.org/r/estimatr/articles/mathematical-notes.html","id":"estimates","dir":"Articles","previous_headings":"Estimators > difference_in_means notes","what":"Estimates","title":"Mathematical notes for estimatr","text":"unblocked design \\[ \\widehat{\\tau} = \\frac{1}{N} \\sum^N_{=1} z_i y_i - (1 - z_i) y_i \\] \\(z_i\\) treatment variable, \\(y_i\\) outcome, \\(N\\) total number units. Blocked design (including matched-pairs designs) \\[ \\widehat{\\tau} = \\sum^J_{j=1} \\frac{N_j}{N} \\widehat{\\tau_j} \\] \\(J\\) number blocks, \\(N_j\\) size blocks, \\(\\widehat{\\tau_j}\\) estimated difference--means block \\(j\\).","code":""},{"path":"https://declaredesign.org/r/estimatr/articles/mathematical-notes.html","id":"weighting-1","dir":"Articles","previous_headings":"Estimators > difference_in_means notes > Estimates","what":"Weighting","title":"Mathematical notes for estimatr","text":"user specifies weights, treatment effects (block-level treatment effects) standard errors estimated lm_robust. three exceptions. First, still compute degrees freedom table. Second, design blocked, weighted treatment effect variance estimate computed within block using lm_robust combined . Third, specifying weights matched-pairs estimator difference_in_means supported moment.","code":""},{"path":[]},{"path":"https://declaredesign.org/r/estimatr/articles/mathematical-notes.html","id":"confidence-intervals-and-hypothesis-testing-2","dir":"Articles","previous_headings":"Estimators > difference_in_means notes","what":"Confidence intervals and hypothesis testing","title":"Mathematical notes for estimatr","text":"build confidence intervals using user specified \\(\\alpha\\) : \\[ \\mathrm{CI}^{1-\\alpha} = \\left(\\widehat{\\tau} + t^{df}_{\\alpha/2} \\sqrt{\\widehat{\\mathbb{V}}[\\widehat{\\tau}]},\\widehat{\\tau}] + t^{df}_{1 - \\alpha/2} \\sqrt{\\widehat{\\mathbb{V}}[\\widehat{\\tau}]}\\right) \\] also provide two-sided p-values using t-distribution aforementioned significance level \\(\\alpha\\) degrees freedom \\(df\\).","code":""},{"path":"https://declaredesign.org/r/estimatr/articles/mathematical-notes.html","id":"horvitz_thompson-notes","dir":"Articles","previous_headings":"Estimators","what":"horvitz_thompson notes","title":"Mathematical notes for estimatr","text":"provide Horvitz-Thompson estimators two-armed trials can used estimate unbiased treatment effects randomization known. Horvitz-Thompson estimators require information probability unit treatment control, well joint probability unit treatment, control, opposite treatment conditions. estimator implement , horvitz_thompson(), can told design experiment several ways, reference page good place see examples. Users can see description estimator properties Aronow Middleton (2013), Middleton Aronow (2015), Aronow Samii (2017). definitions used : \\(\\pi_{zi}\\) marginal probability condition \\(z \\\\{0, 1\\}\\) unit \\(\\pi_{ziwj}\\) joint probability unit \\(\\) condition \\(z\\) unit \\(j\\) condition \\(w \\\\{0, 1\\}\\) \\(\\epsilon_{ziwj}\\) indicator function \\(\\mathbb{1}\\left(\\pi_{ziwj} = 0\\right)\\)","code":""},{"path":"https://declaredesign.org/r/estimatr/articles/mathematical-notes.html","id":"estimates-1","dir":"Articles","previous_headings":"Estimators > horvitz_thompson notes","what":"Estimates","title":"Mathematical notes for estimatr","text":"Simple, complete, clustered \\[ \\widehat{\\tau} = \\frac{1}{N} \\sum^N_{=1} z_i \\frac{y_i}{\\pi_{1i}} - (1 - z_i) \\frac{y_i}{\\pi_{0i}} \\] Blocked \\[ \\widehat{\\tau} = \\sum^J_{j=1} \\frac{N_j}{N} \\widehat{\\tau_j} \\] \\(J\\) number blocks, \\(N_j\\) size blocks, \\(\\widehat{\\tau_j}\\) Horvitz-Thompson estimate block \\(j\\).","code":""},{"path":"https://declaredesign.org/r/estimatr/articles/mathematical-notes.html","id":"variance-2","dir":"Articles","previous_headings":"Estimators > horvitz_thompson notes","what":"Variance","title":"Mathematical notes for estimatr","text":"Currently provide variance estimates rely two separate assumptions: \"youngs\" implements conservative variance estimate using Young’s inequality, described equation 35 page 147 Aronow Middleton (2013) Aronow Samii (2017) pages 11-15. \"constant\" assumes constant treatment effects across units less conservative. provide estimator simple randomized experiments. Young’s inequality designs clustered use following variance: \\[ \\begin{aligned}   \\widehat{\\mathbb{V}}_{Y}[\\widehat{\\tau}] = \\frac{1}{N^2} \\sum^N_{=1} \\Bigg[& z_i \\left(\\frac{y_i}{\\pi_{1i}}\\right)^2 + (1 - z_i) \\left(\\frac{y_i}{\\pi_{0i}}\\right)^2 + \\sum_{j \\neq } \\bigg(\\frac{z_i z_j}{\\pi_{1i1j} + \\epsilon_{1i1j}}(\\pi_{1i1j} - \\pi_{1i}\\pi_{1j})\\frac{y_i}{\\pi_{1i}}\\frac{y_j}{\\pi_{1j}} \\\\\\\\\\\\   & + \\frac{(1-z_i) (1-z_j)}{\\pi_{0i0j} + \\epsilon_{0i0j}}(\\pi_{0i0j} - \\pi_{0i}\\pi_{0j})\\frac{y_i}{\\pi_{0i}}\\frac{y_j}{\\pi_{0j}} - 2 \\frac{z_i (1-z_j)}{\\pi_{1i0j} + \\epsilon_{1i0j}}(\\pi_{1i0j} - \\pi_{1i}\\pi_{0j})\\frac{y_i}{\\pi_{1i}}\\frac{y_j}{\\pi_{0j}} \\\\\\\\\\\\   & + \\sum_{\\forall j \\colon \\pi_{1i1j} = 0} \\left( z_i \\frac{y^2_i}{2\\pi_{1i}} + z_j \\frac{y^2_j}{\\pi_{1j}}\\right) + \\sum_{\\forall j \\colon \\pi_{0i0j} = 0} \\left( (1-z_i) \\frac{y^2_i}{2\\pi_{0i}} + (1-z_j) \\frac{y^2_j}{\\pi_{0j}}\\right)   \\Bigg] \\end{aligned} \\] simplifications simpler designs follow algebraically . example, two units joint probability either condition 0, case experiments matched-pair experiments, get: \\[ \\begin{aligned}   \\widehat{\\mathbb{V}}_{Y}[\\widehat{\\tau}] = \\frac{1}{N^2} \\sum^N_{=1} \\Bigg[& z_i \\left(\\frac{y_i}{\\pi_{1i}}\\right)^2 + (1 - z_i) \\left(\\frac{y_i}{\\pi_{0i}}\\right)^2 + \\sum_{j \\neq } \\bigg(\\frac{z_i z_j}{\\pi_{1i1j}}(\\pi_{1i1j} - \\pi_{1i}\\pi_{1j})\\frac{y_i}{\\pi_{1i}}\\frac{y_j}{\\pi_{1j}} \\\\\\\\\\\\   & + \\frac{(1-z_i) (1-z_j)}{\\pi_{0i0j}}(\\pi_{0i0j} - \\pi_{0i}\\pi_{0j})\\frac{y_i}{\\pi_{0i}}\\frac{y_j}{\\pi_{0j}} - 2 \\frac{z_i (1-z_j)}{\\pi_{1i0j}}(\\pi_{1i0j} - \\pi_{1i}\\pi_{0j})\\frac{y_i}{\\pi_{1i}}\\frac{y_j}{\\pi_{0j}}   \\Bigg] \\end{aligned} \\] simplify case simple random assignment, absolutely dependence among units (.e., \\(\\pi_{ziwj} = \\pi_{zi}\\pi_{wj} \\;\\;\\forall\\;\\;z,w,,j\\)), get: \\[ \\begin{aligned}   \\widehat{\\mathbb{V}}_{Y}[\\widehat{\\tau}] = \\frac{1}{N^2} \\sum^N_{=1} \\Bigg[& z_i \\left(\\frac{y_i}{\\pi_{1i}}\\right)^2 + (1 - z_i) \\left(\\frac{y_i}{\\pi_{0i}}\\right)^2\\Bigg] \\end{aligned} \\] Clustered designs clustered designs, use following collapsed estimator setting collapsed = TRUE. , \\(M\\) total number clusters, \\(y_k\\) total outcomes \\(y_i\\) \\(\\) units cluster \\(k\\), \\(\\pi_zk\\) marginal probability cluster \\(k\\) condition \\(z \\\\{0, 1\\}\\), \\(z_k\\) \\(\\pi_{zkwl}\\) defined analogously. Warning! one passes condition_pr_mat horvitz_thompson clustered design, clusters, function use collapsed estimator variance estimate inaccurate. \\[ \\begin{aligned}   \\widehat{\\mathbb{V}}_{Y}[\\widehat{\\tau}] = \\frac{1}{N^2} \\sum^M_{k=1} \\Bigg[& z_k \\left(\\frac{y_k}{\\pi_{1k}}\\right)^2 + (1 - z_k) \\left(\\frac{y_k}{\\pi_{0k}}\\right)^2 + \\sum_{l \\neq k} \\bigg(\\frac{z_k z_l}{\\pi_{1k1l} + \\epsilon_{1k1l}}(\\pi_{1k1l} - \\pi_{1k}\\pi_{1l})\\frac{y_k}{\\pi_{1k}}\\frac{y_l}{\\pi_{1l}} \\\\\\\\\\\\   & + \\frac{(1-z_k) (1-z_l)}{\\pi_{0k0l} + \\epsilon_{0k0l}}(\\pi_{0k0l} - \\pi_{0k}\\pi_{0l})\\frac{y_k}{\\pi_{0k}}\\frac{y_l}{\\pi_{0l}} - 2 \\frac{z_k (1-z_l)}{\\pi_{1k0l} + \\epsilon_{1k0l}}(\\pi_{1k0l} - \\pi_{1k}\\pi_{0l})\\frac{y_k}{\\pi_{1k}}\\frac{y_l}{\\pi_{0l}} \\\\\\\\\\\\   & + \\sum_{\\forall l \\colon \\pi_{1k1l} = 0} \\left( z_k \\frac{y^2_k}{2\\pi_{1k}} + z_l \\frac{y^2_l}{\\pi_{1l}}\\right) + \\sum_{\\forall l \\colon \\pi_{0k0l} = 0} \\left( (1-z_k) \\frac{y^2_k}{2\\pi_{0k}} + (1-z_l) \\frac{y^2_l}{\\pi_{0l}}\\right)   \\Bigg] \\end{aligned} \\] Constant effects Alternatively, one can assume constant treatment effects , assumption, estimate variance consistent assumption less conservative. , estimator implemented simple randomized case. \\(y_{zi}\\) potential outcome condition \\(z\\) unit \\(\\). either observed \\(z_i = z\\) estimated using constant effects assumption \\(z_i \\neq z\\), \\(z_i\\) condition unit \\(\\). precise \\(y_{1i} = z_i y_{} + (1 - z_i) (y_{} + \\widehat{\\tau})\\) \\(y_{0i} = z_i (y_{} - \\widehat{\\tau}) + (1 - z_i) y_{}\\), \\(\\widehat{\\tau}\\) estimated treatment effect. \\[ \\begin{aligned}     \\widehat{\\mathbb{V}}_{C}[\\widehat{\\tau}] = \\frac{1}{N^2} \\sum^N_{=1} \\Bigg[& (1 - \\pi_{0i}) \\pi_{0i} \\left(\\frac{y_{0i}}{\\pi_{0i}}\\right)^2 + (1 - \\pi_{1i}) \\pi_{1i} \\left(\\frac{y_{1i}}{\\pi_{1i}}\\right)^2 - 2 y_{1i} y_{0i} \\\\\\\\\\\\     & + \\sum_{j \\neq } \\Big( (\\pi_{0i0j} - \\pi_{0i} \\pi_{0j}) \\frac{y_{0i}}{\\pi_{0i}} \\frac{y_{0j}}{\\pi_{0j}} + (\\pi_{1i1j} - \\pi_{1i} \\pi_{1j}) \\frac{y_{1i}}{\\pi_{1i}} \\frac{y_{1j}}{\\pi_{1j}} \\\\\\\\\\\\     &- 2 (\\pi_{1i0j} - \\pi_{1i} \\pi_{0j}) \\frac{y_{1i}}{\\pi_{1i}} \\frac{y_{0j}}{\\pi_{0j}}   \\Big)\\Bigg] \\end{aligned} \\]","code":""},{"path":"https://declaredesign.org/r/estimatr/articles/mathematical-notes.html","id":"confidence-intervals-and-hypothesis-testing-3","dir":"Articles","previous_headings":"Estimators > horvitz_thompson notes","what":"Confidence intervals and hypothesis testing","title":"Mathematical notes for estimatr","text":"Theory hypothesis testing Horvitz-Thompson estimator yet developed. rely normal approximation construct confidence intervals following way: \\[ \\mathrm{CI}^{1-\\alpha} = \\left(\\widehat{\\tau} + z_{\\alpha/2} \\sqrt{\\widehat{\\mathbb{V}}[\\widehat{\\tau}]}, \\widehat{\\tau} + z_{1 - \\alpha/2} \\sqrt{\\widehat{\\mathbb{V}}[\\widehat{\\tau}]}\\right) \\] associated p-values two-sided null hypothesis test computed using normal distribution aforementioned significance level \\(\\alpha\\).","code":""},{"path":"https://declaredesign.org/r/estimatr/articles/mathematical-notes.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Mathematical notes for estimatr","text":"Abadie, Alberto, Susan Athey, Guido W Imbens, Jeffrey Wooldridge. 2017. “Class Unbiased Estimators Average Treatment Effect Randomized Experiments.” arXiv Pre-Print. https://arxiv.org/abs/1710.02926v2. Aronow, Peter M, Joel Middleton. 2013. “Class Unbiased Estimators Average Treatment Effect Randomized Experiments.” Journal Causal Inference 1 (1): 135–54. https://doi.org/10.1515/jci-2012-0009. Aronow, Peter M, Cyrus Samii. 2017. “Estimating Average Causal Effects Interference Units.” Annals Applied Statistics, forthcoming. https://arxiv.org/abs/1305.6156v3. Bell, Robert M, Daniel F McCaffrey. 2002. “Bias Reduction Standard Errors Linear Regression Multi-Stage Samples.” Survey Methodology 28 (2): 169–82. Freedman, David . 2008. “Regression Adjustments Experiments Several Treatments.” Annals Applied Statistics, 176–96. https://doi.org/10.1214/07-AOAS143. Gerber, Alan S, Donald P Green. 2012. Field Experiments: Design, Analysis, Interpretation. New York: W.W. Norton. Imai, Kosuke, Gary King, Clayton Nall. 2009. “Essential Role Pair Matching Cluster-Randomized Experiments, Application Mexican Universal Health Insurance Evaluation.” Statistical Science 24 (1): 29–53. https://doi.org/10.1214/08-STS274. Imbens, Guido W, Michal Kolesar. 2016. “Robust Standard Errors Small Samples: Practical Advice.” Review Economics Statistics 98 (4): 701–12. https://doi.org/10.1162/REST_a_00552. Lin, Winston. 2013. “Agnostic Notes Regression Adjustments Experimental Data: Reexamining Freedman’s Critique.” Annals Applied Statistics 7 (1): 295–318. https://doi.org/10.1214/12-AOAS583. MacKinnon, James, Halbert White. 1985. “Heteroskedasticity-Consistent Covariance Matrix Estimators Improved Finite Sample Properties.” Journal Econometrics 29 (3): 305–25. https://doi.org/10.1016/0304-4076(85)90158-7. Middleton, Joel , Peter M Aronow. 2015. “Unbiased Estimation Average Treatment Effect Cluster-Randomized Experiments.” Statistics, Politics Policy 6 (1-2): 39–75. https://doi.org/10.1515/spp-2013-0002. Pustejovsky, James E, Elizabeth Tipton. 2018. “Small-Sample Methods Cluster-Robust Variance Estimation Hypothesis Testing Fixed Effects Models.” Journal Business & Economic Statistics 36 (4). https://doi.org/10.1080/07350015.2016.1247004. Romano, Joseph P, Michael Wolf. 2017. “Resurrecting Weighted Least Squares.” Journal Econometrics 197 (1): 1–19. https://doi.org/10.1016/j.jeconom.2016.10.003. Samii, Cyrus, Peter M Aronow. 2012. “Equivalencies Design-Based Regression-Based Variance Estimators Randomized Experiments.” Statistics Probability Letters 82 (2). https://doi.org/10.1016/j.spl.2011.10.024.","code":""},{"path":"https://declaredesign.org/r/estimatr/articles/regression-tables.html","id":"setup","dir":"Articles","previous_headings":"","what":"Setup","title":"Regression Tables with estimatr","text":"First ’ll load estimatr magrittr (pipes).","code":"library(estimatr) library(magrittr)"},{"path":"https://declaredesign.org/r/estimatr/articles/regression-tables.html","id":"texreg","dir":"Articles","previous_headings":"","what":"Texreg","title":"Regression Tables with estimatr","text":"Texreg operates directly lm_robust object. like standard errors instead confidence intervals, use include.ci = FALSE.","code":"library(texreg) fit <- lm_robust(mpg ~ disp, data = mtcars) texreg(fit, include.ci = FALSE) ##  ## \\begin{table} ## \\begin{center} ## \\begin{tabular}{l c} ## \\hline ##  & Model 1 \\\\ ## \\hline ## (Intercept) & $29.60^{***}$ \\\\ ##             & $(1.49)$      \\\\ ## disp        & $-0.04^{***}$ \\\\ ##             & $(0.01)$      \\\\ ## \\hline ## R$^2$       & $0.72$        \\\\ ## Adj. R$^2$  & $0.71$        \\\\ ## Num. obs.   & $32$          \\\\ ## RMSE        & $3.25$        \\\\ ## \\hline ## \\multicolumn{2}{l}{\\scriptsize{$^{***}p<0.001$; $^{**}p<0.01$; $^{*}p<0.05$}} ## \\end{tabular} ## \\caption{Statistical models} ## \\label{table:coefficients} ## \\end{center} ## \\end{table}"},{"path":"https://declaredesign.org/r/estimatr/articles/regression-tables.html","id":"modelsummary","dir":"Articles","previous_headings":"","what":"modelsummary","title":"Regression Tables with estimatr","text":"modelsummary operates directly lm_robust objects: learn customize output table /statistics, please consult modelsummary README file Github: https://github.com/vincentarelbundock/modelsummary","code":"library(modelsummary) fit1 <- lm(mpg ~ disp, data = mtcars) fit2 <- lm(mpg ~ hp, data = mtcars) modelsummary(list(fit1, fit2))"},{"path":"https://declaredesign.org/r/estimatr/articles/regression-tables.html","id":"stargazer","dir":"Articles","previous_headings":"","what":"Stargazer","title":"Regression Tables with estimatr","text":"Stargazer tricked – ’s unfortunately way around unless something stargazer package changes. maintainer indicated active plans update stargazer future. First, run regression using lm. can pass lm fits starprep function transforms lm fits lm_robust fits prepare appropriate statistic requested. starprep function defaults returning standard errors uses lm_robust defaults standard errors (robust HC2 SEs default lm_robust). pass lm fit stargazer pass starprep(fit) se argument stargazer. process works great multiple fits. examples, although hide output brevity.","code":"library(stargazer) fit_1 <- lm(mpg ~ disp, data = mtcars) fit_2 <- lm(mpg ~ hp, data = mtcars) stargazer(fit_1, fit_2, se = starprep(fit_1, fit_2)) ##  ## \\begin{table}[!htbp] \\centering  ##   \\caption{}  ##   \\label{}  ## \\begin{tabular}{@{\\extracolsep{5pt}}lcc}  ## \\\\[-1.8ex]\\hline  ## \\hline \\\\[-1.8ex]  ##  & \\multicolumn{2}{c}{\\textit{Dependent variable:}} \\\\  ## \\cline{2-3}  ## \\\\[-1.8ex] & \\multicolumn{2}{c}{mpg} \\\\  ## \\\\[-1.8ex] & (1) & (2)\\\\  ## \\hline \\\\[-1.8ex]  ##  disp & $-$0.041$^{***}$ &  \\\\  ##   & (0.005) &  \\\\  ##   & & \\\\  ##  hp &  & $-$0.068$^{***}$ \\\\  ##   &  & (0.015) \\\\  ##   & & \\\\  ##  Constant & 29.600$^{***}$ & 30.099$^{***}$ \\\\  ##   & (1.490) & (2.193) \\\\  ##   & & \\\\  ## \\hline \\\\[-1.8ex]  ## Observations & 32 & 32 \\\\  ## R$^{2}$ & 0.718 & 0.602 \\\\  ## Adjusted R$^{2}$ & 0.709 & 0.589 \\\\  ## Residual Std. Error (df = 30) & 3.251 & 3.863 \\\\  ## F Statistic (df = 1; 30) & 76.513$^{***}$ & 45.460$^{***}$ \\\\  ## \\hline  ## \\hline \\\\[-1.8ex]  ## \\textit{Note:}  & \\multicolumn{2}{r}{$^{*}$p$<$0.1; $^{**}$p$<$0.05; $^{***}$p$<$0.01} \\\\  ## \\end{tabular}  ## \\end{table} # Can also specify clusters and standard error type stargazer(   fit_1, fit_2,   se = starprep(fit_1, fit_2, clusters = mtcars$cyl, se_type = \"stata\") )  # Can also precompute robust objects to save computation time # using `commarobust` fit_1_r <- commarobust(fit_1) fit_2_r <- commarobust(fit_2) stargazer(fit_1, fit_2,           se = starprep(fit_1_r, fit_2_r),           p = starprep(fit_1_r, fit_2_r, stat = \"p.value\"))  # can also easily get robust confidence intervals stargazer(fit_1, fit_2,           ci.custom = starprep(fit_1_r, fit_2_r, stat = \"ci\"))"},{"path":"https://declaredesign.org/r/estimatr/articles/regression-tables.html","id":"xtable","dir":"Articles","previous_headings":"","what":"xtable","title":"Regression Tables with estimatr","text":"xtable works directly data.frame, just prep lm_robust output tidy function.","code":"library(xtable) fit <- lm_robust(mpg ~ disp, data = mtcars) fit %>% tidy %>% xtable() ## % latex table generated in R 4.3.3 by xtable 1.8-4 package ## % Tue Mar  5 23:09:52 2024 ## \\begin{table}[ht] ## \\centering ## \\begin{tabular}{rlrrrrrrrl} ##   \\hline ##  & term & estimate & std.error & statistic & p.value & conf.low & conf.high & df & outcome \\\\  ##   \\hline ## 1 & (Intercept) & 29.60 & 1.49 & 19.86 & 0.00 & 26.56 & 32.64 & 30.00 & mpg \\\\  ##   2 & disp & -0.04 & 0.01 & -7.97 & 0.00 & -0.05 & -0.03 & 30.00 & mpg \\\\  ##    \\hline ## \\end{tabular} ## \\end{table}"},{"path":"https://declaredesign.org/r/estimatr/articles/regression-tables.html","id":"huxtable","dir":"Articles","previous_headings":"","what":"huxtable","title":"Regression Tables with estimatr","text":"huxtable, , works data.frame, prep tidy.","code":"library(huxtable) fit <- lm_robust(mpg ~ disp, data = mtcars) fit %>% tidy %>% hux() %>% print_latex() ##  ##  ## ```{=latex} ##   ##   \\providecommand{\\huxb}[2]{\\arrayrulecolor[RGB]{#1}\\global\\arrayrulewidth=#2pt} ##   \\providecommand{\\huxvb}[2]{\\color[RGB]{#1}\\vrule width #2pt} ##   \\providecommand{\\huxtpad}[1]{\\rule{0pt}{#1}} ##   \\providecommand{\\huxbpad}[1]{\\rule[-#1]{0pt}{#1}} ##  ## \\begin{table}[ht] ## \\begin{centerbox} ## \\begin{threeparttable} ##  \\label{tab:unnamed-chunk-8} ## \\setlength{\\tabcolsep}{0pt} ## \\begin{tabular}{l l l l l l l l l} ##  ##  ## \\hhline{} ## \\arrayrulecolor{black} ##  ## \\multicolumn{1}{!{\\huxvb{0, 0, 0}{0}}l!{\\huxvb{0, 0, 0}{0}}}{\\huxtpad{6pt + 1em}\\raggedright \\hspace{6pt} term \\hspace{6pt}\\huxbpad{6pt}} & ## \\multicolumn{1}{r!{\\huxvb{0, 0, 0}{0}}}{\\huxtpad{6pt + 1em}\\raggedleft \\hspace{6pt} estimate \\hspace{6pt}\\huxbpad{6pt}} & ## \\multicolumn{1}{r!{\\huxvb{0, 0, 0}{0}}}{\\huxtpad{6pt + 1em}\\raggedleft \\hspace{6pt} std.error \\hspace{6pt}\\huxbpad{6pt}} & ## \\multicolumn{1}{r!{\\huxvb{0, 0, 0}{0}}}{\\huxtpad{6pt + 1em}\\raggedleft \\hspace{6pt} statistic \\hspace{6pt}\\huxbpad{6pt}} & ## \\multicolumn{1}{r!{\\huxvb{0, 0, 0}{0}}}{\\huxtpad{6pt + 1em}\\raggedleft \\hspace{6pt} p.value \\hspace{6pt}\\huxbpad{6pt}} & ## \\multicolumn{1}{r!{\\huxvb{0, 0, 0}{0}}}{\\huxtpad{6pt + 1em}\\raggedleft \\hspace{6pt} conf.low \\hspace{6pt}\\huxbpad{6pt}} & ## \\multicolumn{1}{r!{\\huxvb{0, 0, 0}{0}}}{\\huxtpad{6pt + 1em}\\raggedleft \\hspace{6pt} conf.high \\hspace{6pt}\\huxbpad{6pt}} & ## \\multicolumn{1}{r!{\\huxvb{0, 0, 0}{0}}}{\\huxtpad{6pt + 1em}\\raggedleft \\hspace{6pt} df \\hspace{6pt}\\huxbpad{6pt}} & ## \\multicolumn{1}{l!{\\huxvb{0, 0, 0}{0}}}{\\huxtpad{6pt + 1em}\\raggedright \\hspace{6pt} outcome \\hspace{6pt}\\huxbpad{6pt}} \\tabularnewline[-0.5pt] ##  ##  ## \\hhline{} ## \\arrayrulecolor{black} ##  ## \\multicolumn{1}{!{\\huxvb{0, 0, 0}{0}}l!{\\huxvb{0, 0, 0}{0}}}{\\huxtpad{6pt + 1em}\\raggedright \\hspace{6pt} (Intercept) \\hspace{6pt}\\huxbpad{6pt}} & ## \\multicolumn{1}{r!{\\huxvb{0, 0, 0}{0}}}{\\huxtpad{6pt + 1em}\\raggedleft \\hspace{6pt} 29.6\\hphantom{0}\\hphantom{0}\\hphantom{0} \\hspace{6pt}\\huxbpad{6pt}} & ## \\multicolumn{1}{r!{\\huxvb{0, 0, 0}{0}}}{\\huxtpad{6pt + 1em}\\raggedleft \\hspace{6pt} 1.49\\hphantom{0}\\hphantom{0}\\hphantom{0} \\hspace{6pt}\\huxbpad{6pt}} & ## \\multicolumn{1}{r!{\\huxvb{0, 0, 0}{0}}}{\\huxtpad{6pt + 1em}\\raggedleft \\hspace{6pt} 19.9\\hphantom{0} \\hspace{6pt}\\huxbpad{6pt}} & ## \\multicolumn{1}{r!{\\huxvb{0, 0, 0}{0}}}{\\huxtpad{6pt + 1em}\\raggedleft \\hspace{6pt} 8.19e-19 \\hspace{6pt}\\huxbpad{6pt}} & ## \\multicolumn{1}{r!{\\huxvb{0, 0, 0}{0}}}{\\huxtpad{6pt + 1em}\\raggedleft \\hspace{6pt} 26.6\\hphantom{0}\\hphantom{0}\\hphantom{0} \\hspace{6pt}\\huxbpad{6pt}} & ## \\multicolumn{1}{r!{\\huxvb{0, 0, 0}{0}}}{\\huxtpad{6pt + 1em}\\raggedleft \\hspace{6pt} 32.6\\hphantom{0}\\hphantom{0}\\hphantom{0} \\hspace{6pt}\\huxbpad{6pt}} & ## \\multicolumn{1}{r!{\\huxvb{0, 0, 0}{0}}}{\\huxtpad{6pt + 1em}\\raggedleft \\hspace{6pt} 30 \\hspace{6pt}\\huxbpad{6pt}} & ## \\multicolumn{1}{l!{\\huxvb{0, 0, 0}{0}}}{\\huxtpad{6pt + 1em}\\raggedright \\hspace{6pt} mpg \\hspace{6pt}\\huxbpad{6pt}} \\tabularnewline[-0.5pt] ##  ##  ## \\hhline{} ## \\arrayrulecolor{black} ##  ## \\multicolumn{1}{!{\\huxvb{0, 0, 0}{0}}l!{\\huxvb{0, 0, 0}{0}}}{\\huxtpad{6pt + 1em}\\raggedright \\hspace{6pt} disp \\hspace{6pt}\\huxbpad{6pt}} & ## \\multicolumn{1}{r!{\\huxvb{0, 0, 0}{0}}}{\\huxtpad{6pt + 1em}\\raggedleft \\hspace{6pt} -0.0412 \\hspace{6pt}\\huxbpad{6pt}} & ## \\multicolumn{1}{r!{\\huxvb{0, 0, 0}{0}}}{\\huxtpad{6pt + 1em}\\raggedleft \\hspace{6pt} 0.00517 \\hspace{6pt}\\huxbpad{6pt}} & ## \\multicolumn{1}{r!{\\huxvb{0, 0, 0}{0}}}{\\huxtpad{6pt + 1em}\\raggedleft \\hspace{6pt} -7.97 \\hspace{6pt}\\huxbpad{6pt}} & ## \\multicolumn{1}{r!{\\huxvb{0, 0, 0}{0}}}{\\huxtpad{6pt + 1em}\\raggedleft \\hspace{6pt} 6.74e-09 \\hspace{6pt}\\huxbpad{6pt}} & ## \\multicolumn{1}{r!{\\huxvb{0, 0, 0}{0}}}{\\huxtpad{6pt + 1em}\\raggedleft \\hspace{6pt} -0.0518 \\hspace{6pt}\\huxbpad{6pt}} & ## \\multicolumn{1}{r!{\\huxvb{0, 0, 0}{0}}}{\\huxtpad{6pt + 1em}\\raggedleft \\hspace{6pt} -0.0307 \\hspace{6pt}\\huxbpad{6pt}} & ## \\multicolumn{1}{r!{\\huxvb{0, 0, 0}{0}}}{\\huxtpad{6pt + 1em}\\raggedleft \\hspace{6pt} 30 \\hspace{6pt}\\huxbpad{6pt}} & ## \\multicolumn{1}{l!{\\huxvb{0, 0, 0}{0}}}{\\huxtpad{6pt + 1em}\\raggedright \\hspace{6pt} mpg \\hspace{6pt}\\huxbpad{6pt}} \\tabularnewline[-0.5pt] ##  ##  ## \\hhline{} ## \\arrayrulecolor{black} ## \\end{tabular} ## \\end{threeparttable}\\par\\end{centerbox} ##  ## \\end{table} ##   ## ```"},{"path":"https://declaredesign.org/r/estimatr/articles/simulations-debiasing-dim.html","id":"blocked-designs","dir":"Articles","previous_headings":"","what":"Blocked designs","title":"Simulations - Debiasing Difference-in-Means","text":"Blocking common strategy experimental design used improve efficiency estimators ensuring units similar potential outcomes, blocked, represented treatment conditions.","code":""},{"path":"https://declaredesign.org/r/estimatr/articles/simulations-debiasing-dim.html","id":"fixed-probability-of-treatment","dir":"Articles","previous_headings":"Blocked designs","what":"Fixed probability of treatment","title":"Simulations - Debiasing Difference-in-Means","text":"Let’s first consider example blocks predict potential outcomes probability treatment constant across blocks. case, estimating simple difference--means without passing information blocks bias estimate, take advantage increased efficiency blocking provides standard errors unnecessarily large. Let’s see example. First, let’s set data randomization scheme. analyses, estimand average treatment effect Now let’s define two estimators, one doesn’t account blocking one . estimator accounts blocking essentially compute treatment effects within blocks take weighted average across blocks. Details references can found mathematical notes. Let’s get sample dataset show relationship treatment potential outcomes blocks.  can see, blocks tend clustered treatment potential outcomes. Now let’s compare performance two estimators using diagnosands interest. estimates unbiased (indeed identical), can see standard errors accounting blocking much smaller (leading better coverage efficient estimation). Note \"se\" rows table describe uncertainty arising simulation can help us know well estimated bias variance using simulation approach.","code":"# Define population with blocks of the same size, with some block-level shock simp_blocks <- declare_model(   blocks = add_level(     N = 40,     block_shock = runif(N, 0, 10)   ),   individual = add_level(     N = 8,     epsilon = rnorm(N),     # Block shocks influnce Y_Z_1, the treatment potential outcome     potential_outcomes(Y ~ Z * 0.5 * block_shock + epsilon)   ) ) # Complete random assignment of half of units in each block blocked_assign <- declare_assignment(Z = block_ra(blocks = blocks, prob = 0.5)) # Estimand is the ATE ate <- declare_inquiry(ATE = mean(Y_Z_1 - Y_Z_0)) outcomes <- declare_measurement(Y = reveal_outcomes(Y ~ Z)) dim <- declare_estimator(Y ~ Z, inquiry = \"ATE\", label = \"DIM\") dim_bl <- declare_estimator(Y ~ Z, .method = difference_in_means, blocks = blocks, inquiry = \"ATE\", label = \"DIM blocked\")  # Our design simp_bl_des <- simp_blocks +   blocked_assign +   ate +   outcomes +    dim +   dim_bl  # Our diagnosands of interest my_diagnosands <- declare_diagnosands(   `Bias` = mean(estimate - estimand),   `Coverage` =  mean(estimand <= conf.high & estimand >= conf.low),   `Mean of Estimated ATE` = mean(estimate),   `Mean of True ATE (Estimand)` = mean(estimand),   `Mean Standard Error` = mean(std.error) ) set.seed(42) dat <- draw_data(simp_bl_des) plot(dat$blocks, dat$Y_Z_1,      ylab = \"Y_Z_1 (treatment PO)\", xlab = \"Block ID\") set.seed(42) simp_bl_dig <- diagnose_design(   simp_bl_des,   sims = 500,   diagnosands = my_diagnosands )"},{"path":"https://declaredesign.org/r/estimatr/articles/simulations-debiasing-dim.html","id":"correlated-potential-outcomes-and-treatment-probabilities","dir":"Articles","previous_headings":"Blocked designs","what":"Correlated potential outcomes and treatment probabilities","title":"Simulations - Debiasing Difference-in-Means","text":"However, accounting blocking becomes problematic probability treatment block correlated potential outcomes. Imagine, example, working partner wants intervention big effect amenable rigorous analysis (case, congratulations). scenario, may suspect certain types units higher treatment effects want units treated often. case, blocks higher treatment effects treated often, naive estimator overrepresent treated units upwardly bias ATE. Accounting blocking estimating treatment effects within block weighting probability treatment, difference_in_means() estimator blocks specified, eliminate bias. can see , probability treatment strongly correlated treatment effect.  Let’s diagnose estimators. can see, bias coverage wrong naive difference means, corrected estimator bias coverage closer nominal level.","code":"corr_blocks <- declare_model(   blocks = add_level(     N = 60,     block_shock = runif(N, 0, 10),     indivs_per_block = 8,     # if block shock is > 5, treat 6 units, otherwise treat 2     m_treat = ifelse(block_shock > 5, 6, 2)   ),   individual = add_level(     N = indivs_per_block,     epsilon = rnorm(N, sd = 3)        ) ) +    declare_model(potential_outcomes(Y ~ Z * 0.5 * block_shock + epsilon)) # Use same potential outcomes as above, but now treatment probability varies across blocks corr_blocked_assign <- declare_assignment(   Z = block_ra(     blocks = blocks,     # The next line will just get the number of treated for a block from     # the first unit in that block     block_m = m_treat[!duplicated(blocks)]   ),   legacy = FALSE ) corr_bl_des <-    corr_blocks +   corr_blocked_assign +   ate +   outcomes +   dim +   dim_bl set.seed(43) dat <- draw_data(corr_bl_des) plot(factor(dat$m_treat / 8), dat$Y_Z_1 - dat$Y_Z_0,      ylab = \"True treat. effect\", xlab = \"Pr treatment in block\") set.seed(44) corr_bl_dig <- diagnose_design(   corr_bl_des,   sims = 500,   diagnosands = my_diagnosands ) corr_bl_dig$simulations <- NULL"},{"path":"https://declaredesign.org/r/estimatr/articles/simulations-debiasing-dim.html","id":"clustered-designs","dir":"Articles","previous_headings":"","what":"Clustered designs","title":"Simulations - Debiasing Difference-in-Means","text":"Another common design involves clustered treatment assignment, units can treated groups. often arises treatments can happen classroom, village, aggregated level, can observe outcomes lower level, student classroom voter village.","code":""},{"path":"https://declaredesign.org/r/estimatr/articles/simulations-debiasing-dim.html","id":"clusters-of-the-same-size","dir":"Articles","previous_headings":"Clustered designs","what":"Clusters of the same size","title":"Simulations - Debiasing Difference-in-Means","text":"clustered designs, naive difference--means estimate ATE unbiased. However, potential outcomes correlated cluster, naive standard error underestimate standard error. sampling variability estimated ATE greater certain clusters similar potential outcomes treatment status across runs. pass clusters difference--means estimator, properly account increase sampling variability. Let’s see action. Let’s look example data generated design. can see, treatment clustered. Furthermore, treatment potential outcomes correlated cluster.  Let’s diagnose design. can see, estimates coverage naive difference--means nominal level 95 percent. design-aware difference--means accounts clustering conservative case appropriate estimator.","code":"# Define clustered data simp_clusts <- declare_model(   clusters = add_level(     N = 40,     clust_shock = runif(N, 0, 10)   ),   individual = add_level(     N = 8,     epsilon = rnorm(N),     # Treatment potential outcomes correlated with cluster shock     potential_outcomes(Y ~ Z * 0.2 * clust_shock + epsilon)   ) )  # Clustered assignment to treatment clustered_assign <- declare_assignment(Z = cluster_ra(clusters = clusters, prob = 0.5), legacy = FALSE)  ate <- declare_inquiry(ATE = mean(Y_Z_1 - Y_Z_0))  # Specify our two estimators dim <- declare_estimator(Y ~ Z, label = \"DIM\") dim_cl <- declare_estimator(Y ~ Z, clusters = clusters, label = \"DIM clustered\")  simp_cl_des <- simp_clusts +   clustered_assign +   ate +   outcomes +    dim +   dim_cl set.seed(45) dat <- draw_data(simp_cl_des) table(Z = dat$Z, clusters = dat$clusters) ##    clusters ## Z   01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 ##   0  0  0  0  8  8  8  8  8  8  0  0  0  0  8  8  8  0  0  0  8  8  8  8  0  0 ##   1  8  8  8  0  0  0  0  0  0  8  8  8  8  0  0  0  8  8  8  0  0  0  0  8  8 ##    clusters ## Z   26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 ##   0  8  0  0  8  0  8  0  0  8  8  8  0  8  0  0 ##   1  0  8  8  0  8  0  8  8  0  0  0  8  0  8  8 plot(dat$clusters, dat$Y_Z_1,      ylab = \"Y_Z_1 (treatment PO)\", xlab = \"Cluster ID\") set.seed(46) simp_cl_dig <- diagnose_design(   simp_cl_des,   sims = 500,   diagnosands = my_diagnosands )"},{"path":"https://declaredesign.org/r/estimatr/articles/simulations-debiasing-dim.html","id":"clusters-of-different-sizes","dir":"Articles","previous_headings":"Clustered designs","what":"Clusters of different sizes","title":"Simulations - Debiasing Difference-in-Means","text":"clusters different sizes, potential outcomes correlated cluster size, difference--means estimator longer appropriate biased. One solution use Horvitz-Thompson estimator, actually difference--totals estimator. , use simulation show difference--means estimator account correlation cluster size potential outcomes, Horvitz-Thompson estimator can. Now let’s diagnose! can see, Horvitz-Thompson estimate unbiased DIM biased (observe standard error DIM bias much smaller bias, Horvitz-Thompson bias much smaller standard error bias). Unfortunately, cost lower bias much higher variance. look Mean Standard Error, ’ll see standard error Horvitz-Thompson estimator average 50 percent greater standard error biased difference--means estimator.","code":"# Correlated cluster size and potential outcomes diff_size_cls <- declare_model(   clusters = add_level(     N = 10,     clust_shock = runif(N, 0, 10),     indivs_per_clust = ceiling(clust_shock),     condition_pr = 0.5   ),   individual = add_level(     N = indivs_per_clust,     epsilon = rnorm(N, sd = 3)   ) ) +    declare_model(potential_outcomes(Y ~ Z * 0.4 * clust_shock + epsilon)) clustered_assign <- declare_assignment(Z = cluster_ra(clusters = clusters, prob = 0.5))  ht_cl <- declare_estimator(   formula = Y ~ Z,   clusters = clusters,   condition_prs = condition_pr,   simple = FALSE,   .method = estimatr::horvitz_thompson,   inquiry = \"ATE\",   label = \"Horvitz-Thompson Clustered\" )  ate <- declare_inquiry(ATE = mean(Y_Z_1 - Y_Z_0))  diff_cl_des <- diff_size_cls +    clustered_assign +    ate +    outcomes  dat <- draw_data(diff_cl_des) ht_cl(dat) ##                    estimator term estimate std.error statistic   p.value ## 1 Horvitz-Thompson Clustered    Z 2.728959  2.096487  1.301682 0.1930251 ##    conf.low conf.high df outcome inquiry ## 1 -1.380079  6.837997 NA       Y     ATE diff_cl_des <- diff_size_cls +    clustered_assign +    ate +    outcomes +    dim_cl +    ht_cl set.seed(47) diff_cl_dig <- diagnose_design(   diff_cl_des,   sims = 500,   diagnosands = my_diagnosands )"},{"path":"https://declaredesign.org/r/estimatr/articles/simulations-ols-variance.html","id":"homoskedastic-errors","dir":"Articles","previous_headings":"","what":"Homoskedastic errors","title":"Simulations - OLS and Variance","text":"simple conditions homoskedasticity (.e., errors drawn distribution variance), classical estimator variance OLS unbiased. section demonstrate true using DeclareDesign estimatr. First, let’s take simple set : \\[ \\begin{aligned} \\mathbf{y} &= \\mathbf{X}\\beta + \\epsilon, \\\\ \\epsilon_i &\\overset{..d.}{\\sim} N(0, \\sigma^2). \\end{aligned} \\] simulation, let’s constant one covariate, \\(\\mathbf{X} = [\\mathbf{1}, \\mathbf{x_1}]\\), \\(\\mathbf{x_1}\\) column vector covariate drawn standard normal distribution. Let’s also assume covariates fixed, rather stochastic. Let’s draw data use. function \\[ \\epsilon_i \\overset{..d.}{\\sim} N(0, \\sigma^2), \\] encodes assumption homoskedasticity. homoskedastic errors, know true variance coefficients fixed covariates \\[ \\mathbb{V}[\\widehat{\\beta}] = \\sigma^2 (\\mathbf{X}^\\top \\mathbf{X})^{-1}, \\] hide conditioning \\(\\mathbf{X}\\) simplicity. Let’s compute true variance dataset. example, going focus variance covariate, intercept, let’s store variance. Now, using DeclareDesign, let’s specify rest data generating process (DGP). Let’s set \\(\\beta = [0, 1]^\\top\\), true DGP \\(\\mathbf{y} = \\mathbf{x_1} + \\epsilon\\). Now let’s tell DeclareDesign target, estimand, true variance. estimator estimand classical OLS variance estimator, know unbiased: \\[ \\widehat{\\mathbb{V}[\\widehat{\\beta}]} = \\frac{\\mathbf{e}^\\top\\mathbf{e}}{N - K} (\\mathbf{X}^\\top \\mathbf{X})^{-1}, \\] residuals \\(\\mathbf{e} = \\mathbf{y} - \\mathbf{X}\\widehat{\\beta}\\), \\(N\\) number observations, \\(K\\) number regressors—two case. can easily get estimate variance squaring standard error get lm_robust estimatr. Let’s tell DeclareDesign use estimator get coefficient \\(\\mathbf{x}_1\\) variable. Now, want test results using Monte Carlo simulation. main goal show estimated variance unbiased true variance (estimand). can comparing mean estimated variances across Monto Carlo simulations true variance. can also show standard error coefficient estimate standard deviation sampling distribution coefficient. Lastly, also measure coverage 95 percent confidence intervals across simulations test whether cover true coefficient 95 percent time. Let’s first set design diagnosands. Now let’s run simulations! diagnosands can help us see bias. can see bias close zero. standard error bias much larger estimated bias, can reasonably certain reason bias exactly zero due simulation error. can also see unbiasedness visually, using density plot estimated variances line true variance.","code":"set.seed(41) dat <- data.frame(x = rnorm(50)) sigmasq <- 4 # Build the X matrix with intercept Xmat <- cbind(1, dat$x) # Invert XtX XtX_inv <- solve(crossprod(Xmat)) # Get full variance covariance matrix true_var_cov_mat <- sigmasq * XtX_inv true_varb <- true_var_cov_mat[2, 2] true_varb ## [1] 0.07831866 simp_pop <- declare_model(   epsilon = rnorm(N, sd = 2),   y = x + epsilon ) varb_estimand <- declare_inquiry(true_varb = true_varb) lmc <- declare_estimator(   y ~ x,   model = lm_robust,   se_type = \"classical\",   inquiry = varb_estimand,   term = \"x\" ) # First declare all the steps of our design, starting with our fixed data classical_design <- declare_model(dat) + simp_pop + varb_estimand + lmc  # Declare a set of diagnosands that help us check if # we have unbiasedness my_diagnosands <- declare_diagnosands(   `Bias of Estimated Variance` = mean(std.error^2 - estimand),   `Bias of Standard Error` = mean(std.error - sd(estimate)),   `Coverage Rate` = mean(1 <= conf.low & 1 >= conf.high),   `Mean of Estimated Variance` = mean(std.error^2),   `True Variance` = estimand[1],    keep_defaults = FALSE ) set.seed(42) dx1 <- diagnose_design(   classical_design,   sims = sims,   diagnosands = my_diagnosands ) kable(reshape_diagnosis(dx1, digits = 3))"},{"path":"https://declaredesign.org/r/estimatr/articles/simulations-ols-variance.html","id":"heteroskedastic-errors","dir":"Articles","previous_headings":"","what":"Heteroskedastic errors","title":"Simulations - OLS and Variance","text":"Let’s use fixed data set-, introduce heteroskedasticity. case, variance errors different across units: \\[ \\epsilon_i \\sim N(0, \\sigma_i^2), \\] \\(\\sigma^2_i \\neq \\sigma^2_j\\) units \\(\\) \\(j\\). variance errors independent regressors, “classical” variance biased inconsistent. Meanwhile, heteroskedastic-consistent variance estimators, HC2 estimator, consistent normally less biased “classical” estimator. Let’s demonstrate using DeclareDesign. First, let’s specify variance errors strongly correlated \\(x\\).  Note general form true variance fixed covariates : \\[ \\mathbb{V}[\\widehat{\\beta}] = (\\mathbf{X}^\\top \\mathbf{X})^{-1} \\mathbf{X}^\\top \\mathbf{\\Phi} \\mathbf{X} (\\mathbf{X}^\\top \\mathbf{X})^{-1}, \\] \\(\\mathbf{\\Phi}\\) variance covariance matrix errors, \\(\\mathbf{\\Phi} = \\mathbb{E}[\\epsilon\\epsilon^\\top]\\). case homoskedasticity, assumed \\(\\mathbf{\\Phi} = \\sigma^2 \\mathbf{}\\) able simplify. Now, standard set heteroskedasticity, set \\(\\mathbf{\\Phi}\\) diagonal matrix noise_var, variance unit’s error, diagonal, like : \\[ \\mathbf{\\Phi} = \\begin{bmatrix} \\sigma_1^2 & 0 & \\cdots & 0 \\\\ 0 & \\sigma_2^2 & \\cdots & 0 \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ 0 & 0 & \\cdots & \\sigma_n^2 \\end{bmatrix} \\] Using error structure error unit, can estimate true variance. Now let’s use DeclareDesign test whether HC2 less biased example classical standard errors. HC2 estimatr default; ’ll also throw HC1, Stata’s default robust standard error estimator. ’m going make “designer,” function returns design. let’s use diagnosands test properties estimators heteroskedasticity. bias HC2 errors much closer zero, whereas bias classical error much larger, especially compared standard error bias diagnosand. bias change sample size changes? HC2 variance estimate consistent heteroskedasticity, converge zero.  can see, HC2 variance tends less bias consistent, converging true value sample size increases. classical standard error estimator neither unbiased consistent. HC1 variance also “robust” heteroskedasiticity exhibits greater bias HC2 example.","code":"dat <- mutate(dat, noise_var = 1 + (x - min(x))^2 ) ggplot(dat, aes(x, noise_var)) + geom_point() +   ggtitle(\"The variance of errors increases with x\") Xmat <- with(dat, cbind(1, x)) XtX_inv <- solve(crossprod(Xmat)) varb <- tcrossprod(XtX_inv, Xmat) %*% diag(with(dat, noise_var)) %*% Xmat %*% XtX_inv true_varb_het <- varb[2, 2] true_varb_het ## [1] 0.1473923 het_designer <- function(N) {      dat <- fabricate(N = N, x = rnorm(N), noise_var = 1 + (x - min(x))^2)    # Get true variance for this data   Xmat <- with(dat, cbind(1, x))   XtX_inv <- solve(crossprod(Xmat))   varb <- tcrossprod(XtX_inv, Xmat) %*% diag(with(dat, noise_var)) %*% Xmat %*% XtX_inv   true_varb_het <- varb[2, 2]    # Population function now has heteroskedastic noise   simp_pop <- declare_model(     dat,     epsilon = rnorm(N, sd = sqrt(noise_var)),     y = x + epsilon   )    varb_het_estimand <- declare_inquiry(true_varb_het = true_varb_het)    # Now we declare all three estimators   lm1 <- declare_estimator(     y ~ x,     model = lm_robust,     se_type = \"classical\",     inquiry = varb_het_estimand,     term = \"x\",     label = \"classical\"   )    lm2 <- declare_estimator(     y ~ x,     model = lm_robust,     se_type = \"HC1\",     inquiry = varb_het_estimand,     term = \"x\",     label = \"HC1\"   )      lm3 <- declare_estimator(     y ~ x,     model = lm_robust,     se_type = \"HC2\",     inquiry = varb_het_estimand,     term = \"x\",     label = \"HC2\"   )       # We return the design so we can diagnose it   return(simp_pop + varb_het_estimand + lm1 + lm2 + lm3) } # Create a design using our template and the data we have been using het_design <- het_designer(N = 50) dx2 <- diagnose_design(   het_design,   diagnosands = my_diagnosands,   sims = sims   ) kable(reshape_diagnosis(dx2)) designs <- expand_design(het_designer, N = c(100, 200, 300, 500, 1000, 2500))  set.seed(42) dx3 <- diagnose_design(designs, sims = sims, diagnosands = my_diagnosands) ggplot(dx3$diagnosands_df, aes(x = N, y = `Bias of Estimated Variance`, color = estimator)) +   geom_point() +   geom_line() +   geom_hline(yintercept = 0, linetype = 2, color = \"grey\") +   labs(color = \"Estimator\") +   theme_bw()"},{"path":"https://declaredesign.org/r/estimatr/articles/stata-wls-hat.html","id":"weighted-least-squares","dir":"Articles","previous_headings":"","what":"Weighted least squares","title":"How Stata's hat matrix differs with weights","text":"Let’s briefly review WLS. Weights used linear regression often two key problems; (1) model correct heteroskedasticity, (2) deal unequal sampling (treatment) probabilities. cases, take standard model \\[ y_i = \\mathbf{x}_i^\\top \\mathbf{\\beta} + \\epsilon_i, \\] \\(y_i\\) \\(\\)th unit’s outcome, \\(\\mathbf{x}_i\\) column vector covariates, \\(\\mathbf{\\beta}\\) coefficients interest, \\(\\epsilon\\) error, rescale model square root unit’s weight, \\(\\sqrt{w_i}\\). model becomes \\[ \\frac{y_i}{\\sqrt{w_i}} = \\frac{\\mathbf{x}_i^\\top}{\\sqrt{w_i}} \\mathbf{\\beta} + \\frac{\\epsilon_i}{\\sqrt{w_i}}. \\] can shown solution \\(\\mathbf{\\beta}\\) \\[ \\widehat{\\mathbf{\\beta}} = (\\mathbf{X}^{\\top}\\mathbf{W}\\mathbf{X})^{-1} \\mathbf{X}^\\top \\mathbf{W} \\mathbf{y}, \\] \\(\\mathbf{W}\\) diagonal matrix entry \\(w_{}\\), \\(\\mathbf{X}\\) covariate matrix, \\(\\mathbf{y}\\) outcome column vector. Note weights scaled sum 1 (.e., \\(\\sum_i w_{ii} = 1\\)). easy way get compute \\(\\widehat{\\mathbf{\\beta}}\\) first weight \\(\\mathbf{X}\\) \\(\\mathbf{y}\\) \\(\\mathbf{W}^s\\), simply weight matrix using instead square root weights. Let’s define rescaled matrices \\[ \\begin{aligned} \\widetilde{\\mathbf{X}} &= \\mathbf{X} \\mathbf{W}^s \\\\ \\widetilde{\\mathbf{y}} &= \\mathbf{W}^s \\mathbf{y} \\end{aligned} \\]","code":""},{"path":"https://declaredesign.org/r/estimatr/articles/stata-wls-hat.html","id":"heteroskedastic-consistent-variance-estimators","dir":"Articles","previous_headings":"","what":"Heteroskedastic-consistent variance estimators","title":"How Stata's hat matrix differs with weights","text":"Turning variance, standard sandwich estimator \\[ \\mathbb{V}[\\widehat{\\mathbf{\\beta}}] = (\\mathbf{X}^{\\top}\\mathbf{X})^{-1} \\mathbf{X}^\\top \\Omega \\mathbf{X} (\\mathbf{X}^{\\top}\\mathbf{X})^{-1} \\] \\(\\Omega\\) represents \\(\\mathbb{E}[\\mathbf{\\epsilon}\\mathbf{\\epsilon}^\\top]\\), variance-covariance matrix disturbances. nice review different variance estimators along properties can found Long Ervin (2000) [ungated]. HC2 HC3 estimators, introduced MacKinnon White (1985), use hat matrix part estimation \\(\\Omega\\). standard hat matrix written: \\[ \\mathbf{H} = \\mathbf{X} (\\mathbf{X}^{\\top}\\mathbf{X})^{-1} \\mathbf{X}^\\top \\] \\(h_{ii}\\) diagonal elements hat matrix, HC2 variance estimator \\[ \\mathbb{V}[\\widehat{\\mathbf{\\beta}}]_{HC2} = (\\mathbf{X}^{\\top}\\mathbf{X})^{-1} \\mathbf{X}^\\top \\mathrm{diag}\\left[\\frac{e^2_i}{1 - h_{ii}}\\right] \\mathbf{X} (\\mathbf{X}^{\\top}\\mathbf{X})^{-1}  , \\] \\(e_i\\) residuals. HC3 estimator similar, \\[ \\mathbb{V}[\\widehat{\\mathbf{\\beta}}]_{HC3} = (\\mathbf{X}^{\\top}\\mathbf{X})^{-1} \\mathbf{X}^\\top \\mathrm{diag}\\left[\\frac{e^2_i}{(1 - h_{ii})^2}\\right] \\mathbf{X} (\\mathbf{X}^{\\top}\\mathbf{X})^{-1} . \\] rely hat matrix. Crucially, Stata packages modules R Python disagree. weights specified, Stata estimates hat matrix \\[ \\mathbf{H}_{Stata} = \\mathbf{X} (\\mathbf{X}^{\\top}\\mathbf{W}\\mathbf{X})^{-1} \\mathbf{X}^\\top, \\] software uses \\[ \\mathbf{H}_{R} = \\mathbf{X} (\\mathbf{X}^{\\top}\\mathbf{W}\\mathbf{X})^{-1} \\mathbf{X}^\\top \\mathbf{W}. \\] Thus HC2 HC3 estimator differ values \\(h_{ii}\\) quite different. different results? Let’s use little example using mtcars dataset included R. can also see Python’s statsmodels provides results methods R (fact note difference issue GitHub). Stata 13, get following output: Stata’s standard errors somewhat different. documentation Stata’s formula hat matrix can found statalist forum nowhere official documentation far can tell.","code":"# Using estimatr library(estimatr) lm_robust(   mpg ~ hp,   data = mtcars,   weights = wt,   se_type = \"HC2\" ) #>                Estimate Std. Error   t value     Pr(>|t|)    CI Lower #> (Intercept) 28.54864505 2.16281844 13.199742 4.975934e-14 24.13158053 #> hp          -0.06249413 0.01445662 -4.322872 1.561752e-04 -0.09201849 #>                CI Upper DF #> (Intercept) 32.96570958 30 #> hp          -0.03296977 30 import statsmodels.api as sm import pandas as pd dat = pd.read_csv('mtcars.csv') wls_mod = sm.WLS(dat['mpg'], sm.add_constant(dat['hp']), weights = dat['wt']) print(wls_mod.fit().HC2_se) #> const    2.162818 #> hp       0.014457 #> dtype: float64 insheet using mtcars.csv reg mpg hp [aweight=wt], vce(hc2) Linear regression                                      Number of obs =      32                                                        F(  1,    30) =   19.08                                                        Prob > F      =  0.0001                                                        R-squared     =  0.5851                                                        Root MSE      =  3.6191  ------------------------------------------------------------------------------              |             Robust HC2          mpg |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval] -------------+----------------------------------------------------------------           hp |  -.0624941   .0143083    -4.37   0.000    -.0917155   -.0332727        _cons |   28.54865   2.155169    13.25   0.000      24.1472    32.95009 ------------------------------------------------------------------------------"},{"path":"https://declaredesign.org/r/estimatr/articles/stata-wls-hat.html","id":"which-should-we-prefer","dir":"Articles","previous_headings":"Heteroskedastic-consistent variance estimators","what":"Which should we prefer?","title":"How Stata's hat matrix differs with weights","text":"Just Stata documenting HC2 HC3 estimator mean ’re wrong. Also differences tend minor. fact, unclear prefer given strong literature supporting one . However, several arguments made \\(\\mathbf{H}_{R}\\). ’s estimator get weight data square root weights (\\(\\mathbf{X} \\rightarrow \\widetilde{\\mathbf{X}}\\) \\(\\mathbf{y} \\rightarrow \\widetilde{\\mathbf{y}}\\)) fit regular ordinary least squares. one considers weighted model simply rescaled version unweighted model, users prefer \\(\\mathbf{H}_{R}\\). diagonal \\(\\mathbf{H}_{R}\\) weighted leverages (Li Valliant 2009), \\(\\mathbf{H}_{Stata}\\) need weighted diagonal recover weighted leverage.","code":""},{"path":"https://declaredesign.org/r/estimatr/articles/stata-wls-hat.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"How Stata's hat matrix differs with weights","text":"Li, Jianzhu, Richard Valliant. 2009. “Survey Weighted Hat Matrix Leverages.” Survey Methodology 35 (1): 15–24. Long, J Scott, Laurie H Ervin. 2000. “Using Heteroscedasticity Consistent Standard Errors Linear Regression Model.” American Statistician 54 (3): 217–24. https://doi.org/10.1080/00031305.2000.10474549. MacKinnon, James, Halbert White. 1985. “Heteroskedasticity-Consistent Covariance Matrix Estimators Improved Finite Sample Properties.” Journal Econometrics 29 (3): 305–25. https://doi.org/10.1016/0304-4076(85)90158-7.","code":""},{"path":"https://declaredesign.org/r/estimatr/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Graeme Blair. Author, maintainer. Jasper Cooper. Author. Alexander Coppock. Author. Macartan Humphreys. Author. Luke Sonnet. Author. Neal Fultz. Contributor. Lily Medina. Contributor. Russell Lenth. Contributor.","code":""},{"path":"https://declaredesign.org/r/estimatr/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Blair G, Cooper J, Coppock , Humphreys M, Sonnet L (2024). estimatr: Fast Estimators Design-Based Inference. R package version 1.0.0, https://github.com/DeclareDesign/estimatr, https://declaredesign.org/r/estimatr/.","code":"@Manual{,   title = {estimatr: Fast Estimators for Design-Based Inference},   author = {Graeme Blair and Jasper Cooper and Alexander Coppock and Macartan Humphreys and Luke Sonnet},   year = {2024},   note = {R package version 1.0.0, https://github.com/DeclareDesign/estimatr},   url = {https://declaredesign.org/r/estimatr/}, }"},{"path":"https://declaredesign.org/r/estimatr/index.html","id":"estimatr-fast-estimators-for-design-based-inference","dir":"","previous_headings":"","what":"Fast Estimators for Design-Based Inference","title":"Fast Estimators for Design-Based Inference","text":"estimatr R package providing range commonly-used linear estimators, designed speed ease--use. Users can easily recover robust, cluster-robust, design appropriate estimates. include two functions implement means estimators, difference_in_means() horvitz_thompson(), three linear regression estimators, lm_robust(), lm_lin(), iv_robust(). case, users can choose estimator reflect cluster-randomized, block-randomized, block--cluster-randomized designs. Getting Started Guide describes estimator provided estimatr can used analysis. can also see multiple ways can get regression tables estimatr using commonly used R packages texreg stargazer. Fast estimators also enable fast simulation research designs learn properties (see DeclareDesign).","code":""},{"path":"https://declaredesign.org/r/estimatr/index.html","id":"installing-estimatr","dir":"","previous_headings":"","what":"Installing estimatr","title":"Fast Estimators for Design-Based Inference","text":"install latest stable release estimatr, please ensure running version 3.5 later R run following code:","code":"install.packages(\"estimatr\")"},{"path":"https://declaredesign.org/r/estimatr/index.html","id":"easy-to-use","dir":"","previous_headings":"","what":"Easy to use","title":"Fast Estimators for Design-Based Inference","text":"package installed, getting appropriate estimates standard errors now fast easy. Getting Started Guide examples uses, reference pages. Mathematical Notes provide information estimator hood.","code":"library(estimatr)  # sample data from cluster-randomized experiment library(fabricatr) library(randomizr) dat <- fabricate(   N = 100,   y = rnorm(N),   clusterID = sample(letters[1:10], size = N, replace = TRUE),   z = cluster_ra(clusterID) )  # robust standard errors res_rob <- lm_robust(y ~ z, data = dat) # tidy dataframes on command! tidy(res_rob) #>          term estimate std.error statistic p.value conf.low conf.high df #> 1 (Intercept)    0.065      0.14      0.46    0.64    -0.21      0.34 98 #> 2           z   -0.067      0.21     -0.32    0.75    -0.48      0.35 98 #>   outcome #> 1       y #> 2       y  # cluster robust standard errors res_cl <- lm_robust(y ~ z, data = dat, clusters = clusterID) # standard summary view also available summary(res_cl) #>  #> Call: #> lm_robust(formula = y ~ z, data = dat, clusters = clusterID) #>  #> Standard error type:  CR2  #>  #> Coefficients: #>             Estimate Std. Error t value Pr(>|t|) CI Lower CI Upper   DF #> (Intercept)   0.0653      0.145   0.452    0.678   -0.358    0.489 3.53 #> z            -0.0670      0.202  -0.331    0.750   -0.544    0.410 7.05 #>  #> Multiple R-squared:  0.00105 ,   Adjusted R-squared:  -0.00915  #> F-statistic: 0.11 on 1 and 9 DF,  p-value: 0.748  # matched-pair design learned from blocks argument data(sleep) res_dim <- difference_in_means(extra ~ group, data = sleep, blocks = ID)"},{"path":"https://declaredesign.org/r/estimatr/index.html","id":"fast-to-use","dir":"","previous_headings":"","what":"Fast to use","title":"Fast Estimators for Design-Based Inference","text":"Getting estimates robust standard errors also faster used . Compare package using lm() sandwich package get HC2 standard errors. speed comparisons available . Furthermore, many blocks (fixed effects), users can use fixed_effects argument lm_robust HC1 standard errors greatly improve estimation speed. fixed effects . project generously supported grant Laura John Arnold Foundation seed funding Evidence Governance Politics (EGAP).","code":"dat <- data.frame(X = matrix(rnorm(2000*50), 2000), y = rnorm(2000))  library(microbenchmark) library(lmtest) library(sandwich) mb <- microbenchmark(   `estimatr` = lm_robust(y ~ ., data = dat),   `lm + sandwich` = {     lo <- lm(y ~ ., data = dat)     coeftest(lo, vcov = vcovHC(lo, type = 'HC2'))   } ) #> Warning in microbenchmark(estimatr = lm_robust(y ~ ., data = dat), `lm + #> sandwich` = {: less accurate nanosecond times to avoid potential integer #> overflows"},{"path":"https://declaredesign.org/r/estimatr/reference/alo_star_men.html","id":null,"dir":"Reference","previous_headings":"","what":"Replication data for Lin 2013 — alo_star_men","title":"Replication data for Lin 2013 — alo_star_men","text":"dataset containing data replicate: Lin, Winston. 2013. \"Agnostic notes regression adjustments experimental data: Reexamining Freedman's critique.\" Annals Applied Statistics. Stat. 7(1): 295-318. doi:10.1214/12-AOAS583. https://projecteuclid.org/euclid.aoas/1365527200.","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/alo_star_men.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Replication data for Lin 2013 — alo_star_men","text":"","code":"alo_star_men"},{"path":"https://declaredesign.org/r/estimatr/reference/alo_star_men.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Replication data for Lin 2013 — alo_star_men","text":"data frame educational treatments outcomes: gpa0 high school GPA sfsp financial incentives support treatment ssp support treatment GPA_year1 college GPA year 1 GPA_year2 college GPA year 2","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/alo_star_men.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Replication data for Lin 2013 — alo_star_men","text":"https://www.aeaweb.org/articles?id=10.1257/app.1.1.136","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/alo_star_men.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Replication data for Lin 2013 — alo_star_men","text":"data originally taken following paper, subset men showed college, one arms support condition, GPA data first year college. Angrist, Joshua, Daniel Lang, Philip Oreopoulos. 2009. \"Incentives Services College Achievement: Evidence Randomized Trial.\" American Economic Journal: Applied Economics 1(1): 136-63. https://www.aeaweb.org/articles?id=10.1257/app.1.1.136","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/commarobust.html","id":null,"dir":"Reference","previous_headings":"","what":"Build lm_robust object from lm fit — commarobust","title":"Build lm_robust object from lm fit — commarobust","text":"Build lm_robust object lm fit","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/commarobust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build lm_robust object from lm fit — commarobust","text":"","code":"commarobust(model, se_type = NULL, clusters = NULL, ci = TRUE, alpha = 0.05)"},{"path":"https://declaredesign.org/r/estimatr/reference/commarobust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build lm_robust object from lm fit — commarobust","text":"model lm model object se_type sort standard error sought. clusters specified options \"HC0\", \"HC1\" (\"stata\", equivalent), \"HC2\" (default), \"HC3\", \"classical\". clusters specified options \"CR0\", \"CR2\" (default), \"stata\". Can also specify \"none\", may speed estimation coefficients. clusters vector corresponding clusters data. ci logical. Whether compute return p-values confidence intervals, TRUE default. alpha significance level, 0.05 default.","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/commarobust.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build lm_robust object from lm fit — commarobust","text":"lm_robust object.","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/commarobust.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build lm_robust object from lm fit — commarobust","text":"","code":"lmo <- lm(mpg ~ hp, data = mtcars)  # Default HC2 commarobust(lmo) #>                Estimate Std. Error   t value    Pr(>|t|)    CI Lower #> (Intercept) 30.09886054 2.19301194 13.724896 1.81366e-14 25.62013267 #> hp          -0.06822828 0.01471473 -4.636732 6.48546e-05 -0.09827977 #>                CI Upper DF #> (Intercept) 34.57758841 30 #> hp          -0.03817678 30  commarobust(lmo, se_type = \"HC3\") #>                Estimate Std. Error   t value     Pr(>|t|)   CI Lower #> (Intercept) 30.09886054 2.41006671 12.488808 2.044330e-13 25.1768477 #> hp          -0.06822828 0.01660193 -4.109659 2.822529e-04 -0.1021339 #>                CI Upper DF #> (Intercept) 35.02087341 30 #> hp          -0.03432261 30  commarobust(lmo, se_type = \"stata\", clusters = mtcars$carb) #>                Estimate Std. Error   t value     Pr(>|t|)   CI Lower #> (Intercept) 30.09886054 2.15609050 13.959924 3.390807e-05 24.5564535 #> hp          -0.06822828 0.01404901 -4.856449 4.647551e-03 -0.1043424 #>                CI Upper DF #> (Intercept) 35.64126761  5 #> hp          -0.03211416  5"},{"path":"https://declaredesign.org/r/estimatr/reference/declaration_to_condition_pr_mat.html","id":null,"dir":"Reference","previous_headings":"","what":"Builds condition probability matrices for Horvitz-Thompson estimation from\nrandomizr declaration — declaration_to_condition_pr_mat","title":"Builds condition probability matrices for Horvitz-Thompson estimation from\nrandomizr declaration — declaration_to_condition_pr_mat","text":"Builds condition probability matrices Horvitz-Thompson estimation randomizr declaration","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/declaration_to_condition_pr_mat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Builds condition probability matrices for Horvitz-Thompson estimation from\nrandomizr declaration — declaration_to_condition_pr_mat","text":"","code":"declaration_to_condition_pr_mat(   ra_declaration,   condition1 = NULL,   condition2 = NULL,   prob_matrix = NULL )"},{"path":"https://declaredesign.org/r/estimatr/reference/declaration_to_condition_pr_mat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Builds condition probability matrices for Horvitz-Thompson estimation from\nrandomizr declaration — declaration_to_condition_pr_mat","text":"ra_declaration object class \"ra_declaration\", generated declare_ra function randomizr. object contains experimental design represented condition probability matrix condition1 name first condition, often control group. NULL, defaults first condition randomizr declaration. Either condition1 condition2 specified left NULL. condition2 name second condition, often treatment group. NULL, defaults second condition randomizr declaration. Either condition1 condition2 specified left NULL. prob_matrix optional probability matrix override one ra_declaration","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/declaration_to_condition_pr_mat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Builds condition probability matrices for Horvitz-Thompson estimation from\nrandomizr declaration — declaration_to_condition_pr_mat","text":"numeric 2n*2n matrix marginal joint condition treatment probabilities passed condition_pr_mat argument horvitz_thompson. See details.","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/declaration_to_condition_pr_mat.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Builds condition probability matrices for Horvitz-Thompson estimation from\nrandomizr declaration — declaration_to_condition_pr_mat","text":"function takes \"ra_declaration\", generated declare_ra function randomizr returns 2n*2n matrix can used fully specify design horvitz_thompson estimation. done passing matrix condition_pr_mat argument horvitz_thompson. Currently, function can learn condition probability matrix wide variety randomizations: simple, complete, simple clustered, complete clustered, blocked, block-clustered. condition probability matrix made four submatrices, corresponds joint marginal probability observation one two treatment conditions. upper-left quadrant n*n matrix. diagonal marginal probability condition 1, often control, every unit (Pr(Z_i = Condition1) Z represents vector treatment conditions). -diagonal elements joint probabilities unit condition 1 unit, Pr(Z_i = Condition1, Z_j = Condition1) indexes rows j indexes columns. upper-right quadrant also n*n matrix. diagonal joint probability unit condition 1 condition 2, often treatment, thus always 0. -diagonal elements joint probability unit condition 1 unit j condition 2, Pr(Z_i = Condition1, Z_j = Condition2). lower-left quadrant also n*n matrix. diagonal joint probability unit condition 1 condition 2, thus always 0. -diagonal elements joint probability unit condition 2 unit j condition 1, Pr(Z_i = Condition2, Z_j = Condition1). lower-right quadrant n*n matrix. diagonal marginal probability condition 2, often treatment, every unit (Pr(Z_i = Condition2)). -diagonal elements joint probability unit condition 2 together, Pr(Z_i = Condition2, Z_j = Condition2).","code":""},{"path":[]},{"path":"https://declaredesign.org/r/estimatr/reference/declaration_to_condition_pr_mat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Builds condition probability matrices for Horvitz-Thompson estimation from\nrandomizr declaration — declaration_to_condition_pr_mat","text":"","code":"# Learn condition probability matrix from complete blocked design library(randomizr) n <- 100 dat <- data.frame(   blocks = sample(letters[1:10], size = n, replace = TRUE),   y = rnorm(n) )  # Declare complete blocked randomization bl_declaration <- declare_ra(blocks = dat$blocks, prob = 0.4, simple = FALSE) # Get probabilities block_pr_mat <- declaration_to_condition_pr_mat(bl_declaration, 0, 1) # Do randomiztion dat$z <- conduct_ra(bl_declaration)  horvitz_thompson(y ~ z, data = dat, condition_pr_mat = block_pr_mat) #>     Estimate Std. Error    t value  Pr(>|t|)   CI Lower  CI Upper DF #> z -0.1744343  0.2227431 -0.7831187 0.4335574 -0.6110028 0.2621342 NA  # When you pass a declaration to horvitz_thompson, this function is called  # Equivalent to above call horvitz_thompson(y ~ z, data = dat, ra_declaration = bl_declaration) #>     Estimate Std. Error    t value  Pr(>|t|)   CI Lower  CI Upper DF #> z -0.1744343  0.2227431 -0.7831187 0.4335574 -0.6110028 0.2621342 NA"},{"path":"https://declaredesign.org/r/estimatr/reference/difference_in_means.html","id":null,"dir":"Reference","previous_headings":"","what":"Design-based difference-in-means estimator — difference_in_means","title":"Design-based difference-in-means estimator — difference_in_means","text":"Difference--means estimators selects appropriate point estimate, standard errors, degrees freedom variety designs: unit randomized, cluster randomized, block randomized, block-cluster randomized, matched-pairs, matched-pair cluster randomized designs","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/difference_in_means.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Design-based difference-in-means estimator — difference_in_means","text":"","code":"difference_in_means(   formula,   data,   blocks,   clusters,   weights,   subset,   se_type = c(\"default\", \"none\"),   condition1 = NULL,   condition2 = NULL,   ci = TRUE,   alpha = 0.05 )"},{"path":"https://declaredesign.org/r/estimatr/reference/difference_in_means.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Design-based difference-in-means estimator — difference_in_means","text":"formula object class formula, lm, Y ~ Z one variable right-hand side, treatment. data data.frame. blocks optional bare (unquoted) name block variable. Use blocked designs . clusters optional bare (unquoted) name variable corresponds clusters data; used cluster randomized designs. blocked designs, clusters must nest within blocks. weights bare (unquoted) names weights variable supplied data. subset optional bare (unquoted) expression specifying subset observations used. se_type optional string can one c(\"default\", \"none\"). \"default\" (default), use default standard error estimator design, \"none\" standard errors computed may speed run time point estimate required. condition1 value treatment vector condition control. Effects estimated condition1 control condition2 treatment. unspecified, condition1 \"first\" condition condition2 \"second\" according levels treatment factor according sortif numeric character variable (.e unspecified treatment 0s 1s, condition1 default 0 condition2 1). See examples . condition2 value treatment vector condition treatment. See condition1. ci logical. Whether compute return p-values confidence intervals, TRUE default. alpha significance level, 0.05 default.","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/difference_in_means.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Design-based difference-in-means estimator — difference_in_means","text":"Returns object class \"difference_in_means\". post-estimation commands functions summary tidy return results data.frame. get useful data return, can use data frames, can use resulting list directly, can use generic accessor functions coef confint. object class \"difference_in_means\" list containing least following components: coefficients estimated difference means std.error estimated standard error statistic t-statistic df estimated degrees freedom p.value p-value two-sided t-test using coefficients, std.error, df conf.low lower bound 1 - alpha percent confidence interval conf.high upper bound 1 - alpha percent confidence interval term character vector coefficient names alpha significance level specified user N number observations used outcome name outcome variable design name design learned arguments passed","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/difference_in_means.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Design-based difference-in-means estimator — difference_in_means","text":"function implements difference--means estimator, support blocked, clustered, matched-pairs, block-clustered, matched-pair clustered designs. One specifies design passing blocks clusters data function chooses estimator appropriate. pass blocks, blocks size two, infer design matched-pairs design. size four larger, infer regular blocked design. pass blocks clusters, similarly infer whether matched-pairs clustered design block-clustered design number clusters per block. user passes clusters, infer design cluster-randomized. user specifies neither blocks clusters, regular Welch's t-test performed. Importantly, user specifies weights, estimation handed lm_robust appropriate robust standard errors weighted difference--means estimators implemented . details estimators can found mathematical notes.","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/difference_in_means.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Design-based difference-in-means estimator — difference_in_means","text":"Gerber, Alan S, Donald P Green. 2012. Field Experiments: Design, Analysis, Interpretation. New York: W.W. Norton. Imai, Kosuke, Gary King, Clayton Nall. 2009. \"Essential Role Pair Matching Cluster-Randomized Experiments, Application Mexican Universal Health Insurance Evaluation.\" Statistical Science 24 (1). Institute Mathematical Statistics: 29-53. doi:10.1214/08-STS274 .","code":""},{"path":[]},{"path":"https://declaredesign.org/r/estimatr/reference/difference_in_means.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Design-based difference-in-means estimator — difference_in_means","text":"","code":"library(fabricatr) library(randomizr) # Get appropriate standard errors for unit-randomized designs  # ---------- # 1. Unit randomized # ---------- dat <- fabricate(   N = 100,   Y = rnorm(100),   Z_comp = complete_ra(N, prob = 0.4), )  table(dat$Z_comp) #>  #>  0  1  #> 60 40  difference_in_means(Y ~ Z_comp, data = dat) #> Design:  Standard  #>          Estimate Std. Error t value  Pr(>|t|)   CI Lower  CI Upper       DF #> Z_comp 0.02822768  0.2128302 0.13263 0.8947893 -0.3947386 0.4511939 87.83788  # ---------- # 2. Cluster randomized # ---------- # Accurates estimates and standard errors for clustered designs dat$clust <- sample(20, size = nrow(dat), replace = TRUE) dat$Z_clust <- cluster_ra(dat$clust, prob = 0.6)  table(dat$Z_clust, dat$clust) #>     #>     1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 #>   0 5 0 4 0 5 0 0 2 7  0  0  0  4  0  0  0  0  0  5  3 #>   1 0 5 0 5 0 7 5 0 0  7  6  6  0  7  5  5  3  4  0  0 summary(difference_in_means(Y ~ Z_clust, clusters = clust, data = dat)) #> $coefficients #>            Estimate Std. Error     t value  Pr(>|t|)   CI Lower  CI Upper #> Z_clust -0.01514775  0.2606826 -0.05810801 0.9545717 -0.5799884 0.5496929 #>               DF #> Z_clust 12.63249 #>  #> $design #> [1] \"Clustered\" #>   # ---------- # 3. Block randomized # ---------- dat$block <- rep(1:10, each = 10) dat$Z_block <- block_ra(dat$block, prob = 0.5)  table(dat$Z_block, dat$block) #>     #>     1 2 3 4 5 6 7 8 9 10 #>   0 5 5 5 5 5 5 5 5 5  5 #>   1 5 5 5 5 5 5 5 5 5  5 difference_in_means(Y ~ Z_block, blocks = block, data = dat) #> Design:  Blocked  #>            Estimate Std. Error    t value  Pr(>|t|)   CI Lower  CI Upper DF #> Z_block -0.08359831  0.2077124 -0.4024715 0.6884105 -0.4969591 0.3297625 80  # ---------- # 4. Block cluster randomized # ---------- # Learns this design if there are two clusters per block dat$small_clust <- rep(1:50, each = 2) dat$big_blocks <- rep(1:5, each = 10)  dat$Z_blcl <- block_and_cluster_ra(   blocks = dat$big_blocks,   clusters = dat$small_clust  )  difference_in_means(   Y ~ Z_blcl,   blocks = big_blocks,   clusters = small_clust,   data = dat  ) #> Design:  Block-clustered  #>          Estimate Std. Error   t value  Pr(>|t|)   CI Lower  CI Upper DF #> Z_blcl 0.09845335  0.2098115 0.4692467 0.6414411 -0.3255915 0.5224982 40  # ---------- # 5. Matched-pairs # ---------- # Matched-pair estimates and standard errors are also accurate # Specified same as blocked design, function learns that # it is matched pair from size of blocks! dat$pairs <- rep(1:50, each = 2) dat$Z_pairs <- block_ra(dat$pairs, prob = 0.5)  table(dat$pairs, dat$Z_pairs) #>      #>      0 1 #>   1  1 1 #>   2  1 1 #>   3  1 1 #>   4  1 1 #>   5  1 1 #>   6  1 1 #>   7  1 1 #>   8  1 1 #>   9  1 1 #>   10 1 1 #>   11 1 1 #>   12 1 1 #>   13 1 1 #>   14 1 1 #>   15 1 1 #>   16 1 1 #>   17 1 1 #>   18 1 1 #>   19 1 1 #>   20 1 1 #>   21 1 1 #>   22 1 1 #>   23 1 1 #>   24 1 1 #>   25 1 1 #>   26 1 1 #>   27 1 1 #>   28 1 1 #>   29 1 1 #>   30 1 1 #>   31 1 1 #>   32 1 1 #>   33 1 1 #>   34 1 1 #>   35 1 1 #>   36 1 1 #>   37 1 1 #>   38 1 1 #>   39 1 1 #>   40 1 1 #>   41 1 1 #>   42 1 1 #>   43 1 1 #>   44 1 1 #>   45 1 1 #>   46 1 1 #>   47 1 1 #>   48 1 1 #>   49 1 1 #>   50 1 1 difference_in_means(Y ~ Z_pairs, blocks = pairs, data = dat) #> Design:  Matched-pair  #>            Estimate Std. Error    t value  Pr(>|t|)   CI Lower  CI Upper DF #> Z_pairs -0.09532749   0.212814 -0.4479381 0.6561722 -0.5229932 0.3323383 49  # ---------- # 6. Matched-pair cluster randomized # ---------- # Learns this design if there are two clusters per block dat$small_clust <- rep(1:50, each = 2) dat$cluster_pairs <- rep(1:25, each = 4) table(dat$cluster_pairs, dat$small_clust) #>      #>      1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 #>   1  2 2 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #>   2  0 0 2 2 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #>   3  0 0 0 0 2 2 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #>   4  0 0 0 0 0 0 2 2 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #>   5  0 0 0 0 0 0 0 0 2  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #>   6  0 0 0 0 0 0 0 0 0  0  2  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #>   7  0 0 0 0 0 0 0 0 0  0  0  0  2  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #>   8  0 0 0 0 0 0 0 0 0  0  0  0  0  0  2  2  0  0  0  0  0  0  0  0  0  0  0  0 #>   9  0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  2  2  0  0  0  0  0  0  0  0  0  0 #>   10 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  2  2  0  0  0  0  0  0  0  0 #>   11 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  2  2  0  0  0  0  0  0 #>   12 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  2  0  0  0  0 #>   13 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  2  0  0 #>   14 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  2 #>   15 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #>   16 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #>   17 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #>   18 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #>   19 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #>   20 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #>   21 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #>   22 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #>   23 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #>   24 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #>   25 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #>      #>      29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 #>   1   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #>   2   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #>   3   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #>   4   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #>   5   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #>   6   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #>   7   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #>   8   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #>   9   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #>   10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #>   11  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #>   12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #>   13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #>   14  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #>   15  2  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #>   16  0  0  2  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #>   17  0  0  0  0  2  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #>   18  0  0  0  0  0  0  2  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0 #>   19  0  0  0  0  0  0  0  0  2  2  0  0  0  0  0  0  0  0  0  0  0  0 #>   20  0  0  0  0  0  0  0  0  0  0  2  2  0  0  0  0  0  0  0  0  0  0 #>   21  0  0  0  0  0  0  0  0  0  0  0  0  2  2  0  0  0  0  0  0  0  0 #>   22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  2  0  0  0  0  0  0 #>   23  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  2  0  0  0  0 #>   24  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  2  0  0 #>   25  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  2  dat$Z_mpcl <- block_and_cluster_ra(   blocks = dat$cluster_pairs,   clusters = dat$small_clust  )  difference_in_means(   Y ~ Z_mpcl,   blocks = cluster_pairs,   clusters = small_clust,   data = dat  ) #> Design:  Matched-pair clustered  #>         Estimate Std. Error   t value  Pr(>|t|)   CI Lower  CI Upper DF #> Z_mpcl 0.1760208  0.2335122 0.7537972 0.4583032 -0.3059246 0.6579662 24  # ---------- # Other examples # ----------  # Also works with multi-valued treatments if users specify # comparison of interest dat$Z_multi <- simple_ra(   nrow(dat),   conditions = c(\"Treatment 2\", \"Treatment 1\", \"Control\"),   prob_each = c(0.4, 0.4, 0.2) )  # Only need to specify which condition is treated `condition2` and # which is control `condition1` difference_in_means(   Y ~ Z_multi,   condition1 = \"Treatment 2\",   condition2 = \"Control\",   data = dat ) #> Design:  Standard  #>                Estimate Std. Error   t value  Pr(>|t|) CI Lower  CI Upper #> Z_multiControl -0.36965  0.3302006 -1.119471 0.2731941 -1.04845 0.3091496 #>                      DF #> Z_multiControl 25.95082 difference_in_means(   Y ~ Z_multi,   condition1 = \"Treatment 1\",   condition2 = \"Control\",   data = dat ) #> Design:  Standard  #>                   Estimate Std. Error    t value  Pr(>|t|)   CI Lower  CI Upper #> Z_multiControl -0.04375527   0.330429 -0.1324196 0.8956773 -0.7231372 0.6356266 #>                      DF #> Z_multiControl 25.86285  # Specifying weights will result in estimation via lm_robust() dat$w <- runif(nrow(dat)) difference_in_means(Y ~ Z_comp, weights = w, data = dat) #> Design:  Standard (weighted)  #>          Estimate Std. Error    t value  Pr(>|t|)   CI Lower CI Upper DF #> Z_comp -0.1020411  0.2483971 -0.4107981 0.6821174 -0.5949771 0.390895 98 lm_robust(Y ~ Z_comp, weights = w, data = dat) #>               Estimate Std. Error    t value  Pr(>|t|)   CI Lower  CI Upper DF #> (Intercept)  0.2047595  0.1670486  1.2257484 0.2232309 -0.1267430 0.5362621 98 #> Z_comp      -0.1020411  0.2483971 -0.4107981 0.6821174 -0.5949771 0.3908950 98"},{"path":"https://declaredesign.org/r/estimatr/reference/estimatr.html","id":null,"dir":"Reference","previous_headings":"","what":"estimatr — estimatr","title":"estimatr — estimatr","text":"Fast procedures small set commonly-used, design-appropriate estimators robust standard errors confidence intervals. Includes estimators linear regression, instrumental variables regression, difference--means, Horvitz-Thompson estimation, regression improving precision experimental estimates interacting treatment centered pre-treatment covariates introduced Lin (2013) <doi:10.1214/12-AOAS583>.","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/estimatr_glancers.html","id":null,"dir":"Reference","previous_headings":"","what":"Glance at an estimatr object — estimatr_glancers","title":"Glance at an estimatr object — estimatr_glancers","text":"Glance estimatr object","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/estimatr_glancers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Glance at an estimatr object — estimatr_glancers","text":"","code":"# S3 method for lm_robust glance(x, ...)  # S3 method for lh_robust glance(x, ...)  # S3 method for iv_robust glance(x, ...)  # S3 method for difference_in_means glance(x, ...)  # S3 method for horvitz_thompson glance(x, ...)"},{"path":"https://declaredesign.org/r/estimatr/reference/estimatr_glancers.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Glance at an estimatr object — estimatr_glancers","text":"x object returned one estimators ... extra arguments (used)","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/estimatr_glancers.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Glance at an estimatr object — estimatr_glancers","text":"glance.lm_robust, data.frame columns: r.squared \\(R^2\\), $$R^2 = 1 - Sum(e[]^2) / Sum((y[] - y^*)^2),$$ \\(y^*\\) mean \\(y[]\\) intercept zero otherwise, \\(e[]\\) ith residual. adj.r.squared \\(R^2\\) penalized parameters, rank se_type standard error type specified user statistic value F-statistic p.value p-value F test df.residual residual degrees freedom nobs number observations used glance.lh_robust, glance lm_robust component . can access linear hypotheses data.frame directy lh component lh_robust object glance.iv_robust, data.frame columns: r.squared \\(R^2\\) second stage regression adj.r.squared \\(R^2\\) penalized parameters, rank df.residual residual degrees freedom N number observations used se_type standard error type specified user statistic value F-statistic p.value p-value F test statistic.weakinst value first stage F-statistic, useful weak instruments test; reported one endogenous variable p.value.weakinst p-value first-stage F test, test weak instruments; reported one endogenous variable statistic.endogeneity value F-statistic test endogeneity; often called Wu-Hausman statistic, robust standard errors, employ regression based test p.value.endogeneity p-value F-test endogeneity statistic.overid value chi-squared statistic test instrument correlation error term; reported overidentification p.value.overid p-value chi-squared test; reported overidentification glance.difference_in_means, data.frame columns: design design used, therefore estimator used df degrees freedom nobs number observations used nblocks number blocks, used nclusters number clusters, used condition2 second, \"treatment\", condition condition1 first, \"control\", condition glance.horvitz_thompson, data.frame columns: nobs number observations used se_type type standard error estimator used condition2 second, \"treatment\", condition condition1 first, \"control\", condition","code":""},{"path":[]},{"path":"https://declaredesign.org/r/estimatr/reference/estimatr_tidiers.html","id":null,"dir":"Reference","previous_headings":"","what":"Tidy an estimatr object — estimatr_tidiers","title":"Tidy an estimatr object — estimatr_tidiers","text":"Tidy estimatr object","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/estimatr_tidiers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tidy an estimatr object — estimatr_tidiers","text":"","code":"# S3 method for lm_robust tidy(x, conf.int = TRUE, conf.level = NULL, ...)  # S3 method for iv_robust tidy(x, conf.int = TRUE, conf.level = NULL, ...)  # S3 method for difference_in_means tidy(x, conf.int = TRUE, conf.level = NULL, ...)  # S3 method for horvitz_thompson tidy(x, conf.int = TRUE, conf.level = NULL, ...)  # S3 method for lh_robust tidy(x, conf.int = TRUE, conf.level = NULL, ...)  # S3 method for lh tidy(x, conf.int = TRUE, conf.level = NULL, ...)"},{"path":"https://declaredesign.org/r/estimatr/reference/estimatr_tidiers.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tidy an estimatr object — estimatr_tidiers","text":"x object returned one estimators conf.int Logical indicating whether include confidence interval tidied output. Defaults ‘TRUE’. conf.level confidence level use confidence interval ‘conf.int = TRUE’. Must strictly greater 0 less 1. Defaults 0.95, corresponds 95 percent confidence interval. ... extra arguments (used)","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/estimatr_tidiers.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tidy an estimatr object — estimatr_tidiers","text":"data.frame columns coefficient names, estimates, standard errors, confidence intervals, p-values, degrees freedom, name outcome variable","code":""},{"path":[]},{"path":"https://declaredesign.org/r/estimatr/reference/extract.lm_robust.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract model data for texreg package — extract.robust_default","title":"Extract model data for texreg package — extract.robust_default","text":"Prepares \"lm_robust\" \"iv_robust\" object texreg package. largely clone extract.lm method.","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/extract.lm_robust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract model data for texreg package — extract.robust_default","text":"","code":"extract.robust_default(   model,   include.ci = TRUE,   include.rsquared = TRUE,   include.adjrs = TRUE,   include.nobs = TRUE,   include.fstatistic = FALSE,   include.rmse = TRUE,   include.nclusts = TRUE,   ... )  extract.lm_robust(   model,   include.ci = TRUE,   include.rsquared = TRUE,   include.adjrs = TRUE,   include.nobs = TRUE,   include.fstatistic = FALSE,   include.rmse = TRUE,   include.nclusts = TRUE,   ... )  extract.iv_robust(   model,   include.ci = TRUE,   include.rsquared = TRUE,   include.adjrs = TRUE,   include.nobs = TRUE,   include.fstatistic = FALSE,   include.rmse = TRUE,   include.nclusts = TRUE,   ... )"},{"path":"https://declaredesign.org/r/estimatr/reference/extract.lm_robust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract model data for texreg package — extract.robust_default","text":"model object class lm_robust \"iv_robust\" include.ci logical. Defaults TRUE include.rsquared logical. Defaults TRUE include.adjrs logical. Defaults TRUE include.nobs logical. Defaults TRUE include.fstatistic logical. Defaults TRUE include.rmse logical. Defaults TRUE include.nclusts logical. Defaults TRUE clusters model ... unused","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/gen_pr_matrix_cluster.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate condition probability matrix given clusters and probabilities — gen_pr_matrix_cluster","title":"Generate condition probability matrix given clusters and probabilities — gen_pr_matrix_cluster","text":"Generate condition probability matrix given clusters probabilities","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/gen_pr_matrix_cluster.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate condition probability matrix given clusters and probabilities — gen_pr_matrix_cluster","text":"","code":"gen_pr_matrix_cluster(clusters, treat_probs, simple)"},{"path":"https://declaredesign.org/r/estimatr/reference/gen_pr_matrix_cluster.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate condition probability matrix given clusters and probabilities — gen_pr_matrix_cluster","text":"clusters vector clusters treat_probs vector treatment (condition 2) probabilities simple boolean whether assignment random sample assignment (TRUE, default) complete random assignment (FALSE)","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/gen_pr_matrix_cluster.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate condition probability matrix given clusters and probabilities — gen_pr_matrix_cluster","text":"numeric 2n*2n matrix marginal joint condition treatment probabilities passed condition_pr_mat argument horvitz_thompson.","code":""},{"path":[]},{"path":"https://declaredesign.org/r/estimatr/reference/horvitz_thompson.html","id":null,"dir":"Reference","previous_headings":"","what":"Horvitz-Thompson estimator for two-armed trials — horvitz_thompson","title":"Horvitz-Thompson estimator for two-armed trials — horvitz_thompson","text":"Horvitz-Thompson estimators unbiased designs randomization scheme known","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/horvitz_thompson.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Horvitz-Thompson estimator for two-armed trials — horvitz_thompson","text":"","code":"horvitz_thompson(   formula,   data,   blocks,   clusters,   simple = NULL,   condition_prs,   condition_pr_mat = NULL,   ra_declaration = NULL,   subset,   condition1 = NULL,   condition2 = NULL,   se_type = c(\"youngs\", \"constant\", \"none\"),   ci = TRUE,   alpha = 0.05,   return_condition_pr_mat = FALSE )"},{"path":"https://declaredesign.org/r/estimatr/reference/horvitz_thompson.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Horvitz-Thompson estimator for two-armed trials — horvitz_thompson","text":"formula object class formula, lm, Y ~ Z one variable right-hand side, treatment. data data.frame. blocks optional bare (unquoted) name block variable. Use blocked designs . See details. clusters optional bare (unquoted) name variable corresponds clusters data; used cluster randomized designs. blocked designs, clusters must within blocks. simple logical, optional. Whether randomization simple (TRUE) complete (FALSE). ignored blocks specified, blocked designs use complete randomization, either ra_declaration condition_pr_mat passed. Otherwise, defaults TRUE. condition_prs optional bare (unquoted) name variable condition 2 (treatment) probabilities. See details. May also use single number condition 2 probability constant. condition_pr_mat optional 2n * 2n matrix marginal joint probabilities units condition1 condition2. See details. ra_declaration object class \"ra_declaration\", declare_ra function randomizr package. third way one can specify design estimator. used along condition_prs, blocks, clusters, condition_pr_mat. See details. subset optional bare (unquoted) expression specifying subset observations used. condition1 value treatment vector condition control. Effects estimated condition1 control condition2 treatment. unspecified, condition1 \"first\" condition condition2 \"second\" according levels treatment factor according sortif numeric character variable (.e unspecified treatment 0s 1s, condition1 default 0 condition2 1). See examples . condition2 value treatment vector condition treatment. See condition1. se_type can one c(\"youngs\", \"constant\", \"none\") corresponds estimator standard errors. Default estimator uses Young's inequality (conservative) uses constant treatment effects assumption works simple randomized designs moment. \"none\" standard errors computed may speed run time point estimate required. ci logical. Whether compute return p-values confidence intervals, TRUE default. alpha significance level, 0.05 default. return_condition_pr_mat logical. Whether return condition probability matrix. Returns NULL design simple randomization, FALSE default.","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/horvitz_thompson.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Horvitz-Thompson estimator for two-armed trials — horvitz_thompson","text":"Returns object class \"horvitz_thompson\". post-estimation commands functions summary tidy return results data.frame. get useful data return, can use data frames, can use resulting list directly, can use generic accessor functions coef confint. object class \"horvitz_thompson\" list containing least following components: coefficients estimated difference totals std.error estimated standard error statistic z-statistic df estimated degrees freedom p.value p-value two-sided z-test using coefficients std.error conf.low lower bound 1 - alpha percent confidence interval conf.high upper bound 1 - alpha percent confidence interval term character vector coefficient names alpha significance level specified user nobs number observations used outcome name outcome variable condition_pr_mat condition probability matrix return_condition_pr_mat TRUE","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/horvitz_thompson.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Horvitz-Thompson estimator for two-armed trials — horvitz_thompson","text":"function implements Horvitz-Thompson estimator treatment effects two-armed trials. estimator useful estimating unbiased treatment effects given randomization scheme long randomization scheme known. short, Horvitz-Thompson estimator essentially reweights unit probability observed condition. Pivotal estimation treatment effects using estimator marginal condition probabilities (.e., probability one unit particular treatment condition). Pivotal estimating variance variance whenever design complicated simple randomization, joint condition probabilities (.e., probabilities two units particular set treatment conditions, either different). estimator provide considers case two treatment conditions. Users interested details can see mathematical notes information references, see references . three distinct ways users can specify design function. preferred way use declare_ra function randomizr package. function takes several arguments, including blocks, clusters, treatment probabilities, whether randomization simple , . Passing outcome function, object class \"ra_declaration\" ra_declaration argument function, lead call declaration_to_condition_pr_mat function generates condition probability matrix needed estimate treatment effects standard errors. provide many examples done. second way pass names vectors data condition_prs, blocks, clusters. can specify whether randomization simple complete using simple argument. Note blocks specified randomization always treated complete. vectors, function learns build condition probability matrix used estimation. case condition_prs specified, function assumes probabilities marginal probability unit condition2 uses arguments (blocks, clusters, simple) learn rest design. users pass condition_prs, function learns probability condition2 data. , none arguments specified, assume simple randomization probability unit condition2 average units condition2. Similarly, learn block-level probability treatment within blocks looking mean number units condition2 condition_prs specified. third way pass condition_pr_mat directly. One can see object documentation declaration_to_condition_pr_mat permutations_to_condition_pr_mat. Essentially, 2n * 2n matrix allows users specify marginal joint marginal probabilities units conditions 1 2 arbitrary complexity. Users use option certain know .","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/horvitz_thompson.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Horvitz-Thompson estimator for two-armed trials — horvitz_thompson","text":"Aronow, Peter M, Joel Middleton. 2013. \"Class Unbiased Estimators Average Treatment Effect Randomized Experiments.\" Journal Causal Inference 1 (1): 135-54. http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.712.5830&rep=rep1&type=pdf. Aronow, Peter M, Cyrus Samii. 2017. \"Estimating Average Causal Effects Interference Units.\" Annals Applied Statistics, forthcoming. https://arxiv.org/abs/1305.6156v3. Middleton, Joel , Peter M Aronow. 2015. \"Unbiased Estimation Average Treatment Effect Cluster-Randomized Experiments.\" Statistics, Politics Policy 6 (1-2): 39-75. doi:10.1515/spp-2013-0002 .","code":""},{"path":[]},{"path":"https://declaredesign.org/r/estimatr/reference/horvitz_thompson.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Horvitz-Thompson estimator for two-armed trials — horvitz_thompson","text":"","code":"# Set seed set.seed(42)  # Simulate data n <- 10 dat <- data.frame(y = rnorm(n))  library(randomizr)  #---------- # 1. Simple random assignment #---------- dat$p <- 0.5 dat$z <- rbinom(n, size = 1, prob = dat$p)  # If you only pass condition_prs, we assume simple random sampling horvitz_thompson(y ~ z, data = dat, condition_prs = p) #>     Estimate Std. Error    t value Pr(>|t|)  CI Lower  CI Upper DF #> z -0.2532128   0.609167 -0.4156706 0.677651 -1.447158 0.9407325 NA # Assume constant effects instead horvitz_thompson(y ~ z, data = dat, condition_prs = p, se_type = \"constant\") #>     Estimate Std. Error    t value  Pr(>|t|)  CI Lower CI Upper DF #> z -0.2532128  0.6038814 -0.4193088 0.6749904 -1.436799 0.930373 NA  # Also can use randomizr to pass a declaration srs_declaration <- declare_ra(N = nrow(dat), prob = 0.5, simple = TRUE) horvitz_thompson(y ~ z, data = dat, ra_declaration = srs_declaration) #>     Estimate Std. Error    t value Pr(>|t|)  CI Lower  CI Upper DF #> z -0.2532128   0.609167 -0.4156706 0.677651 -1.447158 0.9407325 NA  #---------- # 2. Complete random assignment #----------  dat$z <- sample(rep(0:1, each = n/2)) # Can use a declaration crs_declaration <- declare_ra(N = nrow(dat), prob = 0.5, simple = FALSE) horvitz_thompson(y ~ z, data = dat, ra_declaration = crs_declaration) #>     Estimate Std. Error   t value  Pr(>|t|)  CI Lower  CI Upper DF #> z -0.2312303  0.5310475 -0.435423 0.6632554 -1.272064 0.8096037 NA # Can precompute condition_pr_mat and pass it # (faster for multiple runs with same condition probability matrix) crs_pr_mat <- declaration_to_condition_pr_mat(crs_declaration) horvitz_thompson(y ~ z, data = dat, condition_pr_mat = crs_pr_mat) #>     Estimate Std. Error   t value  Pr(>|t|)  CI Lower  CI Upper DF #> z -0.2312303  0.5310475 -0.435423 0.6632554 -1.272064 0.8096037 NA  #---------- # 3. Clustered treatment, complete random assigment #----------- # Simulating data dat$cl <- rep(1:4, times = c(2, 2, 3, 3)) dat$prob <- 0.5 clust_crs_decl <- declare_ra(N = nrow(dat), clusters = dat$cl, prob = 0.5) dat$z <- conduct_ra(clust_crs_decl) # Easiest to specify using declaration ht_cl <- horvitz_thompson(y ~ z, data = dat, ra_declaration = clust_crs_decl) # Also can pass the condition probability and the clusters ht_cl_manual <- horvitz_thompson(   y ~ z,   data = dat,   clusters = cl,   condition_prs = prob,   simple = FALSE ) ht_cl #>    Estimate Std. Error   t value  Pr(>|t|)   CI Lower  CI Upper DF #> z 0.0482231   0.230729 0.2090032 0.8344458 -0.4039975 0.5004437 NA ht_cl_manual #>    Estimate Std. Error   t value  Pr(>|t|)   CI Lower  CI Upper DF #> z 0.0482231   0.230729 0.2090032 0.8344458 -0.4039975 0.5004437 NA  # Blocked estimators specified similarly  #---------- # More complicated assignment #----------  # arbitrary permutation matrix possible_treats <- cbind(   c(1, 1, 0, 1, 0, 0, 0, 1, 1, 0),   c(0, 1, 1, 0, 1, 1, 0, 1, 0, 1),   c(1, 0, 1, 1, 1, 1, 1, 0, 0, 0) ) arb_pr_mat <- permutations_to_condition_pr_mat(possible_treats) # Simulating a column to be realized treatment dat$z <- possible_treats[, sample(ncol(possible_treats), size = 1)] horvitz_thompson(y ~ z, data = dat, condition_pr_mat = arb_pr_mat) #>    Estimate Std. Error   t value  Pr(>|t|)   CI Lower CI Upper DF #> z 0.7576713  0.7715048 0.9820695 0.3260656 -0.7544502 2.269793 NA"},{"path":"https://declaredesign.org/r/estimatr/reference/iv_robust.html","id":null,"dir":"Reference","previous_headings":"","what":"Two-Stage Least Squares Instrumental Variables Regression — iv_robust","title":"Two-Stage Least Squares Instrumental Variables Regression — iv_robust","text":"formula estimates instrumental variables regression using two-stage least squares variety options robust standard errors","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/iv_robust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Two-Stage Least Squares Instrumental Variables Regression — iv_robust","text":"","code":"iv_robust(   formula,   data,   weights,   subset,   clusters,   fixed_effects,   se_type = NULL,   ci = TRUE,   alpha = 0.05,   diagnostics = FALSE,   return_vcov = TRUE,   try_cholesky = FALSE )"},{"path":"https://declaredesign.org/r/estimatr/reference/iv_robust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Two-Stage Least Squares Instrumental Variables Regression — iv_robust","text":"formula object class formula regression instruments. example, formula y ~ x1 + x2 | z1 + z2 specifies x1 x2 endogenous regressors z1 z2 respective instruments. data data.frame weights bare (unquoted) names weights variable supplied data. subset optional bare (unquoted) expression specifying subset observations used. clusters optional bare (unquoted) name variable corresponds clusters data. fixed_effects optional right-sided formula containing fixed effects projected data, ~ blockID. pass multiple-fixed effects intersecting groups. Speed gains greatest variables large numbers groups using \"HC1\" \"stata\" standard errors. See 'Details'. se_type sort standard error sought. clusters specified options \"HC0\", \"HC1\" (\"stata\", equivalent),  \"HC2\" (default), \"HC3\", \"classical\". clusters specified options \"CR0\", \"CR2\" (default), \"stata\". Can also specify \"none\", may speed estimation coefficients. ci logical. Whether compute return p-values confidence intervals, TRUE default. alpha significance level, 0.05 default. diagnostics logical. Whether compute return instrumental variable diagnostic statistics tests. return_vcov logical. Whether return variance-covariance matrix later usage, TRUE default. try_cholesky logical. Whether try using Cholesky decomposition solve least squares instead QR decomposition, FALSE default. Using Cholesky decomposition may result speed gains, used users sure model full-rank (.e., perfect multi-collinearity)","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/iv_robust.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Two-Stage Least Squares Instrumental Variables Regression — iv_robust","text":"object class \"iv_robust\". post-estimation commands functions summary tidy return results data.frame. get useful data return, can use data frames, can use resulting list directly, can use generic accessor functions coef, vcov, confint, predict. object class \"iv_robust\" list containing least following components: coefficients estimated coefficients std.error estimated standard errors statistic t-statistic df estimated degrees freedom p.value p-values two-sided t-test using coefficients, std.error, df conf.low lower bound 1 - alpha percent confidence interval conf.high upper bound 1 - alpha percent confidence interval term character vector coefficient names alpha significance level specified user se_type standard error type specified user res_var residual variance nobs number observations used k number columns design matrix (includes linearly dependent columns!) rank rank fitted model vcov fitted variance covariance matrix r.squared \\(R^2\\) second stage regression adj.r.squared \\(R^2\\) second stage regression, penalized parameters, rank fstatistic vector value second stage F-statistic numerator denominator degrees freedom firststage_fstatistic vector value first stage F-statistic numerator denominator degrees freedom, useful test weak instruments weighted whether weights applied call original function call fitted.values matrix predicted means also return terms second stage terms terms_regressors first stage terms, used predict. fixed_effects specified, return proj_fstatistic, proj_r.squared, proj_adj.r.squared, model fit statistics computed projected model (demeaning fixed effects). also return various diagnostics `diagnostics` == TRUE. stored diagnostic_first_stage_fstatistic, diagnostic_endogeneity_test, diagnostic_overid_test. test statistic, relevant degrees freedom, p.value named vector. See 'Details' . printed formatted table model object passed summary().","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/iv_robust.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Two-Stage Least Squares Instrumental Variables Regression — iv_robust","text":"function performs two-stage least squares estimation fit instrumental variables regression. syntax similar ivreg AER package. Regressors instruments specified two-part formula, y ~ x1 + x2 | z1 + z2 + z3, x1 x2 regressors z1, z2, z3 instruments. Unlike ivreg, must explicitly specify exogenous regressors sides bar. default variance estimators lm_robust. Without clusters, default HC2 standard errors, clusters default CR2 standard errors. 2SLS variance estimates computed using estimators lm_robust, however design matrix used second-stage regressors, includes estimated endogenous regressors, residuals used difference outcome fit produced second-stage coefficients first-stage (endogenous) regressors. notes can found mathematical appendix. fixed_effects specified, outcome, regressors, instruments centered using method alternating projections (Halperin 1962; Gaure 2013). Specifying fixed effects way result large speed gains standard error estimators need invert matrix fixed effects. means using \"classical\", \"HC0\", \"HC1\", \"CR0\", \"stata\" standard errors faster standard error estimators. wary specifying fixed effects may result perfect fits observations intersecting groups across multiple fixed effect variables (e.g. specify \"year\" \"country\" fixed effects unbalanced panel one year data one country). diagnostics requested, compute return three sets diagnostics. First, return tests weak instruments using first-stage F-statistics (diagnostic_first_stage_fstatistic). Specifically, F-statistics reported compare model regressing endogeneous variable included exogenous variables instruments model endogenous variable regressed included exogenous variables (without instruments). significant F-test weak instruments provides evidence null hypothesis instruments weak. Second, return tests endogeneity endogenous variables, often called Wu-Hausman test  (diagnostic_endogeneity_test). implement regression test Hausman (1978), allows robust variance estimation. significant endogeneity test provides evidence null variables exogenous. Third, return test correlation instruments error term  (diagnostic_overid_test). implement Wooldridge (1995) robust score test, identical Sargan's (1958) test classical standard errors. test reported model overidentified (.e. number instruments greater number endogenous regressors), weights specified.","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/iv_robust.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Two-Stage Least Squares Instrumental Variables Regression — iv_robust","text":"Gaure, Simon. 2013. \"OLS multiple high dimensional category variables.\" Computational Statistics & Data Analysis 66: 8-1. doi:10.1016/j.csda.2013.03.024 Halperin, . 1962. \"product projection operators.\" Acta Scientiarum Mathematicarum (Szeged) 23(1-2): 96-99.","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/iv_robust.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Two-Stage Least Squares Instrumental Variables Regression — iv_robust","text":"","code":"library(fabricatr) dat <- fabricate(   N = 40,   Y = rpois(N, lambda = 4),   Z = rbinom(N, 1, prob = 0.4),   D  = Z * rbinom(N, 1, prob = 0.8),   X = rnorm(N),   G = sample(letters[1:4], N, replace = TRUE) )  # Instrument for treatment `D` with encouragement `Z` tidy(iv_robust(Y ~ D + X | Z + X, data = dat)) #>          term   estimate std.error  statistic      p.value   conf.low conf.high #> 1 (Intercept) 3.32899931 0.3532949 9.42272101 2.261759e-11  2.6131558 4.0448428 #> 2           D 0.31231384 0.6515096 0.47936952 6.344971e-01 -1.0077700 1.6323977 #> 3           X 0.03953936 0.4343723 0.09102642 9.279626e-01 -0.8405826 0.9196613 #>   df outcome #> 1 37       Y #> 2 37       Y #> 3 37       Y  # Instrument with Stata's `ivregress 2sls , small rob` HC1 variance tidy(iv_robust(Y ~ D | Z, data = dat, se_type = \"stata\")) #>          term  estimate std.error statistic      p.value  conf.low conf.high df #> 1 (Intercept) 3.3157895 0.3419679 9.6962023 7.990568e-12  2.623512  4.008067 38 #> 2           D 0.3184211 0.6522180 0.4882126 6.282047e-01 -1.001925  1.638767 38 #>   outcome #> 1       Y #> 2       Y  # With clusters, we use CR2 errors by default dat$cl <- rep(letters[1:5], length.out = nrow(dat)) tidy(iv_robust(Y ~ D | Z, data = dat, clusters = cl)) #>          term  estimate std.error statistic     p.value   conf.low conf.high #> 1 (Intercept) 3.3157895 0.4457303 7.4390043 0.002360625  2.0374558  4.594123 #> 2           D 0.3184211 0.4682124 0.6800782 0.533811304 -0.9820125  1.618855 #>         df outcome #> 1 3.698715       Y #> 2 3.996357       Y  # Again, easy to replicate Stata (again with `small` correction in Stata) tidy(iv_robust(Y ~ D | Z, data = dat, clusters = cl, se_type = \"stata\")) #>          term  estimate std.error statistic     p.value   conf.low conf.high df #> 1 (Intercept) 3.3157895 0.4414454 7.5112102 0.001681356  2.0901405  4.541438  4 #> 2           D 0.3184211 0.4634526 0.6870629 0.529805076 -0.9683296  1.605172  4 #>   outcome #> 1       Y #> 2       Y  # We can also specify fixed effects, that will be taken as exogenous regressors # Speed gains with fixed effects are greatests with \"stata\" or \"HC1\" std.errors tidy(iv_robust(Y ~ D | Z, data = dat, fixed_effects = ~ G, se_type = \"HC1\")) #>   term  estimate std.error statistic   p.value  conf.low conf.high df outcome #> 1    D 0.2509696 0.6728668 0.3729855 0.7114087 -1.115023  1.616962 35       Y"},{"path":"https://declaredesign.org/r/estimatr/reference/lh_robust.html","id":null,"dir":"Reference","previous_headings":"","what":"Linear Hypothesis for Ordinary Least Squares with Robust Standard Errors — lh_robust","title":"Linear Hypothesis for Ordinary Least Squares with Robust Standard Errors — lh_robust","text":"function fits linear model robust standard errors performs linear hypothesis test.","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/lh_robust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Linear Hypothesis for Ordinary Least Squares with Robust Standard Errors — lh_robust","text":"","code":"lh_robust(..., data, linear_hypothesis)"},{"path":"https://declaredesign.org/r/estimatr/reference/lh_robust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Linear Hypothesis for Ordinary Least Squares with Robust Standard Errors — lh_robust","text":"... arguments passed  lm_robust data data.frame linear_hypothesis character string matrix specifying combination, passed hypothesis.matrix argument car::linearHypothesis See linearHypothesis details.","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/lh_robust.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Linear Hypothesis for Ordinary Least Squares with Robust Standard Errors — lh_robust","text":"object class \"lh_robust\" containing two following components: lm_robust object returned lm_robust. lh data frame columns pulled linearHypothesis' output. analyis directly performed lh_robust t-test null hypothesis effects linear combination coefficients specified user. output components either extracted linearHypothesis lm_robust. original output returned linearHypothesis added attribute \"linear_hypothesis\" attribute.","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/lh_robust.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Linear Hypothesis for Ordinary Least Squares with Robust Standard Errors — lh_robust","text":"function wrapper lm_robust linearHypothesis. first runs lm_robust next passes \"lm_robust\" object argument linearHypothesis.","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/lh_robust.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Linear Hypothesis for Ordinary Least Squares with Robust Standard Errors — lh_robust","text":"","code":"library(fabricatr) dat <- fabricate(   N = 40,   y = rpois(N, lambda = 4),   x = rnorm(N),   z = rbinom(N, 1, prob = 0.4),   clusterID = sample(1:4, 40, replace = TRUE) )  # Default variance estimator is HC2 robust standard errors lhro <- lh_robust(y ~ x + z, data = dat, linear_hypothesis = \"z + 2x = 0\") #> Loading required namespace: car  # The linear hypothesis argument can be specified equivalently as: lh_robust(y ~ x + z, data = dat, linear_hypothesis = \"z = 2x\") #> $lm_robust #>               Estimate Std. Error   t value     Pr(>|t|)   CI Lower  CI Upper #> (Intercept)  4.4094685  0.4557957  9.674221 1.122813e-11  3.4859387 5.3329984 #> x            0.3619881  0.3264857  1.108741 2.746970e-01 -0.2995348 1.0235109 #> z           -0.9191800  0.6702807 -1.371336 1.785304e-01 -2.2772976 0.4389376 #>             DF #> (Intercept) 37 #> x           37 #> z           37 #>  #> $lh #>        Estimate Std. Error t value Pr(>|t|) CI Lower CI Upper DF #> z = 2x   -1.643     0.8839  -1.859  0.07101   -3.434   0.1479 37 #>  lh_robust(y ~ x + z, data = dat, linear_hypothesis = \"2*x +1*z\") #> $lm_robust #>               Estimate Std. Error   t value     Pr(>|t|)   CI Lower  CI Upper #> (Intercept)  4.4094685  0.4557957  9.674221 1.122813e-11  3.4859387 5.3329984 #> x            0.3619881  0.3264857  1.108741 2.746970e-01 -0.2995348 1.0235109 #> z           -0.9191800  0.6702807 -1.371336 1.785304e-01 -2.2772976 0.4389376 #>             DF #> (Intercept) 37 #> x           37 #> z           37 #>  #> $lh #>          Estimate Std. Error t value Pr(>|t|) CI Lower CI Upper DF #> 2*x +1*z  -0.1952     0.9849 -0.1982    0.844   -2.191      1.8 37 #>  lh_robust(y ~ x + z, data = dat, linear_hypothesis = \"z + 2x = 0\") #> $lm_robust #>               Estimate Std. Error   t value     Pr(>|t|)   CI Lower  CI Upper #> (Intercept)  4.4094685  0.4557957  9.674221 1.122813e-11  3.4859387 5.3329984 #> x            0.3619881  0.3264857  1.108741 2.746970e-01 -0.2995348 1.0235109 #> z           -0.9191800  0.6702807 -1.371336 1.785304e-01 -2.2772976 0.4389376 #>             DF #> (Intercept) 37 #> x           37 #> z           37 #>  #> $lh #>            Estimate Std. Error t value Pr(>|t|) CI Lower CI Upper DF #> z + 2x = 0  -0.1952     0.9849 -0.1982    0.844   -2.191      1.8 37 #>   # Also recovers other sorts of standard erorrs just as specified in \\code{\\link{lm_robust}} lh_robust(y ~ x + z, data = dat, linear_hypothesis = \"z + 2x = 0\", se_type = \"classical\") #> $lm_robust #>               Estimate Std. Error    t value     Pr(>|t|)   CI Lower  CI Upper #> (Intercept)  4.4094685  0.4426777  9.9608997 5.104664e-12  3.5125182 5.3064188 #> x            0.3619881  0.3623107  0.9991094 3.242313e-01 -0.3721232 1.0960993 #> z           -0.9191800  0.6992058 -1.3146057 1.967333e-01 -2.3359056 0.4975456 #>             DF #> (Intercept) 37 #> x           37 #> z           37 #>  #> $lh #>            Estimate Std. Error t value Pr(>|t|) CI Lower CI Upper DF #> z + 2x = 0  -0.1952     0.9746 -0.2003   0.8424    -2.17     1.78 37 #>  lh_robust(y ~ x + z, data = dat, linear_hypothesis = \"z + 2x = 0\", se_type =  \"HC1\") #> $lm_robust #>               Estimate Std. Error   t value     Pr(>|t|)   CI Lower  CI Upper #> (Intercept)  4.4094685  0.4575107  9.637957 1.241489e-11  3.4824638 5.3364733 #> x            0.3619881  0.3218063  1.124863 2.678914e-01 -0.2900534 1.0140295 #> z           -0.9191800  0.6715469 -1.368750 1.793307e-01 -2.2798633 0.4415034 #>             DF #> (Intercept) 37 #> x           37 #> z           37 #>  #> $lh #>            Estimate Std. Error t value Pr(>|t|) CI Lower CI Upper DF #> z + 2x = 0  -0.1952     0.9848 -0.1982    0.844   -2.191      1.8 37 #>   #  Can tidy() main output and subcomponents in to a data.frame lhro <- lh_robust(y ~ x + z, data = dat, linear_hypothesis = \"z + 2x = 0\") tidy(lhro ) #>          term   estimate std.error statistic      p.value   conf.low conf.high #> 1 (Intercept)  4.4094685 0.4557957  9.674221 1.122813e-11  3.4859387 5.3329984 #> 2           x  0.3619881 0.3264857  1.108741 2.746970e-01 -0.2995348 1.0235109 #> 3           z -0.9191800 0.6702807 -1.371336 1.785304e-01 -2.2772976 0.4389376 #> 4  z + 2x = 0 -0.1952039 0.9848583 -0.198205 8.439697e-01 -2.1907164 1.8003086 #>   df outcome #> 1 37       y #> 2 37       y #> 3 37       y #> 4 37       y tidy(lhro$lm_robust) #>          term   estimate std.error statistic      p.value   conf.low conf.high #> 1 (Intercept)  4.4094685 0.4557957  9.674221 1.122813e-11  3.4859387 5.3329984 #> 2           x  0.3619881 0.3264857  1.108741 2.746970e-01 -0.2995348 1.0235109 #> 3           z -0.9191800 0.6702807 -1.371336 1.785304e-01 -2.2772976 0.4389376 #>   df outcome #> 1 37       y #> 2 37       y #> 3 37       y tidy(lhro$lh) #>         term   estimate std.error statistic   p.value  conf.low conf.high df #> 1 z + 2x = 0 -0.1952039 0.9848583 -0.198205 0.8439697 -2.190716  1.800309 37 #>   outcome #> 1       y  # Can use summary() to get more statistics on the main output and subcomponents. summary(lhro) #> $lm_robust #>  #> Call: #> lh_robust(y ~ x + z, data = dat, linear_hypothesis = \"z + 2x = 0\") #>  #> Standard error type:  HC2  #>  #> Coefficients: #>             Estimate Std. Error t value  Pr(>|t|) CI Lower CI Upper DF #> (Intercept)   4.4095     0.4558   9.674 1.123e-11   3.4859   5.3330 37 #> x             0.3620     0.3265   1.109 2.747e-01  -0.2995   1.0235 37 #> z            -0.9192     0.6703  -1.371 1.785e-01  -2.2773   0.4389 37 #>  #> Multiple R-squared:  0.06496 ,\tAdjusted R-squared:  0.01442  #> F-statistic: 1.739 on 2 and 37 DF,  p-value: 0.1898 #>  #> $lh #>            Estimate Std. Error t value Pr(>|t|) CI Lower CI Upper DF #> z + 2x = 0  -0.1952     0.9849 -0.1982    0.844   -2.191      1.8 37 #>  summary(lhro$lm_robust) #>  #> Call: #> lh_robust(y ~ x + z, data = dat, linear_hypothesis = \"z + 2x = 0\") #>  #> Standard error type:  HC2  #>  #> Coefficients: #>             Estimate Std. Error t value  Pr(>|t|) CI Lower CI Upper DF #> (Intercept)   4.4095     0.4558   9.674 1.123e-11   3.4859   5.3330 37 #> x             0.3620     0.3265   1.109 2.747e-01  -0.2995   1.0235 37 #> z            -0.9192     0.6703  -1.371 1.785e-01  -2.2773   0.4389 37 #>  #> Multiple R-squared:  0.06496 ,\tAdjusted R-squared:  0.01442  #> F-statistic: 1.739 on 2 and 37 DF,  p-value: 0.1898 summary(lhro$lh) #>            Estimate Std. Error t value Pr(>|t|) CI Lower CI Upper DF #> z + 2x = 0  -0.1952     0.9849 -0.1982    0.844   -2.191      1.8 37"},{"path":"https://declaredesign.org/r/estimatr/reference/lm_lin.html","id":null,"dir":"Reference","previous_headings":"","what":"Linear regression with the Lin (2013) covariate adjustment — lm_lin","title":"Linear regression with the Lin (2013) covariate adjustment — lm_lin","text":"function wrapper lm_robust useful estimating treatment effects pre-treatment covariate data. implements method described Lin (2013).","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/lm_lin.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Linear regression with the Lin (2013) covariate adjustment — lm_lin","text":"","code":"lm_lin(   formula,   covariates,   data,   weights,   subset,   clusters,   se_type = NULL,   ci = TRUE,   alpha = 0.05,   return_vcov = TRUE,   try_cholesky = FALSE )"},{"path":"https://declaredesign.org/r/estimatr/reference/lm_lin.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Linear regression with the Lin (2013) covariate adjustment — lm_lin","text":"formula object class formula, lm, Y ~ Z one variable right-hand side, treatment covariates right-sided formula pre-treatment covariates right hand side,  ~ x1 + x2 + x3. data data.frame weights bare (unquoted) names weights variable supplied data. subset optional bare (unquoted) expression specifying subset observations used. clusters optional bare (unquoted) name variable corresponds clusters data. se_type sort standard error sought. clusters specified options \"HC0\", \"HC1\" (\"stata\", equivalent), \"HC2\" (default), \"HC3\",  \"classical\". clusters specified options \"CR0\", \"CR2\" (default), \"stata\" permissible. ci logical. Whether compute return p-values confidence intervals, TRUE default. alpha significance level, 0.05 default. return_vcov logical. Whether return variance-covariance matrix later usage, TRUE default. try_cholesky logical. Whether try using Cholesky decomposition solve least squares instead QR decomposition, FALSE default. Using Cholesky decomposition may result speed gains, used users sure model full-rank (.e., perfect multi-collinearity)","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/lm_lin.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Linear regression with the Lin (2013) covariate adjustment — lm_lin","text":"object class \"lm_robust\". post-estimation commands functions summary tidy return results data.frame. get useful data return, can use data frames, can use resulting list directly, can use generic accessor functions coef, vcov, confint, predict. Marginal effects uncertainty can gotten passing object margins margins. Users want print results TeX HTML can use extract function texreg package. object class \"lm_robust\" list containing least following components: coefficients estimated coefficients std.error estimated standard errors statistic t-statistic df estimated degrees freedom p.value p-values two-sided t-test using coefficients, std.error, df conf.low lower bound 1 - alpha percent confidence interval conf.high upper bound 1 - alpha percent confidence interval term character vector coefficient names alpha significance level specified user se_type standard error type specified user res_var residual variance N number observations used k number columns design matrix (includes linearly dependent columns!) rank rank fitted model vcov fitted variance covariance matrix r.squared \\(R^2\\),   $$R^2 = 1 - Sum(e[]^2) / Sum((y[] - y^*)^2),$$ \\(y^*\\)   mean \\(y[]\\) intercept zero otherwise,   \\(e[]\\) ith residual. adj.r.squared \\(R^2\\) penalized parameters, rank weighted whether weights applied call original function call fitted.values matrix predicted means also return terms contrasts, used predict, scaled_centerthe means covariates used centering ","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/lm_lin.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Linear regression with the Lin (2013) covariate adjustment — lm_lin","text":"function simply wrapper lm_robust implements Lin estimator (see reference ). method pre-processes data taking covariates specified `covariates` argument, centering subtracting covariate mean, interacting treatment. treatment multiple values, series dummies value created interacted demeaned covariates. details can found Getting Started vignette mathematical notes.","code":""},{"path":[]},{"path":"https://declaredesign.org/r/estimatr/reference/lm_lin.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Linear regression with the Lin (2013) covariate adjustment — lm_lin","text":"","code":"library(fabricatr) library(randomizr) dat <- fabricate(   N = 40,   x = rnorm(N, mean = 2.3),   x2 = rpois(N, lambda = 2),   x3 = runif(N),   y0 = rnorm(N) + x,   y1 = rnorm(N) + x + 0.35 )  dat$z <- complete_ra(N = nrow(dat)) dat$y <- ifelse(dat$z == 1, dat$y1, dat$y0)  # Same specification as lm_robust() with one additional argument lmlin_out <- lm_lin(y ~ z, covariates = ~ x, data = dat) tidy(lmlin_out) #>          term   estimate std.error  statistic      p.value   conf.low conf.high #> 1 (Intercept)  2.0074002 0.2012088  9.9767032 6.611620e-12  1.5993299 2.4154705 #> 2           z  0.7263528 0.3037565  2.3912337 2.214176e-02  0.1103061 1.3423996 #> 3         x_c  1.0673003 0.2721532  3.9216889 3.786550e-04  0.5153480 1.6192527 #> 4       z:x_c -0.2815330 0.3235071 -0.8702529 3.899283e-01 -0.9376358 0.3745698 #>   df outcome #> 1 36       y #> 2 36       y #> 3 36       y #> 4 36       y  # Works with multiple pre-treatment covariates lm_lin(y ~ z, covariates = ~ x + x2, data = dat) #>               Estimate Std. Error    t value     Pr(>|t|)    CI Lower  CI Upper #> (Intercept)  2.0331904  0.2035346  9.9894110 1.198631e-11  1.61955838 2.4468224 #> z            0.6874490  0.3118326  2.2045450 3.435353e-02  0.05372891 1.3211692 #> x_c          1.1154732  0.2539604  4.3923109 1.038122e-04  0.59936348 1.6315829 #> x2_c         0.2456971  0.2805576  0.8757456 3.873136e-01 -0.32446459 0.8158588 #> z:x_c       -0.3294245  0.3067964 -1.0737561 2.904938e-01 -0.95290983 0.2940608 #> z:x2_c      -0.1146326  0.3618812 -0.3167687 7.533560e-01 -0.85006364 0.6207984 #>             DF #> (Intercept) 34 #> z           34 #> x_c         34 #> x2_c        34 #> z:x_c       34 #> z:x2_c      34  # Also centers data AFTER evaluating any functions in formula lmlin_out2 <- lm_lin(y ~ z, covariates = ~ x + log(x3), data = dat) lmlin_out2$scaled_center[\"log(x3)\"] #>    log(x3)  #> -0.7815509  mean(log(dat$x3)) #> [1] -0.7815509  # Works easily with clusters dat$clusterID <- rep(1:20, each = 2) dat$z_clust <- cluster_ra(clusters = dat$clusterID)  lm_lin(y ~ z_clust, covariates = ~ x, data = dat, clusters = clusterID) #>              Estimate Std. Error   t value     Pr(>|t|)     CI Lower  CI Upper #> (Intercept) 2.1869918  0.2599259 8.4139039 6.338923e-05  1.573233032 2.8007505 #> z_clust     0.1547201  0.3441864 0.4495242 6.598847e-01 -0.582978576 0.8924188 #> x_c         0.6678927  0.2632028 2.5375595 5.052778e-02 -0.002227515 1.3380129 #> z_clust:x_c 0.5497024  0.3559260 1.5444288 1.576286e-01 -0.258197236 1.3576021 #>                    DF #> (Intercept)  7.049192 #> z_clust     14.103467 #> x_c          5.165385 #> z_clust:x_c  8.804119  # Works with multi-valued treatments dat$z_multi <- sample(1:3, size = nrow(dat), replace = TRUE) lm_lin(y ~ z_multi, covariates = ~ x, data = dat) #>                  Estimate Std. Error      t value     Pr(>|t|)   CI Lower #> (Intercept)   2.087111175  0.2397513  8.705318218 3.583451e-10  1.5998780 #> z_multi2      0.632076161  0.3949708  1.600311246 1.187819e-01 -0.1706010 #> z_multi3      0.225302890  0.4595353  0.490284219 6.270820e-01 -0.7085851 #> x_c           0.971855697  0.3265662  2.975983428 5.346867e-03  0.3081933 #> z_multi2:x_c -0.164498171  0.4184305 -0.393131454 6.966767e-01 -1.0148512 #> z_multi3:x_c  0.007310125  0.8138866  0.008981748 9.928862e-01 -1.6467064 #>               CI Upper DF #> (Intercept)  2.5743444 34 #> z_multi2     1.4347533 34 #> z_multi3     1.1591909 34 #> x_c          1.6355181 34 #> z_multi2:x_c 0.6858548 34 #> z_multi3:x_c 1.6613267 34  # Stratified estimator with blocks dat$blockID <- rep(1:5, each = 8) dat$z_block <- block_ra(blocks = dat$blockID)  lm_lin(y ~ z_block, ~ factor(blockID), data = dat) #>                                Estimate Std. Error    t value     Pr(>|t|) #> (Intercept)                   2.0704132  0.3451408  5.9987493 1.399160e-06 #> z_block                       0.5931938  0.4501499  1.3177696 1.975558e-01 #> (factor(blockID)2)_c          1.1858143  1.1686199  1.0147134 3.183567e-01 #> (factor(blockID)3)_c          1.4533957  1.1962207  1.2149896 2.338464e-01 #> (factor(blockID)4)_c          0.3103012  1.2793724  0.2425417 8.100110e-01 #> (factor(blockID)5)_c          0.6828532  1.1941371  0.5718382 5.716919e-01 #> z_block:(factor(blockID)2)_c -1.5162764  1.4447190 -1.0495303 3.023158e-01 #> z_block:(factor(blockID)3)_c -1.2130004  1.4862041 -0.8161735 4.208346e-01 #> z_block:(factor(blockID)4)_c -0.4459309  1.5448894 -0.2886491 7.748351e-01 #> z_block:(factor(blockID)5)_c -1.9553208  1.3328098 -1.4670666 1.527638e-01 #>                                CI Lower CI Upper DF #> (Intercept)                   1.3655416 2.775285 30 #> z_block                      -0.3261349 1.512523 30 #> (factor(blockID)2)_c         -1.2008259 3.572455 30 #> (factor(blockID)3)_c         -0.9896129 3.896404 30 #> (factor(blockID)4)_c         -2.3025258 2.923128 30 #> (factor(blockID)5)_c         -1.7559001 3.121606 30 #> z_block:(factor(blockID)2)_c -4.4667862 1.434233 30 #> z_block:(factor(blockID)3)_c -4.2482341 1.822233 30 #> z_block:(factor(blockID)4)_c -3.6010159 2.709154 30 #> z_block:(factor(blockID)5)_c -4.6772816 0.766640 30  if (FALSE) {   # Can also use 'margins' package if you have it installed to get   # marginal effects   library(margins)   lmlout <- lm_lin(y ~ z_block, ~ x, data = dat)   summary(margins(lmlout))    # Can output results using 'texreg'   library(texreg)   texregobj <- extract(lmlout) }"},{"path":"https://declaredesign.org/r/estimatr/reference/lm_robust.html","id":null,"dir":"Reference","previous_headings":"","what":"Ordinary Least Squares with Robust Standard Errors — lm_robust","title":"Ordinary Least Squares with Robust Standard Errors — lm_robust","text":"formula fits linear model, provides variety options robust standard errors, conducts coefficient tests","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/lm_robust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ordinary Least Squares with Robust Standard Errors — lm_robust","text":"","code":"lm_robust(   formula,   data,   weights,   subset,   clusters,   fixed_effects,   se_type = NULL,   ci = TRUE,   alpha = 0.05,   return_vcov = TRUE,   try_cholesky = FALSE )"},{"path":"https://declaredesign.org/r/estimatr/reference/lm_robust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Ordinary Least Squares with Robust Standard Errors — lm_robust","text":"formula object class formula, lm data data.frame weights bare (unquoted) names weights variable supplied data. subset optional bare (unquoted) expression specifying subset observations used. clusters optional bare (unquoted) name variable corresponds clusters data. fixed_effects optional right-sided formula containing fixed effects projected data, ~ blockID. pass multiple-fixed effects intersecting groups. Speed gains greatest variables large numbers groups using \"HC1\" \"stata\" standard errors. See 'Details'. se_type sort standard error sought. clusters specified options \"HC0\", \"HC1\" (\"stata\", equivalent),  \"HC2\" (default), \"HC3\", \"classical\". clusters specified options \"CR0\", \"CR2\" (default), \"stata\". Can also specify \"none\", may speed estimation coefficients. ci logical. Whether compute return p-values confidence intervals, TRUE default. alpha significance level, 0.05 default. return_vcov logical. Whether return variance-covariance matrix later usage, TRUE default. try_cholesky logical. Whether try using Cholesky decomposition solve least squares instead QR decomposition, FALSE default. Using Cholesky decomposition may result speed gains, used users sure model full-rank (.e., perfect multi-collinearity)","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/lm_robust.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Ordinary Least Squares with Robust Standard Errors — lm_robust","text":"object class \"lm_robust\". post-estimation commands functions summary tidy return results data.frame. get useful data return, can use data frames, can use resulting list directly, can use generic accessor functions coef, vcov, confint, predict. Marginal effects uncertainty can gotten passing object margins margins, emmeans emmeans package. Users want print results TeX HTML can use extract function texreg package. users specify multivariate linear regression model (multiple outcomes), components higher dimension accommodate additional models. object class \"lm_robust\" list containing least following components: coefficients estimated coefficients std.error estimated standard errors statistic t-statistic df estimated degrees freedom p.value p-values two-sided t-test using coefficients, std.error, df conf.low lower bound 1 - alpha percent confidence interval conf.high upper bound 1 - alpha percent confidence interval term character vector coefficient names alpha significance level specified user se_type standard error type specified user res_var residual variance N number observations used k number columns design matrix (includes linearly dependent columns!) rank rank fitted model vcov fitted variance covariance matrix r.squared \\(R^2\\),   $$R^2 = 1 - Sum(e[]^2) / Sum((y[] - y^*)^2),$$ \\(y^*\\)   mean \\(y[]\\) intercept zero otherwise,   \\(e[]\\) ith residual. adj.r.squared \\(R^2\\) penalized parameters, rank fstatistic vector value F-statistic numerator denominator degrees freedom weighted whether weights applied call original function call fitted.values matrix predicted means also return terms contrasts, used predict. fixed_effects specified, return proj_fstatistic, proj_r.squared, proj_adj.r.squared, model fit statistics computed projected model (demeaning fixed effects).","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/lm_robust.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Ordinary Least Squares with Robust Standard Errors — lm_robust","text":"function performs linear regression provides variety standard errors. takes formula data much lm , auxiliary variables, clusters weights, can passed either quoted names columns, bare column names, self-contained vector. Examples usage can seen Getting Started vignette. mathematical notes vignette specify exact estimators used function. default variance estimators chosen largely accordance procedures manual. default case without clusters HC2 estimator default clusters analogous CR2 estimator. Users can easily replicate Stata standard errors clustered non-clustered case setting `se_type` = \"stata\". function estimates coefficients standard errors C++, using RcppEigen package. default, estimate coefficients using Column-Pivoting QR decomposition Eigen C++ library, although users get faster solutions setting `try_cholesky` = TRUE use Cholesky decomposition instead. likely result quicker solutions, algorithm reliably detect linear dependencies model may fail silently exist. `fixed_effects` specified, outcome design matrix centered using method alternating projections (Halperin 1962; Gaure 2013). Specifying fixed effects way result large speed gains standard error estimators need invert matrix fixed effects. means using \"classical\", \"HC0\", \"HC1\", \"CR0\", \"stata\" standard errors faster standard error estimators. wary specifying fixed effects may result perfect fits observations intersecting groups across multiple fixed effect variables (e.g. specify \"year\" \"country\" fixed effects unbalanced panel one year data one country). `lm()`, multivariate regression (multiple outcomes) admit observations estimation missingness outcome.","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/lm_robust.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Ordinary Least Squares with Robust Standard Errors — lm_robust","text":"Abadie, Alberto, Susan Athey, Guido W Imbens, Jeffrey Wooldridge. 2017. \"Class Unbiased Estimators Average Treatment Effect Randomized Experiments.\" arXiv Pre-Print. https://arxiv.org/abs/1710.02926v2. Bell, Robert M, Daniel F McCaffrey. 2002. \"Bias Reduction Standard Errors Linear Regression Multi-Stage Samples.\" Survey Methodology 28 (2): 169-82. Gaure, Simon. 2013. \"OLS multiple high dimensional category variables.\" Computational Statistics & Data Analysis 66: 8-1. doi:10.1016/j.csda.2013.03.024 Halperin, . 1962. \"product projection operators.\" Acta Scientiarum Mathematicarum (Szeged) 23(1-2): 96-99. MacKinnon, James, Halbert White. 1985. \"Heteroskedasticity-Consistent Covariance Matrix Estimators Improved Finite Sample Properties.\" Journal Econometrics 29 (3): 305-25. doi:10.1016/0304-4076(85)90158-7 . Pustejovsky, James E, Elizabeth Tipton. 2016. \"Small Sample Methods Cluster-Robust Variance Estimation Hypothesis Testing Fixed Effects Models.\" Journal Business & Economic Statistics. Taylor & Francis. doi:10.1080/07350015.2016.1247004 . Samii, Cyrus, Peter M Aronow. 2012. \"Equivalencies Design-Based Regression-Based Variance Estimators Randomized Experiments.\" Statistics Probability Letters 82 (2). doi:10.1016/j.spl.2011.10.024 .","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/lm_robust.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Ordinary Least Squares with Robust Standard Errors — lm_robust","text":"","code":"set.seed(15) library(fabricatr) dat <- fabricate(   N = 40,   y = rpois(N, lambda = 4),   x = rnorm(N),   z = rbinom(N, 1, prob = 0.4) )  # Default variance estimator is HC2 robust standard errors lmro <- lm_robust(y ~ x + z, data = dat)  # Can tidy() the data in to a data.frame tidy(lmro) #>          term   estimate std.error  statistic      p.value   conf.low conf.high #> 1 (Intercept)  4.5970879 0.4386909 10.4791036 1.261673e-12  3.7082156 5.4859602 #> 2           x  0.1735281 0.3813973  0.4549799 6.517822e-01 -0.5992562 0.9463125 #> 3           z -0.9016607 0.5423749 -1.6624308 1.048766e-01 -2.0006166 0.1972952 #>   df outcome #> 1 37       y #> 2 37       y #> 3 37       y # Can use summary() to get more statistics summary(lmro) #>  #> Call: #> lm_robust(formula = y ~ x + z, data = dat) #>  #> Standard error type:  HC2  #>  #> Coefficients: #>             Estimate Std. Error t value  Pr(>|t|) CI Lower CI Upper DF #> (Intercept)   4.5971     0.4387  10.479 1.262e-12   3.7082   5.4860 37 #> x             0.1735     0.3814   0.455 6.518e-01  -0.5993   0.9463 37 #> z            -0.9017     0.5424  -1.662 1.049e-01  -2.0006   0.1973 37 #>  #> Multiple R-squared:  0.05748 ,\tAdjusted R-squared:  0.00653  #> F-statistic: 1.453 on 2 and 37 DF,  p-value: 0.2468 # Can also get coefficients three ways lmro$coefficients #> (Intercept)           x           z  #>   4.5970879   0.1735281  -0.9016607  coef(lmro) #> (Intercept)           x           z  #>   4.5970879   0.1735281  -0.9016607  tidy(lmro)$estimate #> [1]  4.5970879  0.1735281 -0.9016607 # Can also get confidence intervals from object or with new 1 - `alpha` lmro$conf.low #> (Intercept)           x           z  #>   3.7082156  -0.5992562  -2.0006166  confint(lmro, level = 0.8) #>                   10 %       90 % #> (Intercept)  4.0246601  5.1695157 #> x           -0.3241398  0.6711961 #> z           -1.6093809 -0.1939405  # Can recover classical standard errors lmclassic <- lm_robust(y ~ x + z, data = dat, se_type = \"classical\") tidy(lmclassic) #>          term   estimate std.error  statistic      p.value   conf.low conf.high #> 1 (Intercept)  4.5970879 0.3802497 12.0896557 2.044110e-14  3.8266288 5.3675470 #> 2           x  0.1735281 0.3380391  0.5133374 6.107671e-01 -0.5114042 0.8584604 #> 3           z -0.9016607 0.6184263 -1.4579922 1.532792e-01 -2.1547114 0.3513900 #>   df outcome #> 1 37       y #> 2 37       y #> 3 37       y  # Can easily match Stata's robust standard errors lmstata <- lm_robust(y ~ x + z, data = dat, se_type = \"stata\") tidy(lmstata) #>          term   estimate std.error  statistic      p.value   conf.low conf.high #> 1 (Intercept)  4.5970879 0.4398377 10.4517829 1.356971e-12  3.7058921 5.4882837 #> 2           x  0.1735281 0.3731076  0.4650887 6.445936e-01 -0.5824596 0.9295159 #> 3           z -0.9016607 0.5377414 -1.6767553 1.020208e-01 -1.9912282 0.1879068 #>   df outcome #> 1 37       y #> 2 37       y #> 3 37       y  # Easy to specify clusters for cluster-robust inference dat$clusterID <- sample(1:10, size = 40, replace = TRUE)  lmclust <- lm_robust(y ~ x + z, data = dat, clusters = clusterID) tidy(lmclust) #>          term   estimate std.error  statistic      p.value   conf.low #> 1 (Intercept)  4.5970879 0.3915230 11.7415521 7.616489e-05  3.5922426 #> 2           x  0.1735281 0.3018399  0.5749012 5.896636e-01 -0.5966033 #> 3           z -0.9016607 0.4089681 -2.2047214 6.507872e-02 -1.8780217 #>    conf.high       df outcome #> 1 5.60193322 5.026547       y #> 2 0.94365951 5.127624       y #> 3 0.07470026 6.685305       y  # Can also match Stata's clustered standard errors lm_robust(   y ~ x + z,   data = dat,   clusters = clusterID,   se_type = \"stata\" ) #>               Estimate Std. Error    t value     Pr(>|t|)   CI Lower   CI Upper #> (Intercept)  4.5970879  0.3942711 11.6597139 2.668545e-06  3.6878972 5.50627862 #> x            0.1735281  0.3017859  0.5750041 5.810951e-01 -0.5223914 0.86944760 #> z           -0.9016607  0.4204547 -2.1444897 6.432503e-02 -1.8712309 0.06790948 #>             DF #> (Intercept)  8 #> x            8 #> z            8  # Works just as LM does with functions in the formula dat$blockID <- rep(c(\"A\", \"B\", \"C\", \"D\"), each = 10)  lm_robust(y ~ x + z + factor(blockID), data = dat) #>                    Estimate Std. Error    t value     Pr(>|t|)   CI Lower #> (Intercept)       5.0761464  0.7420501  6.8407062 7.125209e-08  3.5681192 #> x                 0.1905284  0.3731326  0.5106186 6.129177e-01 -0.5677682 #> z                -0.6517671  0.5811381 -1.1215355 2.699187e-01 -1.8327818 #> factor(blockID)B -0.1538306  0.9367502 -0.1642173 8.705325e-01 -2.0575361 #> factor(blockID)C -1.0519650  0.9520788 -1.1049138 2.769549e-01 -2.9868220 #> factor(blockID)D -1.0871302  0.8479584 -1.2820561 2.084963e-01 -2.8103891 #>                   CI Upper DF #> (Intercept)      6.5841735 34 #> x                0.9488250 34 #> z                0.5292477 34 #> factor(blockID)B 1.7498750 34 #> factor(blockID)C 0.8828920 34 #> factor(blockID)D 0.6361286 34  # Weights are also easily specified dat$w <- runif(40)  lm_robust(   y ~ x + z,   data = dat,   weights = w,   clusters = clusterID ) #>               Estimate Std. Error   t value     Pr(>|t|)   CI Lower  CI Upper #> (Intercept)  4.5913785  0.4910753  9.349642 0.0003289342  3.3038538 5.8789032 #> x            0.4028538  0.2133290  1.888416 0.1475001559 -0.2444348 1.0501424 #> z           -1.0782068  0.5341716 -2.018465 0.1086801430 -2.5205693 0.3641556 #>                   DF #> (Intercept) 4.693802 #> x           3.279816 #> z           4.306669  # Subsetting works just as in `lm()` lm_robust(y ~ x, data = dat, subset = z == 1) #>              Estimate Std. Error   t value     Pr(>|t|)  CI Lower  CI Upper DF #> (Intercept)  4.026354  0.3785824 10.635346 1.833544e-07  3.201494 4.8512143 12 #> x           -0.462500  0.3599288 -1.284976 2.230493e-01 -1.246718 0.3217174 12  # One can also choose to set the significance level for different CIs lm_robust(y ~ x + z, data = dat, alpha = 0.1) #>               Estimate Std. Error    t value     Pr(>|t|)   CI Lower   CI Upper #> (Intercept)  4.5970879  0.4386909 10.4791036 1.261673e-12  3.8569752 5.33720059 #> x            0.1735281  0.3813973  0.4549799 6.517822e-01 -0.4699248 0.81698110 #> z           -0.9016607  0.5423749 -1.6624308 1.048766e-01 -1.8166979 0.01337647 #>             DF #> (Intercept) 37 #> x           37 #> z           37  # We can also specify fixed effects # Speed gains with fixed effects are greatest with \"stata\" or \"HC1\" std.errors tidy(lm_robust(y ~ z, data = dat, fixed_effects = ~ blockID, se_type = \"HC1\")) #>   term   estimate std.error statistic   p.value  conf.low conf.high df outcome #> 1    z -0.5857143 0.5551326 -1.055089 0.2986138 -1.712693 0.5412649 35       y  if (FALSE) {   # Can also use 'margins' or 'emmeans' package if you have them installed   # to get marginal effects   library(margins)   lmrout <- lm_robust(y ~ x + z, data = dat)   summary(margins(lmrout))    # Can output results using 'texreg'   library(texreg)   texreg(lmrout)    # Using emmeans to obtain covariate-adjusted means   library(emmeans)   fiber.rlm <- lm_robust(strength ~ diameter + machine, data = fiber)   emmeans(fiber.rlm, \"machine\") }"},{"path":"https://declaredesign.org/r/estimatr/reference/lm_robust_fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal method that creates linear fits — lm_robust_fit","title":"Internal method that creates linear fits — lm_robust_fit","text":"Internal method creates linear fits","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/lm_robust_fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal method that creates linear fits — lm_robust_fit","text":"","code":"lm_robust_fit(   y,   X,   yoriginal = NULL,   Xoriginal = NULL,   weights,   cluster,   fixed_effects = NULL,   ci = TRUE,   se_type,   has_int,   alpha = 0.05,   return_vcov = TRUE,   return_fit = TRUE,   try_cholesky = FALSE,   iv_stage = list(0) )"},{"path":"https://declaredesign.org/r/estimatr/reference/lm_robust_fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal method that creates linear fits — lm_robust_fit","text":"y numeric outcome vector X numeric design matrix yoriginal numeric outcome vector, unprojected fixed effects Xoriginal numeric design matrix, unprojected fixed effects. column named \"(Intercept)\" dropped weights numeric weights vector cluster numeric cluster vector fixed_effects character matrix fixed effect groups ci boolean T returns confidence intervals p-values se_type character denoting kind SEs return has_int logical, whether model intercept, used \\(R^2\\) alpha numeric denoting test size confidence intervals return_vcov logical, whether return vcov matrix later usage return_fit logical, whether return fitted values try_cholesky logical, whether try using cholesky decomposition solve LS instead QR decomposition iv_stage list length two, first element denotes stage 2SLS IV estimation, 0 used OLS. second element used second stage 2SLS first stage design matrix. OLS, default, list(0), first stage 2SLS list(1), second stage 2SLS list(2, first_stage_design_mat).","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/na.omit_detailed.data.frame.html","id":null,"dir":"Reference","previous_headings":"","what":"Extra logging on na.omit handler — na.omit_detailed.data.frame","title":"Extra logging on na.omit handler — na.omit_detailed.data.frame","text":"Extra logging na.omit handler","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/na.omit_detailed.data.frame.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extra logging on na.omit handler — na.omit_detailed.data.frame","text":"","code":"na.omit_detailed.data.frame(object)"},{"path":"https://declaredesign.org/r/estimatr/reference/na.omit_detailed.data.frame.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extra logging on na.omit handler — na.omit_detailed.data.frame","text":"object data.frame","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/na.omit_detailed.data.frame.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extra logging on na.omit handler — na.omit_detailed.data.frame","text":"normal omit object, extra attribute why_omit, contains leftmost column containing NA row dropped, column name, dropped.","code":""},{"path":[]},{"path":"https://declaredesign.org/r/estimatr/reference/permutations_to_condition_pr_mat.html","id":null,"dir":"Reference","previous_headings":"","what":"Builds condition probability matrices for Horvitz-Thompson estimation from\npermutation matrix — permutations_to_condition_pr_mat","title":"Builds condition probability matrices for Horvitz-Thompson estimation from\npermutation matrix — permutations_to_condition_pr_mat","text":"Builds condition probability matrices Horvitz-Thompson estimation permutation matrix","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/permutations_to_condition_pr_mat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Builds condition probability matrices for Horvitz-Thompson estimation from\npermutation matrix — permutations_to_condition_pr_mat","text":"","code":"permutations_to_condition_pr_mat(permutations)"},{"path":"https://declaredesign.org/r/estimatr/reference/permutations_to_condition_pr_mat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Builds condition probability matrices for Horvitz-Thompson estimation from\npermutation matrix — permutations_to_condition_pr_mat","text":"permutations matrix rows units columns different treatment permutations; treated units must represented 1 control units 0","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/permutations_to_condition_pr_mat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Builds condition probability matrices for Horvitz-Thompson estimation from\npermutation matrix — permutations_to_condition_pr_mat","text":"numeric 2n*2n matrix marginal joint condition treatment probabilities passed condition_pr_mat argument horvitz_thompson.","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/permutations_to_condition_pr_mat.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Builds condition probability matrices for Horvitz-Thompson estimation from\npermutation matrix — permutations_to_condition_pr_mat","text":"function takes matrix permutations, example obtain_permutation_matrix function randomizr simulation returns 2n*2n matrix can used fully specify design horvitz_thompson estimation. can read matrices documentation declaration_to_condition_pr_mat function. done passing matrix condition_pr_mat argument ","code":""},{"path":[]},{"path":"https://declaredesign.org/r/estimatr/reference/permutations_to_condition_pr_mat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Builds condition probability matrices for Horvitz-Thompson estimation from\npermutation matrix — permutations_to_condition_pr_mat","text":"","code":"# Complete randomization perms <- replicate(1000, sample(rep(0:1, each = 50))) comp_pr_mat <- permutations_to_condition_pr_mat(perms)  # Arbitrary randomization possible_treats <- cbind(   c(1, 1, 0, 1, 0, 0, 0, 1, 1, 0),   c(0, 1, 1, 0, 1, 1, 0, 1, 0, 1),   c(1, 0, 1, 1, 1, 1, 1, 0, 0, 0) ) arb_pr_mat <- permutations_to_condition_pr_mat(possible_treats) # Simulating a column to be realized treatment z <- possible_treats[, sample(ncol(possible_treats), size = 1)] y <- rnorm(nrow(possible_treats)) horvitz_thompson(y ~ z, condition_pr_mat = arb_pr_mat) #>    Estimate Std. Error   t value  Pr(>|t|) CI Lower CI Upper DF #> z 0.2434772  0.6767714 0.3597629 0.7190245 -1.08297 1.569925 NA"},{"path":"https://declaredesign.org/r/estimatr/reference/predict.lm_robust.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict method for lm_robust object — predict.lm_robust","title":"Predict method for lm_robust object — predict.lm_robust","text":"Predict method lm_robust object","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/predict.lm_robust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict method for lm_robust object — predict.lm_robust","text":"","code":"# S3 method for lm_robust predict(   object,   newdata,   se.fit = FALSE,   interval = c(\"none\", \"confidence\", \"prediction\"),   alpha = 0.05,   na.action = na.pass,   pred.var = NULL,   weights,   ... )"},{"path":"https://declaredesign.org/r/estimatr/reference/predict.lm_robust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict method for lm_robust object — predict.lm_robust","text":"object object class 'lm_robust' newdata data frame look variables predict se.fit logical. Whether standard errors required, default = FALSE interval type interval calculation. Can abbreviated, default = none alpha numeric denoting test size confidence intervals na.action function determining done missing values newdata. default predict NA. pred.var variance(s) future observations assumed prediction intervals. weights variance weights prediction. can numeric vector bare (unquoted) name weights variable supplied newdata. ... arguments, unused","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/predict.lm_robust.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Predict method for lm_robust object — predict.lm_robust","text":"Produces predicted values, obtained evaluating regression function frame newdata fits lm_robust lm_lin. logical se.fit TRUE, standard errors predictions calculated. Setting intervals specifies computation confidence prediction (tolerance) intervals specified level, sometimes referred narrow vs. wide intervals. equation used standard error prediction given row data \\(x\\) : \\(\\sqrt(x \\Sigma x')\\), \\(\\Sigma\\) estimated variance-covariance matrix lm_robust. prediction intervals single observation case newdata error variance(s) pred.var. default assume future observations error variance used fitting, gotten fit lm_robust object. weights supplied, inverse used scale factor. fit weighted, default assume constant prediction variance, warning.","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/predict.lm_robust.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predict method for lm_robust object — predict.lm_robust","text":"","code":"# Set seed set.seed(42)  # Simulate data n <- 10 dat <- data.frame(y = rnorm(n), x = rnorm(n))  # Fit lm lm_out <- lm_robust(y ~ x, data = dat) # Get predicted fits fits <- predict(lm_out, newdata = dat) # With standard errors and confidence intervals fits <- predict(lm_out, newdata = dat, se.fit = TRUE, interval = \"confidence\")  # Use new data as well new_dat <- data.frame(x = runif(n, 5, 8)) predict(lm_out, newdata = new_dat) #>          1          2          3          4          5          6          7  #> -0.6633382 -0.6957332 -0.4661705 -1.0056478 -0.6934163 -0.9964482 -0.9562101  #>          8          9         10  #> -0.8134173 -1.0041648 -0.8012341   # You can also supply custom variance weights for prediction intervals new_dat$w <- runif(n) predict(lm_out, newdata = new_dat, weights = w, interval = \"prediction\") #> $fit #>              fit        lwr      upr #>  [1,] -0.6633382  -5.162176 3.835499 #>  [2,] -0.6957332  -5.207346 3.815879 #>  [3,] -0.4661705  -4.414089 3.481748 #>  [4,] -1.0056478  -5.520872 3.509577 #>  [5,] -0.6934163 -10.799452 9.412619 #>  [6,] -0.9964482  -5.514685 3.521789 #>  [7,] -0.9562101  -5.438922 3.526502 #>  [8,] -0.8134173  -6.558348 4.931514 #>  [9,] -1.0041648  -6.438104 4.429774 #> [10,] -0.8012341  -5.137823 3.535355 #>"},{"path":"https://declaredesign.org/r/estimatr/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. generics glance, tidy","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/starprep.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare model fits for stargazer — starprep","title":"Prepare model fits for stargazer — starprep","text":"Prepare model fits stargazer","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/starprep.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare model fits for stargazer — starprep","text":"","code":"starprep(   ...,   stat = c(\"std.error\", \"statistic\", \"p.value\", \"ci\", \"df\"),   se_type = NULL,   clusters = NULL,   alpha = 0.05 )"},{"path":"https://declaredesign.org/r/estimatr/reference/starprep.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare model fits for stargazer — starprep","text":"... list lm_robust lm objects stat either \"std.error\" (default), \"statistic\" (t-statistic), \"p.value\", \"ci\", \"df\" se_type (optional) objects lm objects, standard errors used. Must one type used lm objects passed starprep. See commarobust . clusters (optional) objects lm objects, clusters used, clusters used. Must one vector used lm objects passed starprep. See commarobust . alpha (optional) objects lm objects, significance level used p-values confidence intervals","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/starprep.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare model fits for stargazer — starprep","text":"list vectors extracted statistics stargazers","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/starprep.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Prepare model fits for stargazer — starprep","text":"Used help extract statistics lists model fits stargazer. Prefers lm_robust objects, stargazer work lm_robust objects, starprep can also take lm objects calls commarobust get preferred, robust statistics.","code":""},{"path":"https://declaredesign.org/r/estimatr/reference/starprep.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prepare model fits for stargazer — starprep","text":"","code":"library(stargazer) #>  #> Please cite as:  #>  Hlavac, Marek (2022). stargazer: Well-Formatted Regression and Summary Statistics Tables. #>  R package version 5.2.3. https://CRAN.R-project.org/package=stargazer   lm1 <- lm(mpg ~ hp, data = mtcars) lm2 <- lm(mpg ~ hp + wt, data = mtcars)  # Use default \"HC2\" standard errors stargazer(lm1, lm2,           se = starprep(lm1, lm2),           p = starprep(lm1, lm2, stat = \"p.value\"),           omit.stat = \"f\") #>  #> % Table created by stargazer v.5.2.3 by Marek Hlavac, Social Policy Institute. E-mail: marek.hlavac at gmail.com #> % Date and time: Tue, Mar 05, 2024 - 23:08:42 #> \\begin{table}[!htbp] \\centering  #>   \\caption{}  #>   \\label{}  #> \\begin{tabular}{@{\\extracolsep{5pt}}lcc}  #> \\\\[-1.8ex]\\hline  #> \\hline \\\\[-1.8ex]  #>  & \\multicolumn{2}{c}{\\textit{Dependent variable:}} \\\\  #> \\cline{2-3}  #> \\\\[-1.8ex] & \\multicolumn{2}{c}{mpg} \\\\  #> \\\\[-1.8ex] & (1) & (2)\\\\  #> \\hline \\\\[-1.8ex]  #>  hp & $-$0.068$^{***}$ & $-$0.032$^{***}$ \\\\  #>   & (0.015) & (0.008) \\\\  #>   & & \\\\  #>  wt &  & $-$3.878$^{***}$ \\\\  #>   &  & (0.688) \\\\  #>   & & \\\\  #>  Constant & 30.099$^{***}$ & 37.227$^{***}$ \\\\  #>   & (2.193) & (2.078) \\\\  #>   & & \\\\  #> \\hline \\\\[-1.8ex]  #> Observations & 32 & 32 \\\\  #> R$^{2}$ & 0.602 & 0.827 \\\\  #> Adjusted R$^{2}$ & 0.589 & 0.815 \\\\  #> Residual Std. Error & 3.863 (df = 30) & 2.593 (df = 29) \\\\  #> \\hline  #> \\hline \\\\[-1.8ex]  #> \\textit{Note:}  & \\multicolumn{2}{r}{$^{*}$p$<$0.1; $^{**}$p$<$0.05; $^{***}$p$<$0.01} \\\\  #> \\end{tabular}  #> \\end{table}  # NB: We remove the F-stat because stargazer only can use original F-stat # which uses classical SEs  # Use default \"CR2\" standard errors with clusters stargazer(lm1, lm2,           se = starprep(lm1, lm2, clusters = mtcars$carb),           p = starprep(lm1, lm2, clusters = mtcars$carb, stat = \"p.value\"),           omit.stat = \"f\") #>  #> % Table created by stargazer v.5.2.3 by Marek Hlavac, Social Policy Institute. E-mail: marek.hlavac at gmail.com #> % Date and time: Tue, Mar 05, 2024 - 23:08:43 #> \\begin{table}[!htbp] \\centering  #>   \\caption{}  #>   \\label{}  #> \\begin{tabular}{@{\\extracolsep{5pt}}lcc}  #> \\\\[-1.8ex]\\hline  #> \\hline \\\\[-1.8ex]  #>  & \\multicolumn{2}{c}{\\textit{Dependent variable:}} \\\\  #> \\cline{2-3}  #> \\\\[-1.8ex] & \\multicolumn{2}{c}{mpg} \\\\  #> \\\\[-1.8ex] & (1) & (2)\\\\  #> \\hline \\\\[-1.8ex]  #>  hp & $-$0.068$^{**}$ & $-$0.032$^{**}$ \\\\  #>   & (0.015) & (0.008) \\\\  #>   & & \\\\  #>  wt &  & $-$3.878$^{*}$ \\\\  #>   &  & (1.025) \\\\  #>   & & \\\\  #>  Constant & 30.099$^{***}$ & 37.227$^{***}$ \\\\  #>   & (2.304) & (2.807) \\\\  #>   & & \\\\  #> \\hline \\\\[-1.8ex]  #> Observations & 32 & 32 \\\\  #> R$^{2}$ & 0.602 & 0.827 \\\\  #> Adjusted R$^{2}$ & 0.589 & 0.815 \\\\  #> Residual Std. Error & 3.863 (df = 30) & 2.593 (df = 29) \\\\  #> \\hline  #> \\hline \\\\[-1.8ex]  #> \\textit{Note:}  & \\multicolumn{2}{r}{$^{*}$p$<$0.1; $^{**}$p$<$0.05; $^{***}$p$<$0.01} \\\\  #> \\end{tabular}  #> \\end{table}   # Can also specify significance levels and different standard errors stargazer(lm1, lm2,           ci.custom = starprep(lm1, lm2, se_type = \"HC3\", alpha = 0.1, stat = \"ci\"),           omit.stat = \"f\") #>  #> % Table created by stargazer v.5.2.3 by Marek Hlavac, Social Policy Institute. E-mail: marek.hlavac at gmail.com #> % Date and time: Tue, Mar 05, 2024 - 23:08:43 #> \\begin{table}[!htbp] \\centering  #>   \\caption{}  #>   \\label{}  #> \\begin{tabular}{@{\\extracolsep{5pt}}lcc}  #> \\\\[-1.8ex]\\hline  #> \\hline \\\\[-1.8ex]  #>  & \\multicolumn{2}{c}{\\textit{Dependent variable:}} \\\\  #> \\cline{2-3}  #> \\\\[-1.8ex] & \\multicolumn{2}{c}{mpg} \\\\  #> \\\\[-1.8ex] & (1) & (2)\\\\  #> \\hline \\\\[-1.8ex]  #>  hp & $-$0.068$^{***}$ & $-$0.032$^{***}$ \\\\  #>   & ($-$0.096, $-$0.040) & ($-$0.048, $-$0.016) \\\\  #>   & & \\\\  #>  wt &  & $-$3.878$^{***}$ \\\\  #>   &  & ($-$5.184, $-$2.572) \\\\  #>   & & \\\\  #>  Constant & 30.099$^{***}$ & 37.227$^{***}$ \\\\  #>   & (26.008, 34.189) & (33.439, 41.016) \\\\  #>   & & \\\\  #> \\hline \\\\[-1.8ex]  #> Observations & 32 & 32 \\\\  #> R$^{2}$ & 0.602 & 0.827 \\\\  #> Adjusted R$^{2}$ & 0.589 & 0.815 \\\\  #> Residual Std. Error & 3.863 (df = 30) & 2.593 (df = 29) \\\\  #> \\hline  #> \\hline \\\\[-1.8ex]  #> \\textit{Note:}  & \\multicolumn{2}{r}{$^{*}$p$<$0.1; $^{**}$p$<$0.05; $^{***}$p$<$0.01} \\\\  #> \\end{tabular}  #> \\end{table}"},{"path":"https://declaredesign.org/r/estimatr/news/index.html","id":"estimatr-100","dir":"Changelog","previous_headings":"","what":"estimatr 1.0.0","title":"estimatr 1.0.0","text":"CRAN release: 2022-07-04 Version bump coincide DeclareDesign package version 1.0.0 Tests edited","code":""},{"path":"https://declaredesign.org/r/estimatr/news/index.html","id":"estimatr-0306","dir":"Changelog","previous_headings":"","what":"estimatr 0.30.6","title":"estimatr 0.30.6","text":"CRAN release: 2022-01-31 Fix tests address CRAN failures","code":""},{"path":"https://declaredesign.org/r/estimatr/news/index.html","id":"estimatr-0304","dir":"Changelog","previous_headings":"","what":"estimatr 0.30.4","title":"estimatr 0.30.4","text":"CRAN release: 2021-11-07 Bug fix tidy handling conf.level Bug fix lh_robust tidy","code":""},{"path":"https://declaredesign.org/r/estimatr/news/index.html","id":"estimatr-0302","dir":"Changelog","previous_headings":"","what":"estimatr 0.30.2","title":"estimatr 0.30.2","text":"CRAN release: 2021-01-17 Remove lfe tests","code":""},{"path":"https://declaredesign.org/r/estimatr/news/index.html","id":"estimatr-0300","dir":"Changelog","previous_headings":"","what":"estimatr 0.30.0","title":"estimatr 0.30.0","text":"CRAN release: 2021-01-07 Test suite changes (skip installed checking packages)","code":""},{"path":"https://declaredesign.org/r/estimatr/news/index.html","id":"estimatr-0280","dir":"Changelog","previous_headings":"","what":"estimatr 0.28.0","title":"estimatr 0.28.0","text":"CRAN release: 2020-11-19 Test suite changes","code":""},{"path":"https://declaredesign.org/r/estimatr/news/index.html","id":"estimatr-0260","dir":"Changelog","previous_headings":"","what":"estimatr 0.26.0","title":"estimatr 0.26.0","text":"CRAN release: 2020-09-07 Test suite changes","code":""},{"path":"https://declaredesign.org/r/estimatr/news/index.html","id":"estimatr-0240","dir":"Changelog","previous_headings":"","what":"estimatr 0.24.0","title":"estimatr 0.24.0","text":"CRAN release: 2020-09-02 tidy: rename nobs, nclusters, nblocks tidy: new arguments conf.int, conf.level Added update.iv_robust() Bug fix regarding fixed effects large numbers","code":""},{"path":"https://declaredesign.org/r/estimatr/news/index.html","id":"estimatr-0220","dir":"Changelog","previous_headings":"","what":"estimatr 0.22.0","title":"estimatr 0.22.0","text":"CRAN release: 2020-03-19 Bug fixes","code":""},{"path":"https://declaredesign.org/r/estimatr/news/index.html","id":"estimatr-0200","dir":"Changelog","previous_headings":"","what":"estimatr 0.20.0","title":"estimatr 0.20.0","text":"CRAN release: 2019-09-09 Added support emmeans (thanks @rvlenth)! Fixed bug estimating diagnostics iv_robust() without explicitly specifying se_type (issue #310) Support rlang 0.4.0","code":""},{"path":"https://declaredesign.org/r/estimatr/news/index.html","id":"estimatr-0180","dir":"Changelog","previous_headings":"","what":"estimatr 0.18.0","title":"estimatr 0.18.0","text":"CRAN release: 2019-05-26 Fixed bug collinear covariates caused fixed effects estimator crash (issue #294) Added glance.lh_robust() fixed issues printing summarizing lh_robust() objects (issues #295 #296) Fixes CRAN errors testing new clubSandwich package","code":""},{"path":"https://declaredesign.org/r/estimatr/news/index.html","id":"estimatr-0160","dir":"Changelog","previous_headings":"","what":"estimatr 0.16.0","title":"estimatr 0.16.0","text":"Add diagnostics iv_robust() Add glance() methods estimators Add lh_robust() easy interface car::linearHypothesis() Fixed minor bug formula .na(var) covariates formula lm_lin() (issue #283)","code":""},{"path":"https://declaredesign.org/r/estimatr/news/index.html","id":"estimatr-0140","dir":"Changelog","previous_headings":"","what":"estimatr 0.14.0","title":"estimatr 0.14.0","text":"Removes broom hack tidy method instead relies importing generics","code":""},{"path":"https://declaredesign.org/r/estimatr/news/index.html","id":"estimatr-0120","dir":"Changelog","previous_headings":"","what":"estimatr 0.12.0","title":"estimatr 0.12.0","text":"Fixed ambiguity interacted covariates centered lm_lin Fixed bug pointed James Pustejovsky via sandwich version 2.5-0 -diagonal blocks multivariate regression vcov matrices Fixed bugs lm_lin preventing multivariate regression Fixed bug truncated degrees freedom “CR2” standard errors Fixed bug returned incorrect R-squared second later outcomes Fixed bug preventing integration latest version margins Fixed bug difference_in_means using condition1 condition2 subset treatment vector two treatment conditions. Previous estimates standard errors incorrect.","code":""},{"path":"https://declaredesign.org/r/estimatr/news/index.html","id":"estimatr-0100","dir":"Changelog","previous_headings":"","what":"estimatr 0.10.0","title":"estimatr 0.10.0","text":"CRAN release: 2018-07-12 Changed names confidence interval columns tidied data ci.lower ci.upper conf.low conf.high line tidy methods Added support fixed_effects just one block Added support specifing condition_prs horvitz_thompson() single number Added t- z-statistics output Limit unnecessary messaging horvitz_thompson()","code":""},{"path":"https://declaredesign.org/r/estimatr/news/index.html","id":"estimatr-080","dir":"Changelog","previous_headings":"","what":"estimatr 0.8.0","title":"estimatr 0.8.0","text":"CRAN release: 2018-06-02 Added support absorbing fixed effects lm_robust iv_robust Added commarobust starprep stargazer integration Added texreg support 2SLS IV models Fixed bugs incorrect F-statistics robust standard errors Refactor main fitting engine linear models","code":""},{"path":"https://declaredesign.org/r/estimatr/news/index.html","id":"estimatr-060","dir":"Changelog","previous_headings":"","what":"estimatr 0.6.0","title":"estimatr 0.6.0","text":"CRAN release: 2018-03-28 Added support multivariate linear models Added support instrumental variables regression old -> new coefficient_names -> term se -> std.error p -> p.values ci_lower -> ci.lower ci_upper -> ci.upper changes also made column names output tidy; furthermore tidy objects one name change coefficients -> estimate made Fixed bug caused variances, standard errors, p-values wrong weighted “CR2” variance estimation Fixed incorrect estimates weights blocks passed difference_in_means Rewrite NSE handling done rlang Rewrite na.omit handler R Major refactor C++ underlying regression estimators","code":""},{"path":"https://declaredesign.org/r/estimatr/news/index.html","id":"estimatr-040","dir":"Changelog","previous_headings":"","what":"estimatr 0.4.0","title":"estimatr 0.4.0","text":"CRAN release: 2018-02-15 Changed suffix added centered variables lm_lin() _bar _c Added vignettes .Rbuildignore, available website now Fixed lm_robust_helper.cpp algorithm catch exception deal valgrind memory errors Bugfix passing formula object within function fail Simplified tests various CRAN test platforms","code":""},{"path":"https://declaredesign.org/r/estimatr/news/index.html","id":"estimatr-020","dir":"Changelog","previous_headings":"","what":"estimatr 0.2.0","title":"estimatr 0.2.0","text":"CRAN release: 2018-01-29 First CRAN upload","code":""}]
