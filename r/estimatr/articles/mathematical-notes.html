<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Mathematical notes for estimatr • estimatr</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Mathematical notes for estimatr">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">estimatr</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="Released version">1.0.2</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../articles/getting-started.html">Getting started</a></li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/getting-started.html">Getting started using estimatr</a></li>
    <li><a class="dropdown-item" href="../articles/absorbing-fixed-effects.html">Absorbing Fixed Effects with estimatr</a></li>
    <li><a class="dropdown-item" href="../articles/estimatr-in-the-tidyverse.html">estimatr in the Tidyverse</a></li>
    <li><a class="dropdown-item" href="../articles/benchmarking-estimatr.html">Benchmarking estimatr</a></li>
    <li><a class="dropdown-item" href="../articles/emmeans-examples.html">Examples with emmeans</a></li>
    <li><a class="dropdown-item" href="../articles/mathematical-notes.html">Mathematical notes for estimatr</a></li>
    <li><a class="dropdown-item" href="../articles/regression-tables.html">Regression Tables with estimatr</a></li>
    <li><a class="dropdown-item" href="../articles/simulations-debiasing-dim.html">Simulations - Debiasing Difference-in-Means</a></li>
    <li><a class="dropdown-item" href="../articles/simulations-ols-variance.html">Simulations - OLS and Variance</a></li>
    <li><a class="dropdown-item" href="../articles/stata-wls-hat.html">How Stata's hat matrix differs with weights</a></li>
  </ul>
</li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-software" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Software</button>
  <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="dropdown-software">
<li><a class="external-link dropdown-item" href="http://declaredesign.org/r/declaredesign/">DeclareDesign</a></li>
    <li><a class="external-link dropdown-item" href="https://declaredesign.org/r/randomizr/">randomizr</a></li>
    <li><a class="external-link dropdown-item" href="https://declaredesign.org/r/fabricatr/">fabricatr</a></li>
    <li><a class="dropdown-item" href="https://declaredesign.org/r/estimatr/">estimatr</a></li>
    <li><a class="external-link dropdown-item" href="https://declaredesign.org/r/designlibrary/">DesignLibrary</a></li>
    <li><a class="external-link dropdown-item" href="https://eos.wzb.eu/ipi/DDWizard/">DesignWizard</a></li>
  </ul>
</li>
<li class="nav-item"><a class="external-link nav-link" href="https://declaredesign.org">declaredesign.org</a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">



<script src="mathematical-notes_files/accessible-code-block-0.0.1/empty-anchor.js"></script><div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Mathematical notes for estimatr</h1>
                        <h4 data-toc-skip class="author">Luke Sonnet</h4>
            
      
      <small class="dont-index">Source: <a href="https://github.com/DeclareDesign/estimatr/blob/main/vignettes/mathematical-notes.Rmd" class="external-link"><code>vignettes/mathematical-notes.Rmd</code></a></small>
      <div class="d-none name"><code>mathematical-notes.Rmd</code></div>
    </div>

    
    
<p>This document provides the mathematical notes for each of the estimators in <code>estimatr</code>. The most up-to-date version of this can be found on the <a href="/r/estimatr/articles/mathematical-notes.html">DeclareDesign website here</a>.</p>
<div class="section level2">
<h2 id="estimators">Estimators<a class="anchor" aria-label="anchor" href="#estimators"></a>
</h2>
<p>The current estimators we provide are:</p>
<ul>
<li>
<a href="#lm_robust-notes"><code>lm_robust</code></a> - for fitting linear models with heteroskedasticity/cluster-robust standard errors</li>
<li>
<a href="#lm_lin-notes"><code>lm_lin</code></a> - a wrapper for <code><a href="../reference/lm_robust.html">lm_robust()</a></code> to simplify interacting centered pre-treatment covariates with a treatment variable</li>
<li>
<a href="#iv_robust-notes"><code>iv_robust</code></a> - two stage least squares estimation of instrumental variables regression</li>
<li>
<a href="#difference_in_means-notes"><code>difference_in_means</code></a> - for estimating differences in means with appropriate standard errors for unit-randomized, cluster-randomized, block-randomized, matched-pair randomized, and matched-pair clustered designs</li>
<li>
<a href="#horvitz_thompson-notes"><code>horvitz_thompson</code></a> - for estimating average treatment effects taking into consideration treatment probabilities or sampling probabilities for simple and cluster randomized designs</li>
</ul>
<div class="section level3">
<h3 id="lm_robust-notes">
<code>lm_robust</code> notes<a class="anchor" aria-label="anchor" href="#lm_robust-notes"></a>
</h3>
<p>The <a href="#lm_robust"><code>lm_robust</code></a> method uses the C++ library <a href="https://eigen.tuxfamily.org/" class="external-link">Eigen</a>, via the <a href="https://github.com/RcppCore/RcppEigen" class="external-link"><code>RcppEigen</code></a> package, to estimate the coefficients, variance-covariance matrix, and, in some cases, the degrees of freedom of linear models.</p>
<p>The default estimators have been selected for efficiency in large samples and low bias in small samples as well as for their similarities to design-based randomization estimators <span class="citation">(Samii and Aronow <a href="#ref-samiiaronow2012" role="doc-biblioref">2012</a>)</span>. This section outlines the various kinds of variance estimators one can employ within <code>lm_robust</code>.</p>
<div class="section level4">
<h4 id="coefficient-estimates">Coefficient estimates<a class="anchor" aria-label="anchor" href="#coefficient-estimates"></a>
</h4>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mi>β</mi><mo accent="true">̂</mo></mover><mo>=</mo><mo stretchy="false" form="prefix">(</mo><msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mi>⊤</mi></msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><msup><mo stretchy="false" form="postfix">)</mo><mrow><mo>−</mo><mn>1</mn></mrow></msup><msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mi>⊤</mi></msup><mstyle mathvariant="bold"><mi>𝐲</mi></mstyle></mrow><annotation encoding="application/x-tex">
\widehat{\beta} =(\mathbf{X}^{\top}\mathbf{X})^{-1}\mathbf{X}^{\top}\mathbf{y}
</annotation></semantics></math></p>
<p>Our algorithm solves the least squares problem using a rank-revealing column-pivoting QR factorization that eliminates the need to invert <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">(</mo><msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mi>⊤</mi></msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><msup><mo stretchy="false" form="postfix">)</mo><mrow><mo>−</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">(\mathbf{X}^{\top}\mathbf{X})^{-1}</annotation></semantics></math> explicitly and behaves much like the default <code>lm</code> function in R. However, when <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><annotation encoding="application/x-tex">\mathbf{X}</annotation></semantics></math> is rank deficient, there are certain conditions under which the QR factorization algorithm we use, from the Eigen C++ library, drops different coefficients from the output than the default <code>lm</code> function. In general, users should avoid specifying models with rank-deficiencies. In fact, if users are certain their data are not rank deficient, they can improve the speed of <code>lm_robust</code> by setting <code>try_cholesky = TRUE</code>. This replaces the QR factorization with a Cholesky factorization that is only guaranteed to work <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><annotation encoding="application/x-tex">\mathbf{X}</annotation></semantics></math> is of full rank.</p>
<div class="section level5">
<h5 id="weights">Weights<a class="anchor" aria-label="anchor" href="#weights"></a>
</h5>
<p>If weights are included, we transform the data as below and then proceed as normal, following advice from <span class="citation">Romano and Wolf (<a href="#ref-romanowolf2017" role="doc-biblioref">2017</a>)</span> that this weighted estimator has attractive properties. We do so by first scaling all of the weights so that they sum to one. Then we multiply each row of the design matrix <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><annotation encoding="application/x-tex">\mathbf{X}</annotation></semantics></math> by the square root each unit’s weight, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mstyle mathvariant="bold"><mi>𝐱</mi></mstyle><mi>i</mi></msub><msqrt><msub><mi>w</mi><mi>i</mi></msub></msqrt></mrow><annotation encoding="application/x-tex">\mathbf{x}_i \sqrt{w_i}</annotation></semantics></math>, and then do the same to the outcome, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mstyle mathvariant="bold"><mi>𝐲</mi></mstyle><mi>i</mi></msub><msqrt><msub><mi>w</mi><mi>i</mi></msub></msqrt></mrow><annotation encoding="application/x-tex">\mathbf{y}_i \sqrt{w_i}</annotation></semantics></math>. This results in our coefficients being estimated as follows, where <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mstyle mathvariant="bold"><mi>𝐖</mi></mstyle><annotation encoding="application/x-tex">\mathbf{W}</annotation></semantics></math> is a diagonal matrix with the scaled weights on the diagonal.</p>
<p>Weighted: <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mi>β</mi><mo accent="true">̂</mo></mover><mo>=</mo><mo stretchy="false" form="prefix">(</mo><msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mi>⊤</mi></msup><mstyle mathvariant="bold"><mi>𝐖</mi></mstyle><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><msup><mo stretchy="false" form="postfix">)</mo><mrow><mo>−</mo><mn>1</mn></mrow></msup><msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mi>⊤</mi></msup><mstyle mathvariant="bold"><mi>𝐖</mi></mstyle><mstyle mathvariant="bold"><mi>𝐲</mi></mstyle></mrow><annotation encoding="application/x-tex">
\widehat{\beta} =(\mathbf{X}^{\top}\mathbf{W}\mathbf{X})^{-1}\mathbf{X}^{\top}\mathbf{W}\mathbf{y}
</annotation></semantics></math></p>
<p>The transformed data are then used in the analysis below, where <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">(</mo><msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mi>⊤</mi></msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><msup><mo stretchy="false" form="postfix">)</mo><mrow><mo>−</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">(\mathbf{X}^{\top}\mathbf{X})^{-1}</annotation></semantics></math> is now <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">(</mo><msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mi>⊤</mi></msup><mstyle mathvariant="bold"><mi>𝐖</mi></mstyle><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><msup><mo stretchy="false" form="postfix">)</mo><mrow><mo>−</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">(\mathbf{X}^{\top}\mathbf{W}\mathbf{X})^{-1}</annotation></semantics></math> and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><annotation encoding="application/x-tex">\mathbf{X}</annotation></semantics></math> is now <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mstyle mathvariant="normal"><mi>s</mi><mi>q</mi><mi>r</mi><mi>t</mi></mstyle><mo stretchy="false" form="prefix">[</mo><mi>W</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathbf{X} \mathrm{sqrt}[W]</annotation></semantics></math>, where <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathvariant="normal"><mi>s</mi><mi>q</mi><mi>r</mi><mi>t</mi></mstyle><mo stretchy="false" form="prefix">[</mo><mi>.</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathrm{sqrt}[.]</annotation></semantics></math> is an operator that applies a square root to the coefficients of some matrix.</p>
<p>We should note that this transformation yields the same standard errors as specifying weights using <code>aweight</code> in Stata for the “classical”, “HC0”, and “HC1” (“stata”) variance estimators. Furthermore, in the clustered case, our weighted estimator for the “stata” cluster-robust variance also matches Stata. Thus Stata’s main robust standard error estimators, “HC1” and their clustered estimator, match our package when weights are applied. Nonetheless, Stata uses a slightly different Hat matrix and thus “HC2” and “HC3” estimates in Stata when weights are specified may differ from our estimates—<a href="/r/estimatr/articles/stata-wls-hat.html">more on that here</a>.</p>
</div>
</div>
<div class="section level4">
<h4 id="variance">Variance<a class="anchor" aria-label="anchor" href="#variance"></a>
</h4>
<p>In addition to solving for OLS coefficients faster than <code>lm</code>, we provide a variety of robust variance estimators. Below we outline them for the non-clustered and clustered cases. You can see some simulations about the unbiasedness of the classical variance estimators with homoskedasticity and the consistency of the HC2 estimators with heteroskedasticity in <a href="/r/estimatr/articles/simulations-ols-variance.html">these simulations</a>.</p>
<div class="section level5">
<h5 id="heteroskedasticity-robust-variance-and-degrees-of-freedom">Heteroskedasticity-Robust Variance and Degrees of Freedom<a class="anchor" aria-label="anchor" href="#heteroskedasticity-robust-variance-and-degrees-of-freedom"></a>
</h5>
<p>The default variance estimator without clusters is the HC2 variance, first proposed by <span class="citation">MacKinnon and White (<a href="#ref-mackinnonwhite1985" role="doc-biblioref">1985</a>)</span>. This estimator has the advantage of being equivalent to a conservative randomization-based “Neyman” estimator of the variance <span class="citation">(Samii and Aronow <a href="#ref-samiiaronow2012" role="doc-biblioref">2012</a>)</span>. Furthermore, while it is somewhat less efficient than the HC1 variance estimator, the default in Stata, it tends to perform better in small samples (evidence for that can be found in our simulations <a href="/r/estimatr/articles/simulations-ols-variance.html#hc1-and-hc2-in-small-samples">here</a>).</p>
<table class="table">
<colgroup>
<col width="14%">
<col width="37%">
<col width="8%">
<col width="40%">
</colgroup>
<thead><tr class="header">
<th><code>se_type =</code></th>
<th>Variance Estimator (<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mstyle mathvariant="double-struck"><mi>𝕍</mi></mstyle><mo accent="true">̂</mo></mover><mo stretchy="false" form="prefix">[</mo><mover><mi>β</mi><mo accent="true">̂</mo></mover><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\widehat{\mathbb{V}}[\widehat{\beta}]</annotation></semantics></math>)</th>
<th>Degrees of Freedom</th>
<th>Notes</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><code>"classical"</code></td>
<td><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><msup><mstyle mathvariant="bold"><mi>𝐞</mi></mstyle><mi>⊤</mi></msup><mstyle mathvariant="bold"><mi>𝐞</mi></mstyle></mrow><mrow><mi>N</mi><mo>−</mo><mi>K</mi></mrow></mfrac><mo stretchy="false" form="prefix">(</mo><msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mi>⊤</mi></msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><msup><mo stretchy="false" form="postfix">)</mo><mrow><mo>−</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">\frac{\mathbf{e}^\top\mathbf{e}}{N-K} (\mathbf{X}^{\top}\mathbf{X})^{-1}</annotation></semantics></math></td>
<td>N - K</td>
<td></td>
</tr>
<tr class="even">
<td><code>"HC0"</code></td>
<td><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">(</mo><msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mi>⊤</mi></msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><msup><mo stretchy="false" form="postfix">)</mo><mrow><mo>−</mo><mn>1</mn></mrow></msup><msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mi>⊤</mi></msup><mstyle mathvariant="normal"><mi>d</mi><mi>i</mi><mi>a</mi><mi>g</mi></mstyle><mrow><mo stretchy="true" form="prefix">[</mo><msubsup><mi>e</mi><mi>i</mi><mn>2</mn></msubsup><mo stretchy="true" form="postfix">]</mo></mrow><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mo stretchy="false" form="prefix">(</mo><msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mi>⊤</mi></msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><msup><mo stretchy="false" form="postfix">)</mo><mrow><mo>−</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">(\mathbf{X}^{\top}\mathbf{X})^{-1}\mathbf{X}^{\top}\mathrm{diag}\left[e_i^2\right]\mathbf{X}(\mathbf{X}^{\top}\mathbf{X})^{-1}</annotation></semantics></math></td>
<td>N - K</td>
<td></td>
</tr>
<tr class="odd">
<td>
<code>"HC1"</code>, <code>"stata"</code>
</td>
<td><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mi>N</mi><mrow><mi>N</mi><mo>−</mo><mi>K</mi></mrow></mfrac><mo stretchy="false" form="prefix">(</mo><msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mi>⊤</mi></msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><msup><mo stretchy="false" form="postfix">)</mo><mrow><mo>−</mo><mn>1</mn></mrow></msup><msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mi>⊤</mi></msup><mstyle mathvariant="normal"><mi>d</mi><mi>i</mi><mi>a</mi><mi>g</mi></mstyle><mrow><mo stretchy="true" form="prefix">[</mo><msubsup><mi>e</mi><mi>i</mi><mn>2</mn></msubsup><mo stretchy="true" form="postfix">]</mo></mrow><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mo stretchy="false" form="prefix">(</mo><msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mi>⊤</mi></msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><msup><mo stretchy="false" form="postfix">)</mo><mrow><mo>−</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">\frac{N}{N-K}(\mathbf{X}^{\top}\mathbf{X})^{-1}\mathbf{X}^{\top}\mathrm{diag}\left[e_i^2\right]\mathbf{X}(\mathbf{X}^{\top}\mathbf{X})^{-1}</annotation></semantics></math></td>
<td>N - K</td>
<td>Often called the Eicker-Huber-White variance (or similar)</td>
</tr>
<tr class="even">
<td>
<code>"HC2"</code> (default)</td>
<td><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">(</mo><msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mi>⊤</mi></msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><msup><mo stretchy="false" form="postfix">)</mo><mrow><mo>−</mo><mn>1</mn></mrow></msup><msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mi>⊤</mi></msup><mstyle mathvariant="normal"><mi>d</mi><mi>i</mi><mi>a</mi><mi>g</mi></mstyle><mrow><mo stretchy="true" form="prefix">[</mo><mfrac><msubsup><mi>e</mi><mi>i</mi><mn>2</mn></msubsup><mrow><mn>1</mn><mo>−</mo><msub><mi>h</mi><mrow><mi>i</mi><mi>i</mi></mrow></msub></mrow></mfrac><mo stretchy="true" form="postfix">]</mo></mrow><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mo stretchy="false" form="prefix">(</mo><msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mi>⊤</mi></msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><msup><mo stretchy="false" form="postfix">)</mo><mrow><mo>−</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">(\mathbf{X}^{\top}\mathbf{X})^{-1}\mathbf{X}^{\top}\mathrm{diag}\left[\frac{e_i^2}{1-h_{ii}}\right]\mathbf{X}(\mathbf{X}^{\top}\mathbf{X})^{-1}</annotation></semantics></math></td>
<td>N - K</td>
<td></td>
</tr>
<tr class="odd">
<td><code>"HC3"</code></td>
<td><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">(</mo><msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mi>⊤</mi></msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><msup><mo stretchy="false" form="postfix">)</mo><mrow><mo>−</mo><mn>1</mn></mrow></msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mi>⊤</mi><mstyle mathvariant="normal"><mi>d</mi><mi>i</mi><mi>a</mi><mi>g</mi></mstyle><mrow><mo stretchy="true" form="prefix">[</mo><mfrac><msubsup><mi>e</mi><mi>i</mi><mn>2</mn></msubsup><mrow><mo stretchy="false" form="prefix">(</mo><mn>1</mn><mo>−</mo><msub><mi>h</mi><mrow><mi>i</mi><mi>i</mi></mrow></msub><msup><mo stretchy="false" form="postfix">)</mo><mn>2</mn></msup></mrow></mfrac><mo stretchy="true" form="postfix">]</mo></mrow><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mo stretchy="false" form="prefix">(</mo><msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mi>⊤</mi></msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><msup><mo stretchy="false" form="postfix">)</mo><mrow><mo>−</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">(\mathbf{X}^{\top}\mathbf{X})^{-1}\mathbf{X}{\top}\mathrm{diag}\left[\frac{e_i^2}{(1-h_{ii})^2}\right]\mathbf{X}(\mathbf{X}^{\top}\mathbf{X})^{-1}</annotation></semantics></math></td>
<td>N - K</td>
<td></td>
</tr>
</tbody>
</table>
<ul>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mstyle mathvariant="bold"><mi>𝐱</mi></mstyle><mi>i</mi></msub><annotation encoding="application/x-tex">\mathbf{x}_i</annotation></semantics></math> is the <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>th row of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><annotation encoding="application/x-tex">\mathbf{X}</annotation></semantics></math>.</li>
<li><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mrow><mi>i</mi><mi>i</mi></mrow></msub><mo>=</mo><msub><mstyle mathvariant="bold"><mi>𝐱</mi></mstyle><mi>i</mi></msub><mo stretchy="false" form="prefix">(</mo><msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mi>⊤</mi></msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><msup><mo stretchy="false" form="postfix">)</mo><mrow><mo>−</mo><mn>1</mn></mrow></msup><msubsup><mstyle mathvariant="bold"><mi>𝐱</mi></mstyle><mi>i</mi><mi>⊤</mi></msubsup></mrow><annotation encoding="application/x-tex">h_{ii} = \mathbf{x}_i(\mathbf{X}^{\top}\mathbf{X})^{-1}\mathbf{x}^{\top}_i</annotation></semantics></math></li>
<li><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>e</mi><mi>i</mi></msub><mo>=</mo><msub><mi>y</mi><mi>i</mi></msub><mo>−</mo><msub><mstyle mathvariant="bold"><mi>𝐱</mi></mstyle><mi>i</mi></msub><mover><mi>β</mi><mo accent="true">̂</mo></mover></mrow><annotation encoding="application/x-tex">e_i = y_i - \mathbf{x}_i\widehat{\beta}</annotation></semantics></math></li>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathvariant="normal"><mi>d</mi><mi>i</mi><mi>a</mi><mi>g</mi></mstyle><mo stretchy="false" form="prefix">[</mo><mi>.</mi><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathrm{diag}[.]</annotation></semantics></math> is an operator that creates a diagonal matrix from a vector</li>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics></math> is the number of observations</li>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>K</mi><annotation encoding="application/x-tex">K</annotation></semantics></math> is the number of elements in <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>β</mi><annotation encoding="application/x-tex">\beta</annotation></semantics></math>.</li>
</ul>
</div>
<div class="section level5">
<h5 id="cluster-robust-variance-and-degrees-of-freedom">Cluster-Robust Variance and Degrees of Freedom<a class="anchor" aria-label="anchor" href="#cluster-robust-variance-and-degrees-of-freedom"></a>
</h5>
<p>For cluster-robust inference, we provide several estimators that are essentially analogs of the heteroskedastic-consistent variance estimators for the clustered case. Our default is the CR2 variance estimator, analogous to HC2 standard errors, and perform quite well in small samples without sacrificing much in the way of efficiency in larger samples. This estimator was originally proposed in <span class="citation">Bell and McCaffrey (<a href="#ref-bellmccaffrey2002" role="doc-biblioref">2002</a>)</span>, although we implement a generalized version of the algorithm outlined in <span class="citation">Pustejovsky and Tipton (<a href="#ref-pustejovskytipton2016" role="doc-biblioref">2018</a>)</span>; these authors provide an R package for CR2 variance estimation, <a href="https://github.com/jepusto/clubSandwich" class="external-link">clubSandwich</a>, that applies these standard errors to a wide variety of models. For a good overview of the different cluster-robust variance estimators and simulations of their accuracy in small samples, again users can see <span class="citation">Imbens and Kolesar (<a href="#ref-imbenskolesar2016" role="doc-biblioref">2016</a>)</span>. For an overview of when to use cluster-robust estimators, especially in an experimental setting, see <span class="citation">Abadie et al. (<a href="#ref-abadieetal2017" role="doc-biblioref">2017</a>)</span>.</p>
<table class="table">
<colgroup>
<col width="4%">
<col width="25%">
<col width="17%">
<col width="52%">
</colgroup>
<thead><tr class="header">
<th><code>se_type =</code></th>
<th>Variance Estimator (<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mstyle mathvariant="double-struck"><mi>𝕍</mi></mstyle><mo accent="true">̂</mo></mover><mo stretchy="false" form="prefix">[</mo><mover><mi>β</mi><mo accent="true">̂</mo></mover><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\widehat{\mathbb{V}}[\widehat{\beta}]</annotation></semantics></math>)</th>
<th>Degrees of Freedom</th>
<th>Notes</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><code>"CR0"</code></td>
<td><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">(</mo><msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mi>⊤</mi></msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><msup><mo stretchy="false" form="postfix">)</mo><mrow><mo>−</mo><mn>1</mn></mrow></msup><msubsup><mo>∑</mo><mrow><mi>s</mi><mo>=</mo><mn>1</mn></mrow><mi>S</mi></msubsup><mrow><mo stretchy="true" form="prefix">[</mo><msubsup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mi>s</mi><mi>⊤</mi></msubsup><msub><mstyle mathvariant="bold"><mi>𝐞</mi></mstyle><mi>s</mi></msub><msubsup><mstyle mathvariant="bold"><mi>𝐞</mi></mstyle><mi>s</mi><mi>⊤</mi></msubsup><msub><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mi>s</mi></msub><mo stretchy="true" form="postfix">]</mo></mrow><mo stretchy="false" form="prefix">(</mo><msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mi>⊤</mi></msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><msup><mo stretchy="false" form="postfix">)</mo><mrow><mo>−</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">(\mathbf{X}^{\top}\mathbf{X})^{-1} \sum^S_{s=1} \left[\mathbf{X}^\top_s \mathbf{e}_s\mathbf{e}^\top_s \mathbf{X}_s \right] (\mathbf{X}^{\top}\mathbf{X})^{-1}</annotation></semantics></math></td>
<td><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">S - 1</annotation></semantics></math></td>
<td></td>
</tr>
<tr class="even">
<td><code>"stata"</code></td>
<td><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi>N</mi><mo>−</mo><mn>1</mn></mrow><mrow><mi>N</mi><mo>−</mo><mi>K</mi></mrow></mfrac><mfrac><mi>S</mi><mrow><mi>S</mi><mo>−</mo><mn>1</mn></mrow></mfrac><mo stretchy="false" form="prefix">(</mo><msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mi>⊤</mi></msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><msup><mo stretchy="false" form="postfix">)</mo><mrow><mo>−</mo><mn>1</mn></mrow></msup><msubsup><mo>∑</mo><mrow><mi>s</mi><mo>=</mo><mn>1</mn></mrow><mi>S</mi></msubsup><mrow><mo stretchy="true" form="prefix">[</mo><msubsup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mi>s</mi><mi>⊤</mi></msubsup><msub><mstyle mathvariant="bold"><mi>𝐞</mi></mstyle><mi>s</mi></msub><msubsup><mstyle mathvariant="bold"><mi>𝐞</mi></mstyle><mi>s</mi><mi>⊤</mi></msubsup><msub><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mi>s</mi></msub><mo stretchy="true" form="postfix">]</mo></mrow><mo stretchy="false" form="prefix">(</mo><msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mi>⊤</mi></msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><msup><mo stretchy="false" form="postfix">)</mo><mrow><mo>−</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">\frac{N-1}{N-K}\frac{S}{S-1} (\mathbf{X}^{\top}\mathbf{X})^{-1} \sum^S_{s=1} \left[\mathbf{X}^\top_s \mathbf{e}_s\mathbf{e}^\top_s \mathbf{X}_s \right] (\mathbf{X}^{\top}\mathbf{X})^{-1}</annotation></semantics></math></td>
<td><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">S - 1</annotation></semantics></math></td>
<td>The Stata variance estimator is the same as the CR0 estimate but with a special finite-sample correction.</td>
</tr>
<tr class="odd">
<td>
<code>"CR2"</code> (default)</td>
<td><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">(</mo><msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mi>⊤</mi></msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><msup><mo stretchy="false" form="postfix">)</mo><mrow><mo>−</mo><mn>1</mn></mrow></msup><msubsup><mo>∑</mo><mrow><mi>s</mi><mo>=</mo><mn>1</mn></mrow><mi>S</mi></msubsup><mrow><mo stretchy="true" form="prefix">[</mo><msubsup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mi>s</mi><mi>⊤</mi></msubsup><msub><mstyle mathvariant="bold"><mi>𝐀</mi></mstyle><mi>s</mi></msub><msub><mstyle mathvariant="bold"><mi>𝐞</mi></mstyle><mi>s</mi></msub><msubsup><mstyle mathvariant="bold"><mi>𝐞</mi></mstyle><mi>s</mi><mi>⊤</mi></msubsup><msubsup><mstyle mathvariant="bold"><mi>𝐀</mi></mstyle><mi>s</mi><mi>⊤</mi></msubsup><msub><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mi>s</mi></msub><mo stretchy="true" form="postfix">]</mo></mrow><mo stretchy="false" form="prefix">(</mo><msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mi>⊤</mi></msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><msup><mo stretchy="false" form="postfix">)</mo><mrow><mo>−</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">(\mathbf{X}^{\top}\mathbf{X})^{-1} \sum^S_{s=1} \left[\mathbf{X}^\top_s \mathbf{A}_s \mathbf{e}_s\mathbf{e}^\top_s \mathbf{A}^\top_s \mathbf{X}_s \right] (\mathbf{X}^{\top}\mathbf{X})^{-1}</annotation></semantics></math></td>
<td><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mfrac><msup><mrow><mo stretchy="true" form="prefix">(</mo><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>S</mi></msubsup><msubsup><mstyle mathvariant="bold"><mi>𝐩</mi></mstyle><mi>i</mi><mi>⊤</mi></msubsup><msub><mstyle mathvariant="bold"><mi>𝐩</mi></mstyle><mi>i</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mn>2</mn></msup><mrow><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>S</mi></msubsup><msubsup><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>S</mi></msubsup><msup><mrow><mo stretchy="true" form="prefix">(</mo><msubsup><mstyle mathvariant="bold"><mi>𝐩</mi></mstyle><mi>i</mi><mi>⊤</mi></msubsup><msub><mstyle mathvariant="bold"><mi>𝐩</mi></mstyle><mi>j</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mn>2</mn></msup></mrow></mfrac><annotation encoding="application/x-tex">\frac{\left(\sum^S_{i = 1} \mathbf{p}^\top_i \mathbf{p}_i \right)^2}{\sum^S_{i=1}\sum^S_{j=1} \left(\mathbf{p}^\top_i \mathbf{p}_j \right)^2}</annotation></semantics></math></td>
<td>These estimates of the variance and degrees of freedom come from <span class="citation">Pustejovsky and Tipton (<a href="#ref-pustejovskytipton2016" role="doc-biblioref">2018</a>)</span>, which is an extension to certain models with a particular set of dummy variables of the method proposed by <span class="citation">Bell and McCaffrey (<a href="#ref-bellmccaffrey2002" role="doc-biblioref">2002</a>)</span>. Note that the degrees of freedom can vary for each coefficient. See below for more complete notation.</td>
</tr>
</tbody>
</table>
<ul>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>S</mi><annotation encoding="application/x-tex">S</annotation></semantics></math> is the number of clusters</li>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mi>s</mi></msub><annotation encoding="application/x-tex">\mathbf{X}_s</annotation></semantics></math> is the rows of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><annotation encoding="application/x-tex">\mathbf{X}</annotation></semantics></math> that belong to cluster <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>s</mi><annotation encoding="application/x-tex">s</annotation></semantics></math>
</li>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>I</mi><mi>n</mi></msub><annotation encoding="application/x-tex">I_n</annotation></semantics></math> is an identity matrix of size <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>×</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">n\times n</annotation></semantics></math>
</li>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mstyle mathvariant="bold"><mi>𝐞</mi></mstyle><mi>s</mi></msub><annotation encoding="application/x-tex">\mathbf{e}_s</annotation></semantics></math> is the elements of the residual matrix <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mstyle mathvariant="bold"><mi>𝐞</mi></mstyle><annotation encoding="application/x-tex">\mathbf{e}</annotation></semantics></math> in cluster <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>s</mi><annotation encoding="application/x-tex">s</annotation></semantics></math>, or <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mstyle mathvariant="bold"><mi>𝐞</mi></mstyle><mi>s</mi></msub><mo>=</mo><msub><mstyle mathvariant="bold"><mi>𝐲</mi></mstyle><mi>s</mi></msub><mo>−</mo><msub><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mi>s</mi></msub><mover><mi>β</mi><mo accent="true">̂</mo></mover></mrow><annotation encoding="application/x-tex">\mathbf{e}_s = \mathbf{y}_s - \mathbf{X}_s \widehat{\beta}</annotation></semantics></math>
</li>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mstyle mathvariant="bold"><mi>𝐀</mi></mstyle><mi>s</mi></msub><annotation encoding="application/x-tex">\mathbf{A}_s</annotation></semantics></math> and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mstyle mathvariant="bold"><mi>𝐩</mi></mstyle><annotation encoding="application/x-tex">\mathbf{p}</annotation></semantics></math> are defined in the notes below</li>
</ul>
<p><strong>Further notes on CR2:</strong> The variance estimator we implement is shown in equations (4) and (5) in <span class="citation">Pustejovsky and Tipton (<a href="#ref-pustejovskytipton2016" role="doc-biblioref">2018</a>)</span> and equation (11), where we set <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mstyle mathvariant="bold"><mi>𝚽</mi></mstyle><annotation encoding="application/x-tex">\mathbf{\Phi}</annotation></semantics></math> to be <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>I</mi><annotation encoding="application/x-tex">I</annotation></semantics></math>, following <span class="citation">Bell and McCaffrey (<a href="#ref-bellmccaffrey2002" role="doc-biblioref">2002</a>)</span>. Further note that the <span class="citation">Pustejovsky and Tipton (<a href="#ref-pustejovskytipton2016" role="doc-biblioref">2018</a>)</span> CR2 estimator and the <span class="citation">Bell and McCaffrey (<a href="#ref-bellmccaffrey2002" role="doc-biblioref">2002</a>)</span> estimator are identical when <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mstyle mathvariant="bold"><msub><mi>𝐁</mi><mi>𝐬</mi></msub></mstyle><annotation encoding="application/x-tex">\mathbf{B_s}</annotation></semantics></math> is full rank. It could be rank-deficient if there were dummy variables, or fixed effects, that were also your clusters. In this case, the original <span class="citation">Bell and McCaffrey (<a href="#ref-bellmccaffrey2002" role="doc-biblioref">2002</a>)</span> estimator could not be computed. You can see the simpler <span class="citation">Bell and McCaffrey (<a href="#ref-bellmccaffrey2002" role="doc-biblioref">2002</a>)</span> estimator written up plainly on page 709 of <span class="citation">Imbens and Kolesar (<a href="#ref-imbenskolesar2016" role="doc-biblioref">2016</a>)</span> along with the degrees of freedom denoted as <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>K</mi><mrow><mi>B</mi><mi>M</mi></mrow></msub><annotation encoding="application/x-tex">K_{BM}</annotation></semantics></math>.</p>
<p>In the CR2 variance calculation, we get <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mstyle mathvariant="bold"><mi>𝐀</mi></mstyle><mi>s</mi></msub><annotation encoding="application/x-tex">\mathbf{A}_s</annotation></semantics></math> as follows:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right"><mstyle mathvariant="bold"><mi>𝐇</mi></mstyle></mtd><mtd columnalign="left"><mo>=</mo><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mo stretchy="false" form="prefix">(</mo><msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mi>⊤</mi></msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><msup><mo stretchy="false" form="postfix">)</mo><mrow><mo>−</mo><mn>1</mn></mrow></msup><msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mi>⊤</mi></msup></mtd></mtr><mtr><mtd columnalign="right"></mtd></mtr><mtr><mtd columnalign="right"></mtd></mtr><mtr><mtd columnalign="right"><msub><mstyle mathvariant="bold"><mi>𝐁</mi></mstyle><mi>s</mi></msub></mtd><mtd columnalign="left"><mo>=</mo><mo stretchy="false" form="prefix">(</mo><msub><mi>I</mi><mi>N</mi></msub><mo>−</mo><mstyle mathvariant="bold"><mi>𝐇</mi></mstyle><msub><mo stretchy="false" form="postfix">)</mo><mi>s</mi></msub><mo stretchy="false" form="prefix">(</mo><msub><mi>I</mi><mi>N</mi></msub><mo>−</mo><mstyle mathvariant="bold"><mi>𝐇</mi></mstyle><msubsup><mo stretchy="false" form="postfix">)</mo><mi>s</mi><mi>⊤</mi></msubsup></mtd></mtr><mtr><mtd columnalign="right"></mtd></mtr><mtr><mtd columnalign="right"></mtd></mtr><mtr><mtd columnalign="right"><msub><mstyle mathvariant="bold"><mi>𝐀</mi></mstyle><mi>s</mi></msub></mtd><mtd columnalign="left"><mo>=</mo><msubsup><mstyle mathvariant="bold"><mi>𝐁</mi></mstyle><mi>s</mi><mrow><mo>+</mo><mn>1</mn><mi>/</mi><mn>2</mn></mrow></msubsup></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
\mathbf{H} &amp;= \mathbf{X}(\mathbf{X}^{\top}\mathbf{X})^{-1}\mathbf{X}^\top \\\\\\
\mathbf{B}_s &amp;= (I_{N} - \mathbf{H})_s (I_{N} - \mathbf{H})^\top_s \\\\\\
\mathbf{A}_s &amp;= \mathbf{B}^{+1/2}_s
\end{aligned}
</annotation></semantics></math></p>
<p>where <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msubsup><mstyle mathvariant="bold"><mi>𝐁</mi></mstyle><mi>s</mi><mrow><mo>+</mo><mn>1</mn><mi>/</mi><mn>2</mn></mrow></msubsup><annotation encoding="application/x-tex">\mathbf{B}^{+1/2}_s</annotation></semantics></math> is the symmetric square root of the Moore–Penrose inverse of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mstyle mathvariant="bold"><mi>𝐁</mi></mstyle><mi>s</mi></msub><annotation encoding="application/x-tex">\mathbf{B}_s</annotation></semantics></math> and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">(</mo><mi>I</mi><mo>−</mo><mstyle mathvariant="bold"><mi>𝐇</mi></mstyle><msub><mo stretchy="false" form="postfix">)</mo><mi>s</mi></msub></mrow><annotation encoding="application/x-tex">(I - \mathbf{H})_s</annotation></semantics></math> are the <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>N</mi><mi>s</mi></msub><annotation encoding="application/x-tex">N_s</annotation></semantics></math> columns that correspond to cluster <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>s</mi><annotation encoding="application/x-tex">s</annotation></semantics></math>. To get the corresponding degrees of freedom, note that</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mstyle mathvariant="bold"><mi>𝐩</mi></mstyle><mi>s</mi></msub><mo>=</mo><mo stretchy="false" form="prefix">(</mo><msub><mi>I</mi><mi>N</mi></msub><mo>−</mo><mstyle mathvariant="bold"><mi>𝐇</mi></mstyle><msubsup><mo stretchy="false" form="postfix">)</mo><mi>s</mi><mi>⊤</mi></msubsup><msub><mstyle mathvariant="bold"><mi>𝐀</mi></mstyle><mi>s</mi></msub><msub><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mi>s</mi></msub><mo stretchy="false" form="prefix">(</mo><msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mi>⊤</mi></msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><msup><mo stretchy="false" form="postfix">)</mo><mrow><mo>−</mo><mn>1</mn></mrow></msup><msub><mstyle mathvariant="bold"><mi>𝐳</mi></mstyle><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">
\mathbf{p}_s = (I_N - \mathbf{H})^\top_s \mathbf{A}_s \mathbf{X}_s (\mathbf{X}^{\top}\mathbf{X})^{-1} \mathbf{z}_{k}
</annotation></semantics></math> where <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mstyle mathvariant="bold"><mi>𝐳</mi></mstyle><mi>k</mi></msub><annotation encoding="application/x-tex">\mathbf{z}_{k}</annotation></semantics></math> is a vector of length <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>K</mi><annotation encoding="application/x-tex">K</annotation></semantics></math>, the number of coefficients, where the <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>th element is 1 and all other elements are 0. The <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math> signifies the coefficient for which we are computing the degrees of freedom.</p>
</div>
</div>
<div class="section level4">
<h4 id="confidence-intervals-and-hypothesis-testing">Confidence intervals and hypothesis testing<a class="anchor" aria-label="anchor" href="#confidence-intervals-and-hypothesis-testing"></a>
</h4>
<p>If <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mover><mstyle mathvariant="double-struck"><mi>𝕍</mi></mstyle><mo accent="true">̂</mo></mover><mi>k</mi></msub><annotation encoding="application/x-tex">\widehat{\mathbb{V}}_k</annotation></semantics></math> is the <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>th diagonal element of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mstyle mathvariant="double-struck"><mi>𝕍</mi></mstyle><mo accent="true">̂</mo></mover><annotation encoding="application/x-tex">\widehat{\mathbb{V}}</annotation></semantics></math>, we build confidence intervals using the user specified <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math> as:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mstyle mathvariant="normal"><mi>C</mi><mi>I</mi></mstyle><mrow><mn>1</mn><mo>−</mo><mi>α</mi></mrow></msup><mo>=</mo><mrow><mo stretchy="true" form="prefix">(</mo><mover><msub><mi>β</mi><mi>k</mi></msub><mo accent="true">̂</mo></mover><mo>+</mo><msubsup><mi>t</mi><mrow><mi>α</mi><mi>/</mi><mn>2</mn></mrow><mrow><mi>d</mi><mi>f</mi></mrow></msubsup><msqrt><msub><mover><mstyle mathvariant="double-struck"><mi>𝕍</mi></mstyle><mo accent="true">̂</mo></mover><mi>k</mi></msub></msqrt><mo>,</mo><mover><msub><mi>β</mi><mi>k</mi></msub><mo accent="true">̂</mo></mover><mo>+</mo><msubsup><mi>t</mi><mrow><mn>1</mn><mo>−</mo><mi>α</mi><mi>/</mi><mn>2</mn></mrow><mrow><mi>d</mi><mi>f</mi></mrow></msubsup><msqrt><msub><mover><mstyle mathvariant="double-struck"><mi>𝕍</mi></mstyle><mo accent="true">̂</mo></mover><mi>k</mi></msub></msqrt><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">
\mathrm{CI}^{1-\alpha} = \left(\widehat{\beta_k} + t^{df}_{\alpha/2} \sqrt{\widehat{\mathbb{V}}_k}, \widehat{\beta_k} + t^{df}_{1 - \alpha/2} \sqrt{\widehat{\mathbb{V}}_k}\right)
</annotation></semantics></math></p>
<p>We also provide two-sided p-values using a t-distribution with the aforementioned significance level <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math> and degrees of freedom <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><mi>f</mi></mrow><annotation encoding="application/x-tex">df</annotation></semantics></math>.</p>
</div>
</div>
<div class="section level3">
<h3 id="lm_lin-notes">
<code>lm_lin</code> notes<a class="anchor" aria-label="anchor" href="#lm_lin-notes"></a>
</h3>
<p>The <a href="#lm_lin"><code>lm_lin</code></a> estimator is a data pre-processor for <code>lm_robust</code> that implements the regression method for covariate adjustment suggested by <span class="citation">Lin (<a href="#ref-lin2013" role="doc-biblioref">2013</a>)</span>.</p>
<p>This estimator works by taking the outcome and treatment variable as the main formula (<code>formula</code>) and takes a right-sided formula of all pre-treatment covariates (<code>covariates</code>). These pre-treatment covariates are then centered to be mean zero and interacted with the treatment variable before being added to the formula and passed to <code>lm_robust</code>. In other words, instead of fitting a simple model adjusting for pre-treatment covariates such as</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>=</mo><mi>τ</mi><msub><mi>z</mi><mi>i</mi></msub><mo>+</mo><msup><mstyle mathvariant="bold"><mi>𝛃</mi></mstyle><mi>⊤</mi></msup><msub><mstyle mathvariant="bold"><mi>𝐱</mi></mstyle><mi>i</mi></msub><mo>+</mo><msub><mi>ϵ</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">
y_i = \tau z_i + \mathbf{\beta}^\top \mathbf{x}_i + \epsilon_i
</annotation></semantics></math></p>
<p>with the following model</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>=</mo><mi>τ</mi><msub><mi>z</mi><mi>i</mi></msub><mo>+</mo><msup><mstyle mathvariant="bold"><mi>𝛃</mi></mstyle><mi>⊤</mi></msup><msubsup><mstyle mathvariant="bold"><mi>𝐱</mi></mstyle><mi>i</mi><mi>c</mi></msubsup><mo>+</mo><msup><mstyle mathvariant="bold"><mi>𝛄</mi></mstyle><mi>⊤</mi></msup><msubsup><mstyle mathvariant="bold"><mi>𝐱</mi></mstyle><mi>i</mi><mi>c</mi></msubsup><msub><mi>z</mi><mi>i</mi></msub><mo>+</mo><msub><mi>ϵ</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">
y_i = \tau z_i + \mathbf{\beta}^\top \mathbf{x}^c_i  + \mathbf{\gamma}^\top \mathbf{x}^c_i z_i + \epsilon_i
</annotation></semantics></math></p>
<p>where <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msubsup><mstyle mathvariant="bold"><mi>𝐱</mi></mstyle><mi>i</mi><mi>c</mi></msubsup><annotation encoding="application/x-tex">\mathbf{x}^c_i</annotation></semantics></math> is a vector of pre-treatment covariates for unit <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math> that have been centered to have mean zero and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>z</mi><mi>i</mi></msub><annotation encoding="application/x-tex">z_i</annotation></semantics></math> is an indicator for the treatment group. <span class="citation">Lin (<a href="#ref-lin2013" role="doc-biblioref">2013</a>)</span> proposed this estimator in response to the critique by <span class="citation">Freedman (<a href="#ref-freedman2008" role="doc-biblioref">2008</a>)</span> that using regression to adjust for pre-treatment covariates could bias estimates of treatment effects.</p>
<p>The estimator <code>lm_lin</code> also works for multi-valued treatments by creating a full set of dummies for each treatment level and interacting each with the centered pre-treatment covariates. The rest of the options for the function and corresponding estimation is identical to <a href="#lm_robust"><code>lm_robust</code></a>.</p>
</div>
<div class="section level3">
<h3 id="iv_robust-notes">
<code>iv_robust</code> notes<a class="anchor" aria-label="anchor" href="#iv_robust-notes"></a>
</h3>
<p>Our <a href="#iv_robust"><code>iv_robust</code></a> estimator uses a two-stage least squares estimation.</p>
<div class="section level4">
<h4 id="coefficient-estimates-1">Coefficient estimates<a class="anchor" aria-label="anchor" href="#coefficient-estimates-1"></a>
</h4>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>β</mi><mo accent="true">̂</mo></mover><mrow><mn>2</mn><mi>S</mi><mi>L</mi><mi>S</mi></mrow></msub><mo>=</mo><mo stretchy="false" form="prefix">(</mo><msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mi>⊤</mi></msup><mstyle mathvariant="bold"><msub><mi>𝐏</mi><mi>𝐳</mi></msub></mstyle><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><msup><mo stretchy="false" form="postfix">)</mo><mrow><mo>−</mo><mn>1</mn></mrow></msup><msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mi>⊤</mi></msup><mstyle mathvariant="bold"><msub><mi>𝐏</mi><mi>𝐳</mi></msub></mstyle><mstyle mathvariant="bold"><mi>𝐲</mi></mstyle><mo>,</mo></mrow><annotation encoding="application/x-tex">
\widehat{\beta}_{2SLS} =(\mathbf{X}^{\top}\mathbf{P_z}\mathbf{X})^{-1}\mathbf{X}^{\top}\mathbf{P_z}\mathbf{y},
</annotation></semantics></math></p>
<p>where <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><annotation encoding="application/x-tex">\mathbf{X}</annotation></semantics></math> are the endogenous regressors, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathvariant="bold"><msub><mi>𝐏</mi><mi>𝐙</mi></msub></mstyle><mo>=</mo><mstyle mathvariant="bold"><mi>𝐙</mi></mstyle><mo stretchy="false" form="prefix">(</mo><msup><mstyle mathvariant="bold"><mi>𝐙</mi></mstyle><mi>⊤</mi></msup><mstyle mathvariant="bold"><mi>𝐙</mi></mstyle><msup><mo stretchy="false" form="postfix">)</mo><mrow><mo>−</mo><mn>1</mn></mrow></msup><msup><mstyle mathvariant="bold"><mi>𝐙</mi></mstyle><mi>⊤</mi></msup></mrow><annotation encoding="application/x-tex">\mathbf{P_Z} = \mathbf{Z}(\mathbf{Z}^{\top}\mathbf{Z})^{-1}\mathbf{Z}^\top</annotation></semantics></math>, and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mstyle mathvariant="bold"><mi>𝐙</mi></mstyle><annotation encoding="application/x-tex">\mathbf{Z}</annotation></semantics></math> are the instruments. This is equivalent to estimating the first stage regression,</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mo>=</mo><mstyle mathvariant="bold"><mi>𝐙</mi></mstyle><msub><mi>β</mi><mrow><mi>F</mi><mi>S</mi></mrow></msub><mo>+</mo><mstyle mathvariant="bold"><mi>𝛇</mi></mstyle><mo>,</mo></mrow><annotation encoding="application/x-tex">
\mathbf{X} = \mathbf{Z}\beta_{FS} + \mathbf{\zeta},
</annotation></semantics></math></p>
<p>and using the first stage predicted values in the second stage regression,</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right"><mover><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mo accent="true">̂</mo></mover></mtd><mtd columnalign="left"><mo>=</mo><mstyle mathvariant="bold"><mi>𝐙</mi></mstyle><msub><mover><mi>β</mi><mo accent="true">̂</mo></mover><mrow><mi>F</mi><mi>S</mi></mrow></msub></mtd></mtr><mtr><mtd columnalign="right"><mstyle mathvariant="bold"><mi>𝐲</mi></mstyle></mtd><mtd columnalign="left"><mo>=</mo><mover><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mo accent="true">̂</mo></mover><msub><mi>β</mi><mrow><mn>2</mn><mi>S</mi><mi>L</mi><mi>S</mi></mrow></msub><mo>+</mo><mstyle mathvariant="bold"><mi>𝛜</mi></mstyle><mi>.</mi></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
\widehat{\mathbf{X}} &amp;= \mathbf{Z}\widehat{\beta}_{FS} \\
\mathbf{y} &amp;= \widehat{\mathbf{X}}\beta_{2SLS} + \mathbf{\epsilon}.
\end{aligned}
</annotation></semantics></math></p>
<div class="section level5">
<h5 id="weighting">Weighting<a class="anchor" aria-label="anchor" href="#weighting"></a>
</h5>
<p>When weights are applied, we use the same estimation strategy as in <code>lm_robust</code> where we first transform the data by the square root of the weights and proceed with estimation as usual.</p>
</div>
</div>
<div class="section level4">
<h4 id="variance-1">Variance<a class="anchor" aria-label="anchor" href="#variance-1"></a>
</h4>
<p>The variances estimates for <code>iv_robust</code> are the same as the estimates for <code>lm_robust</code> although two changes are made. First, we replace <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><annotation encoding="application/x-tex">\mathbf{X}</annotation></semantics></math> with the second stage regressors, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mo accent="true">̂</mo></mover><annotation encoding="application/x-tex">\widehat{\mathbf{X}}</annotation></semantics></math>, and we replace the residuals, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>e</mi><mi>i</mi></msub><annotation encoding="application/x-tex">e_i</annotation></semantics></math>, with <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathvariant="bold"><mi>𝐲</mi></mstyle><mo>−</mo><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><msub><mi>β</mi><mrow><mn>2</mn><mi>S</mi><mi>L</mi><mi>S</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\mathbf{y} - \mathbf{X} \beta_{2SLS}</annotation></semantics></math>. That is, we use the residuals from the final coefficients and the endogenous, uninstrumented regressors <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><annotation encoding="application/x-tex">\mathbf{X}</annotation></semantics></math>.</p>
<p>Because Stata does not default to using finite sample corrections and tests with its <code>ivregress 2sls</code> estimator, the correspondence between our instrumental variables estimator and theirs can be a bit unclear. The following table shows the options in Stata that correspond to our estimators.</p>
<table class="table">
<colgroup>
<col width="27%">
<col width="19%">
<col width="53%">
</colgroup>
<thead><tr class="header">
<th><code>estimatr</code></th>
<th>Stata</th>
<th>Notes</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>N/A</td>
<td><code>ivregress 2sls y (x = z)</code></td>
<td>Stata’s default has no finite sample correction (i.e., <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mover><mi>σ</mi><mo accent="true">̂</mo></mover><mn>2</mn></msup><mo>=</mo><msup><mstyle mathvariant="bold"><mi>𝐞</mi></mstyle><mi>⊤</mi></msup><mstyle mathvariant="bold"><mi>𝐞</mi></mstyle></mrow><annotation encoding="application/x-tex">\widehat{\sigma}^2 = \mathbf{e}^\top \mathbf{e}</annotation></semantics></math>). Stata here also uses z-tests.</td>
</tr>
<tr class="even">
<td><code>iv_robust(y ~ x | z, se_type = "classical")</code></td>
<td><code>ivregress 2sls y (x = z), small</code></td>
<td>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mover><mi>σ</mi><mo accent="true">̂</mo></mover><mn>2</mn></msup><mo>=</mo><mfrac><mrow><msup><mstyle mathvariant="bold"><mi>𝐞</mi></mstyle><mi>⊤</mi></msup><mstyle mathvariant="bold"><mi>𝐞</mi></mstyle></mrow><mrow><mi>N</mi><mo>−</mo><mi>k</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\widehat{\sigma}^2 = \frac{\mathbf{e}^\top \mathbf{e}}{N - k}</annotation></semantics></math>.</td>
</tr>
<tr class="odd">
<td><code>iv_robust(y ~ x | z, se_type = "HC0")</code></td>
<td><code>ivregress 2sls y (x = z), rob</code></td>
<td>Stata uses z-tests here.</td>
</tr>
<tr class="even">
<td><code>iv_robust(y ~ x | z, se_type = "HC1")</code></td>
<td><code>ivregress 2sls y (x = z), rob small</code></td>
<td></td>
</tr>
<tr class="odd">
<td>
<code>iv_robust(y ~ x | z, se_type = "HC2")</code> (default)</td>
<td>N/A</td>
<td></td>
</tr>
<tr class="even">
<td><code>iv_robust(y ~ x | z, se_type = "HC3")</code></td>
<td>N/A</td>
<td></td>
</tr>
<tr class="odd">
<td>
<code>iv_robust(y ~ x | z, clusters = clust,</code> <code>se_type = "CR0")</code>
</td>
<td><code>ivregress 2sls y (x = z), vce(cl clust)</code></td>
<td>Stata uses z-tests here.</td>
</tr>
<tr class="even">
<td>
<code>iv_robust(y ~ x | z, clusters = clust,</code> <code>se_type = "stata")</code>
</td>
<td><code>ivregress 2sls y (x = z), vce(cl clust) small</code></td>
<td></td>
</tr>
<tr class="odd">
<td>
<code>iv_robust(y ~ x | z, clusters = clust,</code> <code>se_type = "CR2")</code> (default)</td>
<td>N/A</td>
<td></td>
</tr>
</tbody>
</table>
</div>
<div class="section level4">
<h4 id="confidence-intervals-and-hypothesis-testing-1">Confidence intervals and hypothesis testing<a class="anchor" aria-label="anchor" href="#confidence-intervals-and-hypothesis-testing-1"></a>
</h4>
<p>If <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mover><mstyle mathvariant="double-struck"><mi>𝕍</mi></mstyle><mo accent="true">̂</mo></mover><mi>k</mi></msub><annotation encoding="application/x-tex">\widehat{\mathbb{V}}_k</annotation></semantics></math> is the <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>th diagonal element of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mstyle mathvariant="double-struck"><mi>𝕍</mi></mstyle><mo accent="true">̂</mo></mover><annotation encoding="application/x-tex">\widehat{\mathbb{V}}</annotation></semantics></math>, we build confidence intervals using the user specified <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math> as:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mstyle mathvariant="normal"><mi>C</mi><mi>I</mi></mstyle><mrow><mn>1</mn><mo>−</mo><mi>α</mi></mrow></msup><mo>=</mo><mrow><mo stretchy="true" form="prefix">(</mo><mover><msub><mi>β</mi><mrow><mn>2</mn><mi>S</mi><mi>L</mi><mi>S</mi><mo>,</mo><mi>k</mi></mrow></msub><mo accent="true">̂</mo></mover><mo>+</mo><msubsup><mi>t</mi><mrow><mi>α</mi><mi>/</mi><mn>2</mn></mrow><mrow><mi>d</mi><mi>f</mi></mrow></msubsup><msqrt><msub><mover><mstyle mathvariant="double-struck"><mi>𝕍</mi></mstyle><mo accent="true">̂</mo></mover><mi>k</mi></msub></msqrt><mo>,</mo><mover><msub><mi>β</mi><mrow><mn>2</mn><mi>S</mi><mi>L</mi><mi>S</mi><mo>,</mo><mi>k</mi></mrow></msub><mo accent="true">̂</mo></mover><mo>+</mo><msubsup><mi>t</mi><mrow><mn>1</mn><mo>−</mo><mi>α</mi><mi>/</mi><mn>2</mn></mrow><mrow><mi>d</mi><mi>f</mi></mrow></msubsup><msqrt><msub><mover><mstyle mathvariant="double-struck"><mi>𝕍</mi></mstyle><mo accent="true">̂</mo></mover><mi>k</mi></msub></msqrt><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">
\mathrm{CI}^{1-\alpha} = \left(\widehat{\beta_{2SLS, k}} + t^{df}_{\alpha/2} \sqrt{\widehat{\mathbb{V}}_k}, \widehat{\beta_{2SLS, k}} + t^{df}_{1 - \alpha/2} \sqrt{\widehat{\mathbb{V}}_k}\right)
</annotation></semantics></math></p>
<p>We also provide two-sided p-values using a t-distribution with the aforementioned significance level <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math> and degrees of freedom <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><mi>f</mi></mrow><annotation encoding="application/x-tex">df</annotation></semantics></math>, which come from the second-stage regression. As mentioned in the table above, these results will be different from Stata in certain cases as Stata uses z-tests when <code>small</code> is not specified.</p>
</div>
</div>
<div class="section level3">
<h3 id="difference_in_means-notes">
<code>difference_in_means</code> notes<a class="anchor" aria-label="anchor" href="#difference_in_means-notes"></a>
</h3>
<p>There are six kinds of experimental designs for which our <a href="#difference_in_means"><code>difference_in_means</code></a> estimator can estimate treatment effects, standard errors, confidence intervals, and provide p-values. We list the different designs here along with how the software learns the design:</p>
<ul>
<li>Simple (both <code>clusters</code> and <code>blocks</code> are unused)</li>
<li>Clustered (<code>clusters</code> is specified while <code>blocks</code> is not)</li>
<li>Blocked (<code>blocks</code> is specified while <code>clusters</code> is not)</li>
<li>Blocked and clustered (both are specified)</li>
</ul>
<p>There are two subsets of blocked designs that we also consider:</p>
<ul>
<li>Matched-pairs (only <code>blocks</code> is specified and all blocks are size two)</li>
<li>Matched-pair clustered design (both names are specified and each block only has two clusters)</li>
</ul>
<p>Note: if there are blocks of size two and blocks greater than size two, we default to the matched-pairs estimators described below.</p>
<p>For each design, our estimator is informed by the recent statistical literature on the analysis of experimental data.</p>
<div class="section level4">
<h4 id="estimates">Estimates<a class="anchor" aria-label="anchor" href="#estimates"></a>
</h4>
<p><strong>Any unblocked design</strong> <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mi>τ</mi><mo accent="true">̂</mo></mover><mo>=</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><msub><mi>z</mi><mi>i</mi></msub><msub><mi>y</mi><mi>i</mi></msub><mo>−</mo><mo stretchy="false" form="prefix">(</mo><mn>1</mn><mo>−</mo><msub><mi>z</mi><mi>i</mi></msub><mo stretchy="false" form="postfix">)</mo><msub><mi>y</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">
\widehat{\tau} = \frac{1}{N} \sum^N_{i=1} z_i y_i - (1 - z_i) y_i
</annotation></semantics></math> where <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>z</mi><mi>i</mi></msub><annotation encoding="application/x-tex">z_i</annotation></semantics></math> is the treatment variable, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mi>i</mi></msub><annotation encoding="application/x-tex">y_i</annotation></semantics></math> is the outcome, and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics></math> is the total number of units.</p>
<p><strong>Blocked design (including matched-pairs designs)</strong> <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mi>τ</mi><mo accent="true">̂</mo></mover><mo>=</mo><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>J</mi></munderover><mfrac><msub><mi>N</mi><mi>j</mi></msub><mi>N</mi></mfrac><mover><msub><mi>τ</mi><mi>j</mi></msub><mo accent="true">̂</mo></mover></mrow><annotation encoding="application/x-tex">
\widehat{\tau} = \sum^J_{j=1} \frac{N_j}{N} \widehat{\tau_j}
</annotation></semantics></math> where <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>J</mi><annotation encoding="application/x-tex">J</annotation></semantics></math> is the number of blocks, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>N</mi><mi>j</mi></msub><annotation encoding="application/x-tex">N_j</annotation></semantics></math> is the size of those blocks, and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><msub><mi>τ</mi><mi>j</mi></msub><mo accent="true">̂</mo></mover><annotation encoding="application/x-tex">\widehat{\tau_j}</annotation></semantics></math> is the estimated difference-in-means in block <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math>.</p>
<div class="section level5">
<h5 id="weighting-1">Weighting<a class="anchor" aria-label="anchor" href="#weighting-1"></a>
</h5>
<p>If the user specifies weights, treatment effects (or block-level treatment effects) and their standard errors are estimated by <code>lm_robust</code>. There are three exceptions. First, we still compute the degrees of freedom as in the below table. Second, if the design is blocked, a weighted treatment effect and variance estimate are computed within each block using <code>lm_robust</code> and then combined as below. Third, specifying weights with a matched-pairs estimator in <code>difference_in_means</code> is not supported at the moment.</p>
</div>
</div>
<div class="section level4">
<h4 id="variance-and-degrees-of-freedom">Variance and Degrees of Freedom<a class="anchor" aria-label="anchor" href="#variance-and-degrees-of-freedom"></a>
</h4>
<table class="table">
<colgroup>
<col width="5%">
<col width="15%">
<col width="21%">
<col width="56%">
</colgroup>
<thead><tr class="header">
<th>Design type</th>
<th>Variance <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mstyle mathvariant="double-struck"><mi>𝕍</mi></mstyle><mo accent="true">̂</mo></mover><mo stretchy="false" form="prefix">[</mo><mover><mi>τ</mi><mo accent="true">̂</mo></mover><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\widehat{\mathbb{V}}[\widehat{\tau}]</annotation></semantics></math>
</th>
<th>Degrees of Freedom</th>
<th>Notes</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>No blocks or clusters (standard)</td>
<td><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mover><mstyle mathvariant="double-struck"><mi>𝕍</mi></mstyle><mo accent="true">̂</mo></mover><mo stretchy="false" form="prefix">[</mo><msub><mi>y</mi><mrow><mi>i</mi><mo>,</mo><mn>0</mn></mrow></msub><mo stretchy="false" form="postfix">]</mo></mrow><msub><mi>N</mi><mn>0</mn></msub></mfrac><mo>+</mo><mfrac><mrow><mover><mstyle mathvariant="double-struck"><mi>𝕍</mi></mstyle><mo accent="true">̂</mo></mover><mo stretchy="false" form="prefix">[</mo><msub><mi>y</mi><mrow><mi>i</mi><mo>,</mo><mn>1</mn></mrow></msub><mo stretchy="false" form="postfix">]</mo></mrow><msub><mi>N</mi><mn>1</mn></msub></mfrac></mrow><annotation encoding="application/x-tex">\frac{\widehat{\mathbb{V}}[y_{i,0}]}{N_0} + \frac{\widehat{\mathbb{V}}[y_{i,1}]}{N_1}</annotation></semantics></math></td>
<td><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mstyle mathvariant="double-struck"><mi>𝕍</mi></mstyle><mo accent="true">̂</mo></mover><mo stretchy="false" form="prefix">[</mo><mover><mi>τ</mi><mo accent="true">̂</mo></mover><msup><mo stretchy="false" form="postfix">]</mo><mn>2</mn></msup><mrow><mo stretchy="true" form="prefix">(</mo><mfrac><mrow><mo stretchy="false" form="prefix">(</mo><mover><mstyle mathvariant="double-struck"><mi>𝕍</mi></mstyle><mo accent="true">̂</mo></mover><mo stretchy="false" form="prefix">[</mo><msub><mi>y</mi><mrow><mi>i</mi><mo>,</mo><mn>1</mn></mrow></msub><mo stretchy="false" form="postfix">]</mo><mi>/</mi><msub><mi>N</mi><mn>1</mn></msub><msup><mo stretchy="false" form="postfix">)</mo><mn>2</mn></msup></mrow><mrow><msub><mi>N</mi><mn>1</mn></msub><mo>−</mo><mn>1</mn></mrow></mfrac><mo>+</mo><mfrac><mrow><mo stretchy="false" form="prefix">(</mo><mover><mstyle mathvariant="double-struck"><mi>𝕍</mi></mstyle><mo accent="true">̂</mo></mover><mo stretchy="false" form="prefix">[</mo><msub><mi>y</mi><mrow><mi>i</mi><mo>,</mo><mn>0</mn></mrow></msub><mo stretchy="false" form="postfix">]</mo><mi>/</mi><msub><mi>N</mi><mn>0</mn></msub><msup><mo stretchy="false" form="postfix">)</mo><mn>2</mn></msup></mrow><mrow><msub><mi>N</mi><mn>0</mn></msub><mo>−</mo><mn>1</mn></mrow></mfrac><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\widehat{\mathbb{V}}[\widehat{\tau}]^2 \left(\frac{(\widehat{\mathbb{V}}[y_{i,1}]/ N_1)^2}{N_1 - 1} + \frac{(\widehat{\mathbb{V}}[y_{i,0}]/ N_0)^2}{N_0 - 1}\right)</annotation></semantics></math></td>
<td>Where <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mstyle mathvariant="double-struck"><mi>𝕍</mi></mstyle><mo accent="true">̂</mo></mover><mo stretchy="false" form="prefix">[</mo><msub><mi>y</mi><mrow><mi>i</mi><mo>,</mo><mi>k</mi></mrow></msub><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\widehat{\mathbb{V}}[y_{i,k}]</annotation></semantics></math> is the Bessel-corrected variance of all units where <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>i</mi></msub><mo>=</mo><mi>k</mi></mrow><annotation encoding="application/x-tex">z_i = k</annotation></semantics></math> and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>N</mi><mi>k</mi></msub><annotation encoding="application/x-tex">N_k</annotation></semantics></math> is the number of units in condition <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>. This is equivalent to the variance and Welch–Satterthwaite approximation of the degrees of freedom used by R’s <code>t.test</code>.</td>
</tr>
<tr class="even">
<td>Blocked</td>
<td><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>J</mi></msubsup><msup><mrow><mo stretchy="true" form="prefix">(</mo><mfrac><msub><mi>N</mi><mi>j</mi></msub><mi>N</mi></mfrac><mo stretchy="true" form="postfix">)</mo></mrow><mn>2</mn></msup><mover><mstyle mathvariant="double-struck"><mi>𝕍</mi></mstyle><mo accent="true">̂</mo></mover><mo stretchy="false" form="prefix">[</mo><mover><msub><mi>τ</mi><mi>j</mi></msub><mo accent="true">̂</mo></mover><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\sum^J_{j=1} \left(\frac{N_j}{N}\right)^2 \widehat{\mathbb{V}}[\widehat{\tau_j}]</annotation></semantics></math></td>
<td><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mo>−</mo><mn>2</mn><mo>*</mo><mi>J</mi></mrow><annotation encoding="application/x-tex">N - 2 * J</annotation></semantics></math></td>
<td>Where <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mstyle mathvariant="double-struck"><mi>𝕍</mi></mstyle><mo accent="true">̂</mo></mover><mo stretchy="false" form="prefix">[</mo><mover><msub><mi>τ</mi><mi>j</mi></msub><mo accent="true">̂</mo></mover><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\widehat{\mathbb{V}}[\widehat{\tau_j}]</annotation></semantics></math> is the variance of the estimated difference-in-means in block <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math>. See footnote 17 on page 74 of <span class="citation">(Gerber and Green <a href="#ref-gerbergreen2012" role="doc-biblioref">2012</a>)</span> for a reference. The degrees of freedom are equivalent to a regression with a full set of block specific treatment effects.</td>
</tr>
<tr class="odd">
<td>Clusters</td>
<td>Same as <code>lm_robust</code> CR2 estimator</td>
<td>Same as <code>lm_robust</code> CR2 estimator</td>
<td>This variance is the same as that recommended by <span class="citation">Gerber and Green (<a href="#ref-gerbergreen2012" role="doc-biblioref">2012</a>)</span> in equation 3.23 on page 83 when the clusters are even sizes.</td>
</tr>
<tr class="even">
<td>Blocked and clustered</td>
<td><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>J</mi></msubsup><msup><mrow><mo stretchy="true" form="prefix">(</mo><mfrac><msub><mi>N</mi><mi>j</mi></msub><mi>N</mi></mfrac><mo stretchy="true" form="postfix">)</mo></mrow><mn>2</mn></msup><mover><mstyle mathvariant="double-struck"><mi>𝕍</mi></mstyle><mo accent="true">̂</mo></mover><mo stretchy="false" form="prefix">[</mo><mover><msub><mi>τ</mi><mi>j</mi></msub><mo accent="true">̂</mo></mover><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\sum^J_{j=1} \left(\frac{N_j}{N}\right)^2 \widehat{\mathbb{V}}[\widehat{\tau_j}]</annotation></semantics></math></td>
<td><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mo>−</mo><mn>2</mn><mo>*</mo><mi>J</mi></mrow><annotation encoding="application/x-tex">S - 2 * J</annotation></semantics></math></td>
<td>Where <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mstyle mathvariant="double-struck"><mi>𝕍</mi></mstyle><mo accent="true">̂</mo></mover><mo stretchy="false" form="prefix">[</mo><mover><msub><mi>τ</mi><mi>j</mi></msub><mo accent="true">̂</mo></mover><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\widehat{\mathbb{V}}[\widehat{\tau_j}]</annotation></semantics></math> is the variance of the estimated difference-in-means in block <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math> and S is the number of clusters. See footnote 17 on page 74 of <span class="citation">Gerber and Green (<a href="#ref-gerbergreen2012" role="doc-biblioref">2012</a>)</span> for a reference. The degrees of freedom are equivalent to a regression on data collapsed by cluster with a full set of block specific treatment effects.</td>
</tr>
<tr class="odd">
<td>Matched pairs</td>
<td><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mrow><mi>J</mi><mo stretchy="false" form="prefix">(</mo><mi>J</mi><mo>−</mo><mn>1</mn><mo stretchy="false" form="postfix">)</mo></mrow></mfrac><msubsup><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>J</mi></msubsup><msup><mrow><mo stretchy="true" form="prefix">(</mo><mover><msub><mi>τ</mi><mi>j</mi></msub><mo accent="true">̂</mo></mover><mo>−</mo><mover><mi>τ</mi><mo accent="true">̂</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">\frac{1}{J(J-1)} \sum^J_{j=1} \left(\widehat{\tau_j} - \widehat{\tau}\right)^2</annotation></semantics></math></td>
<td><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">J - 1</annotation></semantics></math></td>
<td>See equation 3.16 on page 77 of <span class="citation">Gerber and Green (<a href="#ref-gerbergreen2012" role="doc-biblioref">2012</a>)</span> for a reference.</td>
</tr>
<tr class="even">
<td>Matched pair cluster randomized</td>
<td><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mi>J</mi><mrow><mo stretchy="false" form="prefix">(</mo><mi>J</mi><mo>−</mo><mn>1</mn><mo stretchy="false" form="postfix">)</mo><msup><mi>N</mi><mn>2</mn></msup></mrow></mfrac><msubsup><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>J</mi></msubsup><msup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>N</mi><mi>j</mi></msub><mover><msub><mi>τ</mi><mi>j</mi></msub><mo accent="true">̂</mo></mover><mo>−</mo><mfrac><mrow><mi>N</mi><mover><mi>τ</mi><mo accent="true">̂</mo></mover></mrow><mi>J</mi></mfrac><mo stretchy="true" form="postfix">)</mo></mrow><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">\frac{J}{(J-1)N^2} \sum^J_{j=1} \left(N_j \widehat{\tau_j} - \frac{N \widehat{\tau}}{J}\right)^2</annotation></semantics></math></td>
<td><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">J - 1</annotation></semantics></math></td>
<td>See the variance for the SATE defined in equation 6 on page 36 of <span class="citation">(Imai, King, and Nall <a href="#ref-imaietal2009" role="doc-biblioref">2009</a>)</span> and the suggested degrees of freedom on page 37.</td>
</tr>
</tbody>
</table>
</div>
<div class="section level4">
<h4 id="confidence-intervals-and-hypothesis-testing-2">Confidence intervals and hypothesis testing<a class="anchor" aria-label="anchor" href="#confidence-intervals-and-hypothesis-testing-2"></a>
</h4>
<p>We build confidence intervals using the user specified <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math> as:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mstyle mathvariant="normal"><mi>C</mi><mi>I</mi></mstyle><mrow><mn>1</mn><mo>−</mo><mi>α</mi></mrow></msup><mo>=</mo><mrow><mo stretchy="true" form="prefix">(</mo><mover><mi>τ</mi><mo accent="true">̂</mo></mover><mo>+</mo><msubsup><mi>t</mi><mrow><mi>α</mi><mi>/</mi><mn>2</mn></mrow><mrow><mi>d</mi><mi>f</mi></mrow></msubsup><msqrt><mrow><mover><mstyle mathvariant="double-struck"><mi>𝕍</mi></mstyle><mo accent="true">̂</mo></mover><mo stretchy="false" form="prefix">[</mo><mover><mi>τ</mi><mo accent="true">̂</mo></mover><mo stretchy="false" form="postfix">]</mo></mrow></msqrt><mo>,</mo><mover><mi>τ</mi><mo accent="true">̂</mo></mover><mo stretchy="false" form="postfix">]</mo><mo>+</mo><msubsup><mi>t</mi><mrow><mn>1</mn><mo>−</mo><mi>α</mi><mi>/</mi><mn>2</mn></mrow><mrow><mi>d</mi><mi>f</mi></mrow></msubsup><msqrt><mrow><mover><mstyle mathvariant="double-struck"><mi>𝕍</mi></mstyle><mo accent="true">̂</mo></mover><mo stretchy="false" form="prefix">[</mo><mover><mi>τ</mi><mo accent="true">̂</mo></mover><mo stretchy="false" form="postfix">]</mo></mrow></msqrt><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">
\mathrm{CI}^{1-\alpha} = \left(\widehat{\tau} + t^{df}_{\alpha/2} \sqrt{\widehat{\mathbb{V}}[\widehat{\tau}]},\widehat{\tau}] + t^{df}_{1 - \alpha/2} \sqrt{\widehat{\mathbb{V}}[\widehat{\tau}]}\right)
</annotation></semantics></math></p>
<p>We also provide two-sided p-values using a t-distribution with the aforementioned significance level <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math> and degrees of freedom <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><mi>f</mi></mrow><annotation encoding="application/x-tex">df</annotation></semantics></math>.</p>
</div>
</div>
<div class="section level3">
<h3 id="horvitz_thompson-notes">
<code>horvitz_thompson</code> notes<a class="anchor" aria-label="anchor" href="#horvitz_thompson-notes"></a>
</h3>
<p>We provide Horvitz-Thompson estimators for two-armed trials and can be used to estimate unbiased treatment effects when the randomization is known. Horvitz-Thompson estimators require information about the probability each unit is in treatment and control, as well as the joint probability each unit is in the treatment, in the control, and in opposite treatment conditions.</p>
<p>The estimator we implement here, <code><a href="../reference/horvitz_thompson.html">horvitz_thompson()</a></code>, can be told the design of an experiment in several ways, and the reference page is a good place to see some of those examples. Users can see a description of the estimator and its properties in <span class="citation">Aronow and Middleton (<a href="#ref-aronowmiddleton2013" role="doc-biblioref">2013</a>)</span>, <span class="citation">Middleton and Aronow (<a href="#ref-middletonaronow2015" role="doc-biblioref">2015</a>)</span>, and <span class="citation">Aronow and Samii (<a href="#ref-aronowsamii2017" role="doc-biblioref">2017</a>)</span>.</p>
<p>Some definitions used below:</p>
<ul>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>π</mi><mrow><mi>z</mi><mi>i</mi></mrow></msub><annotation encoding="application/x-tex">\pi_{zi}</annotation></semantics></math> is the marginal probability of being in condition <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi><mo>∈</mo><mo stretchy="false" form="prefix">{</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="false" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">z \in \{0, 1\}</annotation></semantics></math> for unit i</li>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>π</mi><mrow><mi>z</mi><mi>i</mi><mi>w</mi><mi>j</mi></mrow></msub><annotation encoding="application/x-tex">\pi_{ziwj}</annotation></semantics></math> is the joint probability of unit <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math> being in condition <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>z</mi><annotation encoding="application/x-tex">z</annotation></semantics></math> and unit <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math> being in condition <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>w</mi><mo>∈</mo><mo stretchy="false" form="prefix">{</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="false" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">w \in \{0, 1\}</annotation></semantics></math>
</li>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>ϵ</mi><mrow><mi>z</mi><mi>i</mi><mi>w</mi><mi>j</mi></mrow></msub><annotation encoding="application/x-tex">\epsilon_{ziwj}</annotation></semantics></math> is the indicator function <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathvariant="double-struck"><mn>1</mn></mstyle><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>π</mi><mrow><mi>z</mi><mi>i</mi><mi>w</mi><mi>j</mi></mrow></msub><mo>=</mo><mn>0</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathbb{1}\left(\pi_{ziwj} = 0\right)</annotation></semantics></math>
</li>
</ul>
<div class="section level4">
<h4 id="estimates-1">Estimates<a class="anchor" aria-label="anchor" href="#estimates-1"></a>
</h4>
<p><strong>Simple, complete, clustered</strong></p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mi>τ</mi><mo accent="true">̂</mo></mover><mo>=</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><msub><mi>z</mi><mi>i</mi></msub><mfrac><msub><mi>y</mi><mi>i</mi></msub><msub><mi>π</mi><mrow><mn>1</mn><mi>i</mi></mrow></msub></mfrac><mo>−</mo><mo stretchy="false" form="prefix">(</mo><mn>1</mn><mo>−</mo><msub><mi>z</mi><mi>i</mi></msub><mo stretchy="false" form="postfix">)</mo><mfrac><msub><mi>y</mi><mi>i</mi></msub><msub><mi>π</mi><mrow><mn>0</mn><mi>i</mi></mrow></msub></mfrac></mrow><annotation encoding="application/x-tex">
\widehat{\tau} = \frac{1}{N} \sum^N_{i=1} z_i \frac{y_i}{\pi_{1i}} - (1 - z_i) \frac{y_i}{\pi_{0i}}
</annotation></semantics></math></p>
<p><strong>Blocked</strong></p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mi>τ</mi><mo accent="true">̂</mo></mover><mo>=</mo><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>J</mi></munderover><mfrac><msub><mi>N</mi><mi>j</mi></msub><mi>N</mi></mfrac><mover><msub><mi>τ</mi><mi>j</mi></msub><mo accent="true">̂</mo></mover></mrow><annotation encoding="application/x-tex">
\widehat{\tau} = \sum^J_{j=1} \frac{N_j}{N} \widehat{\tau_j}
</annotation></semantics></math> where <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>J</mi><annotation encoding="application/x-tex">J</annotation></semantics></math> is the number of blocks, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>N</mi><mi>j</mi></msub><annotation encoding="application/x-tex">N_j</annotation></semantics></math> is the size of those blocks, and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><msub><mi>τ</mi><mi>j</mi></msub><mo accent="true">̂</mo></mover><annotation encoding="application/x-tex">\widehat{\tau_j}</annotation></semantics></math> is the Horvitz-Thompson estimate in block <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math>.</p>
</div>
<div class="section level4">
<h4 id="variance-2">Variance<a class="anchor" aria-label="anchor" href="#variance-2"></a>
</h4>
<p>Currently we provide variance estimates that rely on two separate assumptions:</p>
<ul>
<li>
<code>"youngs"</code> which implements a conservative variance estimate using Young’s inequality, described in equation 35 on page 147 of <span class="citation">Aronow and Middleton (<a href="#ref-aronowmiddleton2013" role="doc-biblioref">2013</a>)</span> and in <span class="citation">Aronow and Samii (<a href="#ref-aronowsamii2017" role="doc-biblioref">2017</a>)</span> on pages 11-15.</li>
<li>
<code>"constant"</code> which assumes constant treatment effects across all units but is less conservative. We only provide this estimator for simple randomized experiments.</li>
</ul>
<p><strong>Young’s inequality</strong></p>
<p>For designs that that are not clustered we use the following variance:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right"><msub><mover><mstyle mathvariant="double-struck"><mi>𝕍</mi></mstyle><mo accent="true">̂</mo></mover><mi>Y</mi></msub><mo stretchy="false" form="prefix">[</mo><mover><mi>τ</mi><mo accent="true">̂</mo></mover><mo stretchy="false" form="postfix">]</mo><mo>=</mo><mfrac><mn>1</mn><msup><mi>N</mi><mn>2</mn></msup></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mo minsize="3.0" maxsize="3.0" stretchy="false" form="prefix">[</mo></mtd><mtd columnalign="left"><msub><mi>z</mi><mi>i</mi></msub><msup><mrow><mo stretchy="true" form="prefix">(</mo><mfrac><msub><mi>y</mi><mi>i</mi></msub><msub><mi>π</mi><mrow><mn>1</mn><mi>i</mi></mrow></msub></mfrac><mo stretchy="true" form="postfix">)</mo></mrow><mn>2</mn></msup><mo>+</mo><mo stretchy="false" form="prefix">(</mo><mn>1</mn><mo>−</mo><msub><mi>z</mi><mi>i</mi></msub><mo stretchy="false" form="postfix">)</mo><msup><mrow><mo stretchy="true" form="prefix">(</mo><mfrac><msub><mi>y</mi><mi>i</mi></msub><msub><mi>π</mi><mrow><mn>0</mn><mi>i</mi></mrow></msub></mfrac><mo stretchy="true" form="postfix">)</mo></mrow><mn>2</mn></msup><mo>+</mo><munder><mo>∑</mo><mrow><mi>j</mi><mo>≠</mo><mi>i</mi></mrow></munder><mo minsize="2.4" maxsize="2.4" stretchy="false" form="prefix">(</mo><mfrac><mrow><msub><mi>z</mi><mi>i</mi></msub><msub><mi>z</mi><mi>j</mi></msub></mrow><mrow><msub><mi>π</mi><mrow><mn>1</mn><mi>i</mi><mn>1</mn><mi>j</mi></mrow></msub><mo>+</mo><msub><mi>ϵ</mi><mrow><mn>1</mn><mi>i</mi><mn>1</mn><mi>j</mi></mrow></msub></mrow></mfrac><mo stretchy="false" form="prefix">(</mo><msub><mi>π</mi><mrow><mn>1</mn><mi>i</mi><mn>1</mn><mi>j</mi></mrow></msub><mo>−</mo><msub><mi>π</mi><mrow><mn>1</mn><mi>i</mi></mrow></msub><msub><mi>π</mi><mrow><mn>1</mn><mi>j</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mfrac><msub><mi>y</mi><mi>i</mi></msub><msub><mi>π</mi><mrow><mn>1</mn><mi>i</mi></mrow></msub></mfrac><mfrac><msub><mi>y</mi><mi>j</mi></msub><msub><mi>π</mi><mrow><mn>1</mn><mi>j</mi></mrow></msub></mfrac></mtd></mtr><mtr><mtd columnalign="right"></mtd></mtr><mtr><mtd columnalign="right"></mtd></mtr><mtr><mtd columnalign="right"></mtd><mtd columnalign="left"><mo>+</mo><mfrac><mrow><mo stretchy="false" form="prefix">(</mo><mn>1</mn><mo>−</mo><msub><mi>z</mi><mi>i</mi></msub><mo stretchy="false" form="postfix">)</mo><mo stretchy="false" form="prefix">(</mo><mn>1</mn><mo>−</mo><msub><mi>z</mi><mi>j</mi></msub><mo stretchy="false" form="postfix">)</mo></mrow><mrow><msub><mi>π</mi><mrow><mn>0</mn><mi>i</mi><mn>0</mn><mi>j</mi></mrow></msub><mo>+</mo><msub><mi>ϵ</mi><mrow><mn>0</mn><mi>i</mi><mn>0</mn><mi>j</mi></mrow></msub></mrow></mfrac><mo stretchy="false" form="prefix">(</mo><msub><mi>π</mi><mrow><mn>0</mn><mi>i</mi><mn>0</mn><mi>j</mi></mrow></msub><mo>−</mo><msub><mi>π</mi><mrow><mn>0</mn><mi>i</mi></mrow></msub><msub><mi>π</mi><mrow><mn>0</mn><mi>j</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mfrac><msub><mi>y</mi><mi>i</mi></msub><msub><mi>π</mi><mrow><mn>0</mn><mi>i</mi></mrow></msub></mfrac><mfrac><msub><mi>y</mi><mi>j</mi></msub><msub><mi>π</mi><mrow><mn>0</mn><mi>j</mi></mrow></msub></mfrac><mo>−</mo><mn>2</mn><mfrac><mrow><msub><mi>z</mi><mi>i</mi></msub><mo stretchy="false" form="prefix">(</mo><mn>1</mn><mo>−</mo><msub><mi>z</mi><mi>j</mi></msub><mo stretchy="false" form="postfix">)</mo></mrow><mrow><msub><mi>π</mi><mrow><mn>1</mn><mi>i</mi><mn>0</mn><mi>j</mi></mrow></msub><mo>+</mo><msub><mi>ϵ</mi><mrow><mn>1</mn><mi>i</mi><mn>0</mn><mi>j</mi></mrow></msub></mrow></mfrac><mo stretchy="false" form="prefix">(</mo><msub><mi>π</mi><mrow><mn>1</mn><mi>i</mi><mn>0</mn><mi>j</mi></mrow></msub><mo>−</mo><msub><mi>π</mi><mrow><mn>1</mn><mi>i</mi></mrow></msub><msub><mi>π</mi><mrow><mn>0</mn><mi>j</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mfrac><msub><mi>y</mi><mi>i</mi></msub><msub><mi>π</mi><mrow><mn>1</mn><mi>i</mi></mrow></msub></mfrac><mfrac><msub><mi>y</mi><mi>j</mi></msub><msub><mi>π</mi><mrow><mn>0</mn><mi>j</mi></mrow></msub></mfrac></mtd></mtr><mtr><mtd columnalign="right"></mtd></mtr><mtr><mtd columnalign="right"></mtd></mtr><mtr><mtd columnalign="right"></mtd><mtd columnalign="left"><mo>+</mo><munder><mo>∑</mo><mrow><mo>∀</mo><mi>j</mi><mo>:</mo><msub><mi>π</mi><mrow><mn>1</mn><mi>i</mi><mn>1</mn><mi>j</mi></mrow></msub><mo>=</mo><mn>0</mn></mrow></munder><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>z</mi><mi>i</mi></msub><mfrac><msubsup><mi>y</mi><mi>i</mi><mn>2</mn></msubsup><mrow><mn>2</mn><msub><mi>π</mi><mrow><mn>1</mn><mi>i</mi></mrow></msub></mrow></mfrac><mo>+</mo><msub><mi>z</mi><mi>j</mi></msub><mfrac><msubsup><mi>y</mi><mi>j</mi><mn>2</mn></msubsup><msub><mi>π</mi><mrow><mn>1</mn><mi>j</mi></mrow></msub></mfrac><mo stretchy="true" form="postfix">)</mo></mrow><mo>+</mo><munder><mo>∑</mo><mrow><mo>∀</mo><mi>j</mi><mo>:</mo><msub><mi>π</mi><mrow><mn>0</mn><mi>i</mi><mn>0</mn><mi>j</mi></mrow></msub><mo>=</mo><mn>0</mn></mrow></munder><mrow><mo stretchy="true" form="prefix">(</mo><mo stretchy="false" form="prefix">(</mo><mn>1</mn><mo>−</mo><msub><mi>z</mi><mi>i</mi></msub><mo stretchy="false" form="postfix">)</mo><mfrac><msubsup><mi>y</mi><mi>i</mi><mn>2</mn></msubsup><mrow><mn>2</mn><msub><mi>π</mi><mrow><mn>0</mn><mi>i</mi></mrow></msub></mrow></mfrac><mo>+</mo><mo stretchy="false" form="prefix">(</mo><mn>1</mn><mo>−</mo><msub><mi>z</mi><mi>j</mi></msub><mo stretchy="false" form="postfix">)</mo><mfrac><msubsup><mi>y</mi><mi>j</mi><mn>2</mn></msubsup><msub><mi>π</mi><mrow><mn>0</mn><mi>j</mi></mrow></msub></mfrac><mo stretchy="true" form="postfix">)</mo></mrow><mo minsize="3.0" maxsize="3.0" stretchy="false" form="postfix">]</mo></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
  \widehat{\mathbb{V}}_{Y}[\widehat{\tau}] = \frac{1}{N^2} \sum^N_{i=1} \Bigg[&amp; z_i \left(\frac{y_i}{\pi_{1i}}\right)^2 + (1 - z_i) \left(\frac{y_i}{\pi_{0i}}\right)^2 + \sum_{j \neq i} \bigg(\frac{z_i z_j}{\pi_{1i1j} + \epsilon_{1i1j}}(\pi_{1i1j} - \pi_{1i}\pi_{1j})\frac{y_i}{\pi_{1i}}\frac{y_j}{\pi_{1j}} \\\\\\
  &amp; + \frac{(1-z_i) (1-z_j)}{\pi_{0i0j} + \epsilon_{0i0j}}(\pi_{0i0j} - \pi_{0i}\pi_{0j})\frac{y_i}{\pi_{0i}}\frac{y_j}{\pi_{0j}} - 2 \frac{z_i (1-z_j)}{\pi_{1i0j} + \epsilon_{1i0j}}(\pi_{1i0j} - \pi_{1i}\pi_{0j})\frac{y_i}{\pi_{1i}}\frac{y_j}{\pi_{0j}} \\\\\\
  &amp; + \sum_{\forall j \colon \pi_{1i1j} = 0} \left( z_i \frac{y^2_i}{2\pi_{1i}} + z_j \frac{y^2_j}{\pi_{1j}}\right) + \sum_{\forall j \colon \pi_{0i0j} = 0} \left( (1-z_i) \frac{y^2_i}{2\pi_{0i}} + (1-z_j) \frac{y^2_j}{\pi_{0j}}\right)
  \Bigg]
\end{aligned}
</annotation></semantics></math></p>
<p>There are some simplifications of the above for simpler designs that follow algebraically from the above. For example, if there are no two units for which the joint probability of being in either condition is 0, which is the case for most experiments that are not matched-pair experiments, then we get:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right"><msub><mover><mstyle mathvariant="double-struck"><mi>𝕍</mi></mstyle><mo accent="true">̂</mo></mover><mi>Y</mi></msub><mo stretchy="false" form="prefix">[</mo><mover><mi>τ</mi><mo accent="true">̂</mo></mover><mo stretchy="false" form="postfix">]</mo><mo>=</mo><mfrac><mn>1</mn><msup><mi>N</mi><mn>2</mn></msup></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mo minsize="3.0" maxsize="3.0" stretchy="false" form="prefix">[</mo></mtd><mtd columnalign="left"><msub><mi>z</mi><mi>i</mi></msub><msup><mrow><mo stretchy="true" form="prefix">(</mo><mfrac><msub><mi>y</mi><mi>i</mi></msub><msub><mi>π</mi><mrow><mn>1</mn><mi>i</mi></mrow></msub></mfrac><mo stretchy="true" form="postfix">)</mo></mrow><mn>2</mn></msup><mo>+</mo><mo stretchy="false" form="prefix">(</mo><mn>1</mn><mo>−</mo><msub><mi>z</mi><mi>i</mi></msub><mo stretchy="false" form="postfix">)</mo><msup><mrow><mo stretchy="true" form="prefix">(</mo><mfrac><msub><mi>y</mi><mi>i</mi></msub><msub><mi>π</mi><mrow><mn>0</mn><mi>i</mi></mrow></msub></mfrac><mo stretchy="true" form="postfix">)</mo></mrow><mn>2</mn></msup><mo>+</mo><munder><mo>∑</mo><mrow><mi>j</mi><mo>≠</mo><mi>i</mi></mrow></munder><mo minsize="2.4" maxsize="2.4" stretchy="false" form="prefix">(</mo><mfrac><mrow><msub><mi>z</mi><mi>i</mi></msub><msub><mi>z</mi><mi>j</mi></msub></mrow><msub><mi>π</mi><mrow><mn>1</mn><mi>i</mi><mn>1</mn><mi>j</mi></mrow></msub></mfrac><mo stretchy="false" form="prefix">(</mo><msub><mi>π</mi><mrow><mn>1</mn><mi>i</mi><mn>1</mn><mi>j</mi></mrow></msub><mo>−</mo><msub><mi>π</mi><mrow><mn>1</mn><mi>i</mi></mrow></msub><msub><mi>π</mi><mrow><mn>1</mn><mi>j</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mfrac><msub><mi>y</mi><mi>i</mi></msub><msub><mi>π</mi><mrow><mn>1</mn><mi>i</mi></mrow></msub></mfrac><mfrac><msub><mi>y</mi><mi>j</mi></msub><msub><mi>π</mi><mrow><mn>1</mn><mi>j</mi></mrow></msub></mfrac></mtd></mtr><mtr><mtd columnalign="right"></mtd></mtr><mtr><mtd columnalign="right"></mtd></mtr><mtr><mtd columnalign="right"></mtd><mtd columnalign="left"><mo>+</mo><mfrac><mrow><mo stretchy="false" form="prefix">(</mo><mn>1</mn><mo>−</mo><msub><mi>z</mi><mi>i</mi></msub><mo stretchy="false" form="postfix">)</mo><mo stretchy="false" form="prefix">(</mo><mn>1</mn><mo>−</mo><msub><mi>z</mi><mi>j</mi></msub><mo stretchy="false" form="postfix">)</mo></mrow><msub><mi>π</mi><mrow><mn>0</mn><mi>i</mi><mn>0</mn><mi>j</mi></mrow></msub></mfrac><mo stretchy="false" form="prefix">(</mo><msub><mi>π</mi><mrow><mn>0</mn><mi>i</mi><mn>0</mn><mi>j</mi></mrow></msub><mo>−</mo><msub><mi>π</mi><mrow><mn>0</mn><mi>i</mi></mrow></msub><msub><mi>π</mi><mrow><mn>0</mn><mi>j</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mfrac><msub><mi>y</mi><mi>i</mi></msub><msub><mi>π</mi><mrow><mn>0</mn><mi>i</mi></mrow></msub></mfrac><mfrac><msub><mi>y</mi><mi>j</mi></msub><msub><mi>π</mi><mrow><mn>0</mn><mi>j</mi></mrow></msub></mfrac><mo>−</mo><mn>2</mn><mfrac><mrow><msub><mi>z</mi><mi>i</mi></msub><mo stretchy="false" form="prefix">(</mo><mn>1</mn><mo>−</mo><msub><mi>z</mi><mi>j</mi></msub><mo stretchy="false" form="postfix">)</mo></mrow><msub><mi>π</mi><mrow><mn>1</mn><mi>i</mi><mn>0</mn><mi>j</mi></mrow></msub></mfrac><mo stretchy="false" form="prefix">(</mo><msub><mi>π</mi><mrow><mn>1</mn><mi>i</mi><mn>0</mn><mi>j</mi></mrow></msub><mo>−</mo><msub><mi>π</mi><mrow><mn>1</mn><mi>i</mi></mrow></msub><msub><mi>π</mi><mrow><mn>0</mn><mi>j</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mfrac><msub><mi>y</mi><mi>i</mi></msub><msub><mi>π</mi><mrow><mn>1</mn><mi>i</mi></mrow></msub></mfrac><mfrac><msub><mi>y</mi><mi>j</mi></msub><msub><mi>π</mi><mrow><mn>0</mn><mi>j</mi></mrow></msub></mfrac><mo minsize="3.0" maxsize="3.0" stretchy="false" form="postfix">]</mo></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
  \widehat{\mathbb{V}}_{Y}[\widehat{\tau}] = \frac{1}{N^2} \sum^N_{i=1} \Bigg[&amp; z_i \left(\frac{y_i}{\pi_{1i}}\right)^2 + (1 - z_i) \left(\frac{y_i}{\pi_{0i}}\right)^2 + \sum_{j \neq i} \bigg(\frac{z_i z_j}{\pi_{1i1j}}(\pi_{1i1j} - \pi_{1i}\pi_{1j})\frac{y_i}{\pi_{1i}}\frac{y_j}{\pi_{1j}} \\\\\\
  &amp; + \frac{(1-z_i) (1-z_j)}{\pi_{0i0j}}(\pi_{0i0j} - \pi_{0i}\pi_{0j})\frac{y_i}{\pi_{0i}}\frac{y_j}{\pi_{0j}} - 2 \frac{z_i (1-z_j)}{\pi_{1i0j}}(\pi_{1i0j} - \pi_{1i}\pi_{0j})\frac{y_i}{\pi_{1i}}\frac{y_j}{\pi_{0j}}
  \Bigg]
\end{aligned}
</annotation></semantics></math></p>
<p>If we further simplify to the case where there is simple random assignment, and there is absolutely no dependence among units (i.e., <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>π</mi><mrow><mi>z</mi><mi>i</mi><mi>w</mi><mi>j</mi></mrow></msub><mo>=</mo><msub><mi>π</mi><mrow><mi>z</mi><mi>i</mi></mrow></msub><msub><mi>π</mi><mrow><mi>w</mi><mi>j</mi></mrow></msub><mspace width="0.278em"></mspace><mspace width="0.278em"></mspace><mo>∀</mo><mspace width="0.278em"></mspace><mspace width="0.278em"></mspace><mi>z</mi><mo>,</mo><mi>w</mi><mo>,</mo><mi>i</mi><mo>,</mo><mi>j</mi></mrow><annotation encoding="application/x-tex">\pi_{ziwj} = \pi_{zi}\pi_{wj} \;\;\forall\;\;z,w,i,j</annotation></semantics></math>), we get:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right"><msub><mover><mstyle mathvariant="double-struck"><mi>𝕍</mi></mstyle><mo accent="true">̂</mo></mover><mi>Y</mi></msub><mo stretchy="false" form="prefix">[</mo><mover><mi>τ</mi><mo accent="true">̂</mo></mover><mo stretchy="false" form="postfix">]</mo><mo>=</mo><mfrac><mn>1</mn><msup><mi>N</mi><mn>2</mn></msup></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mo minsize="3.0" maxsize="3.0" stretchy="false" form="prefix">[</mo></mtd><mtd columnalign="left"><msub><mi>z</mi><mi>i</mi></msub><msup><mrow><mo stretchy="true" form="prefix">(</mo><mfrac><msub><mi>y</mi><mi>i</mi></msub><msub><mi>π</mi><mrow><mn>1</mn><mi>i</mi></mrow></msub></mfrac><mo stretchy="true" form="postfix">)</mo></mrow><mn>2</mn></msup><mo>+</mo><mo stretchy="false" form="prefix">(</mo><mn>1</mn><mo>−</mo><msub><mi>z</mi><mi>i</mi></msub><mo stretchy="false" form="postfix">)</mo><msup><mrow><mo stretchy="true" form="prefix">(</mo><mfrac><msub><mi>y</mi><mi>i</mi></msub><msub><mi>π</mi><mrow><mn>0</mn><mi>i</mi></mrow></msub></mfrac><mo stretchy="true" form="postfix">)</mo></mrow><mn>2</mn></msup><mo minsize="3.0" maxsize="3.0" stretchy="false" form="postfix">]</mo></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
  \widehat{\mathbb{V}}_{Y}[\widehat{\tau}] = \frac{1}{N^2} \sum^N_{i=1} \Bigg[&amp; z_i \left(\frac{y_i}{\pi_{1i}}\right)^2 + (1 - z_i) \left(\frac{y_i}{\pi_{0i}}\right)^2\Bigg]
\end{aligned}
</annotation></semantics></math></p>
<p><strong>Clustered designs</strong></p>
<p>For clustered designs, we use the following collapsed estimator by setting <code>collapsed = TRUE</code>. Here, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math> is the total number of clusters, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mi>k</mi></msub><annotation encoding="application/x-tex">y_k</annotation></semantics></math> is the total of the outcomes <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mi>i</mi></msub><annotation encoding="application/x-tex">y_i</annotation></semantics></math> for all <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math> units in cluster <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>π</mi><mi>z</mi></msub><mi>k</mi></mrow><annotation encoding="application/x-tex">\pi_zk</annotation></semantics></math> is the marginal probability of cluster <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math> being in condition <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi><mo>∈</mo><mo stretchy="false" form="prefix">{</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="false" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">z \in \{0, 1\}</annotation></semantics></math>, and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>z</mi><mi>k</mi></msub><annotation encoding="application/x-tex">z_k</annotation></semantics></math> and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>π</mi><mrow><mi>z</mi><mi>k</mi><mi>w</mi><mi>l</mi></mrow></msub><annotation encoding="application/x-tex">\pi_{zkwl}</annotation></semantics></math> are defined analogously. Warning! If one passes <code>condition_pr_mat</code> to <code>horvitz_thompson</code> for a clustered design, but not <code>clusters</code>, the function will not use the collapsed estimator the the variance estimate will be inaccurate.</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right"><msub><mover><mstyle mathvariant="double-struck"><mi>𝕍</mi></mstyle><mo accent="true">̂</mo></mover><mi>Y</mi></msub><mo stretchy="false" form="prefix">[</mo><mover><mi>τ</mi><mo accent="true">̂</mo></mover><mo stretchy="false" form="postfix">]</mo><mo>=</mo><mfrac><mn>1</mn><msup><mi>N</mi><mn>2</mn></msup></mfrac><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>M</mi></munderover><mo minsize="3.0" maxsize="3.0" stretchy="false" form="prefix">[</mo></mtd><mtd columnalign="left"><msub><mi>z</mi><mi>k</mi></msub><msup><mrow><mo stretchy="true" form="prefix">(</mo><mfrac><msub><mi>y</mi><mi>k</mi></msub><msub><mi>π</mi><mrow><mn>1</mn><mi>k</mi></mrow></msub></mfrac><mo stretchy="true" form="postfix">)</mo></mrow><mn>2</mn></msup><mo>+</mo><mo stretchy="false" form="prefix">(</mo><mn>1</mn><mo>−</mo><msub><mi>z</mi><mi>k</mi></msub><mo stretchy="false" form="postfix">)</mo><msup><mrow><mo stretchy="true" form="prefix">(</mo><mfrac><msub><mi>y</mi><mi>k</mi></msub><msub><mi>π</mi><mrow><mn>0</mn><mi>k</mi></mrow></msub></mfrac><mo stretchy="true" form="postfix">)</mo></mrow><mn>2</mn></msup><mo>+</mo><munder><mo>∑</mo><mrow><mi>l</mi><mo>≠</mo><mi>k</mi></mrow></munder><mo minsize="2.4" maxsize="2.4" stretchy="false" form="prefix">(</mo><mfrac><mrow><msub><mi>z</mi><mi>k</mi></msub><msub><mi>z</mi><mi>l</mi></msub></mrow><mrow><msub><mi>π</mi><mrow><mn>1</mn><mi>k</mi><mn>1</mn><mi>l</mi></mrow></msub><mo>+</mo><msub><mi>ϵ</mi><mrow><mn>1</mn><mi>k</mi><mn>1</mn><mi>l</mi></mrow></msub></mrow></mfrac><mo stretchy="false" form="prefix">(</mo><msub><mi>π</mi><mrow><mn>1</mn><mi>k</mi><mn>1</mn><mi>l</mi></mrow></msub><mo>−</mo><msub><mi>π</mi><mrow><mn>1</mn><mi>k</mi></mrow></msub><msub><mi>π</mi><mrow><mn>1</mn><mi>l</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mfrac><msub><mi>y</mi><mi>k</mi></msub><msub><mi>π</mi><mrow><mn>1</mn><mi>k</mi></mrow></msub></mfrac><mfrac><msub><mi>y</mi><mi>l</mi></msub><msub><mi>π</mi><mrow><mn>1</mn><mi>l</mi></mrow></msub></mfrac></mtd></mtr><mtr><mtd columnalign="right"></mtd></mtr><mtr><mtd columnalign="right"></mtd></mtr><mtr><mtd columnalign="right"></mtd><mtd columnalign="left"><mo>+</mo><mfrac><mrow><mo stretchy="false" form="prefix">(</mo><mn>1</mn><mo>−</mo><msub><mi>z</mi><mi>k</mi></msub><mo stretchy="false" form="postfix">)</mo><mo stretchy="false" form="prefix">(</mo><mn>1</mn><mo>−</mo><msub><mi>z</mi><mi>l</mi></msub><mo stretchy="false" form="postfix">)</mo></mrow><mrow><msub><mi>π</mi><mrow><mn>0</mn><mi>k</mi><mn>0</mn><mi>l</mi></mrow></msub><mo>+</mo><msub><mi>ϵ</mi><mrow><mn>0</mn><mi>k</mi><mn>0</mn><mi>l</mi></mrow></msub></mrow></mfrac><mo stretchy="false" form="prefix">(</mo><msub><mi>π</mi><mrow><mn>0</mn><mi>k</mi><mn>0</mn><mi>l</mi></mrow></msub><mo>−</mo><msub><mi>π</mi><mrow><mn>0</mn><mi>k</mi></mrow></msub><msub><mi>π</mi><mrow><mn>0</mn><mi>l</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mfrac><msub><mi>y</mi><mi>k</mi></msub><msub><mi>π</mi><mrow><mn>0</mn><mi>k</mi></mrow></msub></mfrac><mfrac><msub><mi>y</mi><mi>l</mi></msub><msub><mi>π</mi><mrow><mn>0</mn><mi>l</mi></mrow></msub></mfrac><mo>−</mo><mn>2</mn><mfrac><mrow><msub><mi>z</mi><mi>k</mi></msub><mo stretchy="false" form="prefix">(</mo><mn>1</mn><mo>−</mo><msub><mi>z</mi><mi>l</mi></msub><mo stretchy="false" form="postfix">)</mo></mrow><mrow><msub><mi>π</mi><mrow><mn>1</mn><mi>k</mi><mn>0</mn><mi>l</mi></mrow></msub><mo>+</mo><msub><mi>ϵ</mi><mrow><mn>1</mn><mi>k</mi><mn>0</mn><mi>l</mi></mrow></msub></mrow></mfrac><mo stretchy="false" form="prefix">(</mo><msub><mi>π</mi><mrow><mn>1</mn><mi>k</mi><mn>0</mn><mi>l</mi></mrow></msub><mo>−</mo><msub><mi>π</mi><mrow><mn>1</mn><mi>k</mi></mrow></msub><msub><mi>π</mi><mrow><mn>0</mn><mi>l</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mfrac><msub><mi>y</mi><mi>k</mi></msub><msub><mi>π</mi><mrow><mn>1</mn><mi>k</mi></mrow></msub></mfrac><mfrac><msub><mi>y</mi><mi>l</mi></msub><msub><mi>π</mi><mrow><mn>0</mn><mi>l</mi></mrow></msub></mfrac></mtd></mtr><mtr><mtd columnalign="right"></mtd></mtr><mtr><mtd columnalign="right"></mtd></mtr><mtr><mtd columnalign="right"></mtd><mtd columnalign="left"><mo>+</mo><munder><mo>∑</mo><mrow><mo>∀</mo><mi>l</mi><mo>:</mo><msub><mi>π</mi><mrow><mn>1</mn><mi>k</mi><mn>1</mn><mi>l</mi></mrow></msub><mo>=</mo><mn>0</mn></mrow></munder><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>z</mi><mi>k</mi></msub><mfrac><msubsup><mi>y</mi><mi>k</mi><mn>2</mn></msubsup><mrow><mn>2</mn><msub><mi>π</mi><mrow><mn>1</mn><mi>k</mi></mrow></msub></mrow></mfrac><mo>+</mo><msub><mi>z</mi><mi>l</mi></msub><mfrac><msubsup><mi>y</mi><mi>l</mi><mn>2</mn></msubsup><msub><mi>π</mi><mrow><mn>1</mn><mi>l</mi></mrow></msub></mfrac><mo stretchy="true" form="postfix">)</mo></mrow><mo>+</mo><munder><mo>∑</mo><mrow><mo>∀</mo><mi>l</mi><mo>:</mo><msub><mi>π</mi><mrow><mn>0</mn><mi>k</mi><mn>0</mn><mi>l</mi></mrow></msub><mo>=</mo><mn>0</mn></mrow></munder><mrow><mo stretchy="true" form="prefix">(</mo><mo stretchy="false" form="prefix">(</mo><mn>1</mn><mo>−</mo><msub><mi>z</mi><mi>k</mi></msub><mo stretchy="false" form="postfix">)</mo><mfrac><msubsup><mi>y</mi><mi>k</mi><mn>2</mn></msubsup><mrow><mn>2</mn><msub><mi>π</mi><mrow><mn>0</mn><mi>k</mi></mrow></msub></mrow></mfrac><mo>+</mo><mo stretchy="false" form="prefix">(</mo><mn>1</mn><mo>−</mo><msub><mi>z</mi><mi>l</mi></msub><mo stretchy="false" form="postfix">)</mo><mfrac><msubsup><mi>y</mi><mi>l</mi><mn>2</mn></msubsup><msub><mi>π</mi><mrow><mn>0</mn><mi>l</mi></mrow></msub></mfrac><mo stretchy="true" form="postfix">)</mo></mrow><mo minsize="3.0" maxsize="3.0" stretchy="false" form="postfix">]</mo></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
  \widehat{\mathbb{V}}_{Y}[\widehat{\tau}] = \frac{1}{N^2} \sum^M_{k=1} \Bigg[&amp; z_k \left(\frac{y_k}{\pi_{1k}}\right)^2 + (1 - z_k) \left(\frac{y_k}{\pi_{0k}}\right)^2 + \sum_{l \neq k} \bigg(\frac{z_k z_l}{\pi_{1k1l} + \epsilon_{1k1l}}(\pi_{1k1l} - \pi_{1k}\pi_{1l})\frac{y_k}{\pi_{1k}}\frac{y_l}{\pi_{1l}} \\\\\\
  &amp; + \frac{(1-z_k) (1-z_l)}{\pi_{0k0l} + \epsilon_{0k0l}}(\pi_{0k0l} - \pi_{0k}\pi_{0l})\frac{y_k}{\pi_{0k}}\frac{y_l}{\pi_{0l}} - 2 \frac{z_k (1-z_l)}{\pi_{1k0l} + \epsilon_{1k0l}}(\pi_{1k0l} - \pi_{1k}\pi_{0l})\frac{y_k}{\pi_{1k}}\frac{y_l}{\pi_{0l}} \\\\\\
  &amp; + \sum_{\forall l \colon \pi_{1k1l} = 0} \left( z_k \frac{y^2_k}{2\pi_{1k}} + z_l \frac{y^2_l}{\pi_{1l}}\right) + \sum_{\forall l \colon \pi_{0k0l} = 0} \left( (1-z_k) \frac{y^2_k}{2\pi_{0k}} + (1-z_l) \frac{y^2_l}{\pi_{0l}}\right)
  \Bigg]
\end{aligned}
</annotation></semantics></math></p>
<p><strong>Constant effects</strong></p>
<p>Alternatively, one can assume constant treatment effects and, under that assumption, estimate the variance that is consistent under that assumption but less conservative. Again, this estimator is only implemented for the simple randomized case.</p>
<ul>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mrow><mi>z</mi><mi>i</mi></mrow></msub><annotation encoding="application/x-tex">y_{zi}</annotation></semantics></math> is the potential outcome for condition <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>z</mi><annotation encoding="application/x-tex">z</annotation></semantics></math> for unit <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>. This is either observed if <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>i</mi></msub><mo>=</mo><mi>z</mi></mrow><annotation encoding="application/x-tex">z_i = z</annotation></semantics></math> or estimated using the constant effects assumption if <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>i</mi></msub><mo>≠</mo><mi>z</mi></mrow><annotation encoding="application/x-tex">z_i \neq z</annotation></semantics></math>, where <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>z</mi><mi>i</mi></msub><annotation encoding="application/x-tex">z_i</annotation></semantics></math> is the condition for unit <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>. To be precise <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mrow><mn>1</mn><mi>i</mi></mrow></msub><mo>=</mo><msub><mi>z</mi><mi>i</mi></msub><msub><mi>y</mi><mi>i</mi></msub><mo>+</mo><mo stretchy="false" form="prefix">(</mo><mn>1</mn><mo>−</mo><msub><mi>z</mi><mi>i</mi></msub><mo stretchy="false" form="postfix">)</mo><mo stretchy="false" form="prefix">(</mo><msub><mi>y</mi><mi>i</mi></msub><mo>+</mo><mover><mi>τ</mi><mo accent="true">̂</mo></mover><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">y_{1i} = z_i y_{i} + (1 - z_i) (y_{i} + \widehat{\tau})</annotation></semantics></math> and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mrow><mn>0</mn><mi>i</mi></mrow></msub><mo>=</mo><msub><mi>z</mi><mi>i</mi></msub><mo stretchy="false" form="prefix">(</mo><msub><mi>y</mi><mi>i</mi></msub><mo>−</mo><mover><mi>τ</mi><mo accent="true">̂</mo></mover><mo stretchy="false" form="postfix">)</mo><mo>+</mo><mo stretchy="false" form="prefix">(</mo><mn>1</mn><mo>−</mo><msub><mi>z</mi><mi>i</mi></msub><mo stretchy="false" form="postfix">)</mo><msub><mi>y</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">y_{0i} = z_i (y_{i} - \widehat{\tau}) + (1 - z_i) y_{i}</annotation></semantics></math>, where <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>τ</mi><mo accent="true">̂</mo></mover><annotation encoding="application/x-tex">\widehat{\tau}</annotation></semantics></math> is the estimated treatment effect.</li>
</ul>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right"><msub><mover><mstyle mathvariant="double-struck"><mi>𝕍</mi></mstyle><mo accent="true">̂</mo></mover><mi>C</mi></msub><mo stretchy="false" form="prefix">[</mo><mover><mi>τ</mi><mo accent="true">̂</mo></mover><mo stretchy="false" form="postfix">]</mo><mo>=</mo><mfrac><mn>1</mn><msup><mi>N</mi><mn>2</mn></msup></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mo minsize="3.0" maxsize="3.0" stretchy="false" form="prefix">[</mo></mtd><mtd columnalign="left"><mo stretchy="false" form="prefix">(</mo><mn>1</mn><mo>−</mo><msub><mi>π</mi><mrow><mn>0</mn><mi>i</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><msub><mi>π</mi><mrow><mn>0</mn><mi>i</mi></mrow></msub><msup><mrow><mo stretchy="true" form="prefix">(</mo><mfrac><msub><mi>y</mi><mrow><mn>0</mn><mi>i</mi></mrow></msub><msub><mi>π</mi><mrow><mn>0</mn><mi>i</mi></mrow></msub></mfrac><mo stretchy="true" form="postfix">)</mo></mrow><mn>2</mn></msup><mo>+</mo><mo stretchy="false" form="prefix">(</mo><mn>1</mn><mo>−</mo><msub><mi>π</mi><mrow><mn>1</mn><mi>i</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><msub><mi>π</mi><mrow><mn>1</mn><mi>i</mi></mrow></msub><msup><mrow><mo stretchy="true" form="prefix">(</mo><mfrac><msub><mi>y</mi><mrow><mn>1</mn><mi>i</mi></mrow></msub><msub><mi>π</mi><mrow><mn>1</mn><mi>i</mi></mrow></msub></mfrac><mo stretchy="true" form="postfix">)</mo></mrow><mn>2</mn></msup><mo>−</mo><mn>2</mn><msub><mi>y</mi><mrow><mn>1</mn><mi>i</mi></mrow></msub><msub><mi>y</mi><mrow><mn>0</mn><mi>i</mi></mrow></msub></mtd></mtr><mtr><mtd columnalign="right"></mtd></mtr><mtr><mtd columnalign="right"></mtd></mtr><mtr><mtd columnalign="right"></mtd><mtd columnalign="left"><mo>+</mo><munder><mo>∑</mo><mrow><mi>j</mi><mo>≠</mo><mi>i</mi></mrow></munder><mo minsize="1.8" maxsize="1.8" stretchy="false" form="prefix">(</mo><mo stretchy="false" form="prefix">(</mo><msub><mi>π</mi><mrow><mn>0</mn><mi>i</mi><mn>0</mn><mi>j</mi></mrow></msub><mo>−</mo><msub><mi>π</mi><mrow><mn>0</mn><mi>i</mi></mrow></msub><msub><mi>π</mi><mrow><mn>0</mn><mi>j</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mfrac><msub><mi>y</mi><mrow><mn>0</mn><mi>i</mi></mrow></msub><msub><mi>π</mi><mrow><mn>0</mn><mi>i</mi></mrow></msub></mfrac><mfrac><msub><mi>y</mi><mrow><mn>0</mn><mi>j</mi></mrow></msub><msub><mi>π</mi><mrow><mn>0</mn><mi>j</mi></mrow></msub></mfrac><mo>+</mo><mo stretchy="false" form="prefix">(</mo><msub><mi>π</mi><mrow><mn>1</mn><mi>i</mi><mn>1</mn><mi>j</mi></mrow></msub><mo>−</mo><msub><mi>π</mi><mrow><mn>1</mn><mi>i</mi></mrow></msub><msub><mi>π</mi><mrow><mn>1</mn><mi>j</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mfrac><msub><mi>y</mi><mrow><mn>1</mn><mi>i</mi></mrow></msub><msub><mi>π</mi><mrow><mn>1</mn><mi>i</mi></mrow></msub></mfrac><mfrac><msub><mi>y</mi><mrow><mn>1</mn><mi>j</mi></mrow></msub><msub><mi>π</mi><mrow><mn>1</mn><mi>j</mi></mrow></msub></mfrac></mtd></mtr><mtr><mtd columnalign="right"></mtd></mtr><mtr><mtd columnalign="right"></mtd></mtr><mtr><mtd columnalign="right"></mtd><mtd columnalign="left"><mo>−</mo><mn>2</mn><mo stretchy="false" form="prefix">(</mo><msub><mi>π</mi><mrow><mn>1</mn><mi>i</mi><mn>0</mn><mi>j</mi></mrow></msub><mo>−</mo><msub><mi>π</mi><mrow><mn>1</mn><mi>i</mi></mrow></msub><msub><mi>π</mi><mrow><mn>0</mn><mi>j</mi></mrow></msub><mo stretchy="false" form="postfix">)</mo><mfrac><msub><mi>y</mi><mrow><mn>1</mn><mi>i</mi></mrow></msub><msub><mi>π</mi><mrow><mn>1</mn><mi>i</mi></mrow></msub></mfrac><mfrac><msub><mi>y</mi><mrow><mn>0</mn><mi>j</mi></mrow></msub><msub><mi>π</mi><mrow><mn>0</mn><mi>j</mi></mrow></msub></mfrac><mo minsize="1.8" maxsize="1.8" stretchy="false" form="postfix">)</mo><mo minsize="3.0" maxsize="3.0" stretchy="false" form="postfix">]</mo></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
    \widehat{\mathbb{V}}_{C}[\widehat{\tau}] = \frac{1}{N^2} \sum^N_{i=1} \Bigg[&amp; (1 - \pi_{0i}) \pi_{0i} \left(\frac{y_{0i}}{\pi_{0i}}\right)^2 + (1 - \pi_{1i}) \pi_{1i} \left(\frac{y_{1i}}{\pi_{1i}}\right)^2 - 2 y_{1i} y_{0i} \\\\\\
    &amp; + \sum_{j \neq i} \Big( (\pi_{0i0j} - \pi_{0i} \pi_{0j}) \frac{y_{0i}}{\pi_{0i}} \frac{y_{0j}}{\pi_{0j}} + (\pi_{1i1j} - \pi_{1i} \pi_{1j}) \frac{y_{1i}}{\pi_{1i}} \frac{y_{1j}}{\pi_{1j}} \\\\\\
    &amp;- 2 (\pi_{1i0j} - \pi_{1i} \pi_{0j}) \frac{y_{1i}}{\pi_{1i}} \frac{y_{0j}}{\pi_{0j}}
  \Big)\Bigg]
\end{aligned}
</annotation></semantics></math></p>
</div>
<div class="section level4">
<h4 id="confidence-intervals-and-hypothesis-testing-3">Confidence intervals and hypothesis testing<a class="anchor" aria-label="anchor" href="#confidence-intervals-and-hypothesis-testing-3"></a>
</h4>
<p>Theory on hypothesis testing with the Horvitz-Thompson estimator is yet to be developed. We rely on a normal approximation and construct confidence intervals in the following way: <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mstyle mathvariant="normal"><mi>C</mi><mi>I</mi></mstyle><mrow><mn>1</mn><mo>−</mo><mi>α</mi></mrow></msup><mo>=</mo><mrow><mo stretchy="true" form="prefix">(</mo><mover><mi>τ</mi><mo accent="true">̂</mo></mover><mo>+</mo><msub><mi>z</mi><mrow><mi>α</mi><mi>/</mi><mn>2</mn></mrow></msub><msqrt><mrow><mover><mstyle mathvariant="double-struck"><mi>𝕍</mi></mstyle><mo accent="true">̂</mo></mover><mo stretchy="false" form="prefix">[</mo><mover><mi>τ</mi><mo accent="true">̂</mo></mover><mo stretchy="false" form="postfix">]</mo></mrow></msqrt><mo>,</mo><mover><mi>τ</mi><mo accent="true">̂</mo></mover><mo>+</mo><msub><mi>z</mi><mrow><mn>1</mn><mo>−</mo><mi>α</mi><mi>/</mi><mn>2</mn></mrow></msub><msqrt><mrow><mover><mstyle mathvariant="double-struck"><mi>𝕍</mi></mstyle><mo accent="true">̂</mo></mover><mo stretchy="false" form="prefix">[</mo><mover><mi>τ</mi><mo accent="true">̂</mo></mover><mo stretchy="false" form="postfix">]</mo></mrow></msqrt><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">
\mathrm{CI}^{1-\alpha} = \left(\widehat{\tau} + z_{\alpha/2} \sqrt{\widehat{\mathbb{V}}[\widehat{\tau}]}, \widehat{\tau} + z_{1 - \alpha/2} \sqrt{\widehat{\mathbb{V}}[\widehat{\tau}]}\right)
</annotation></semantics></math></p>
<p>The associated p-values for a two-sided null hypothesis test are computed using a normal distribution and the aforementioned significance level <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>.</p>
</div>
</div>
</div>
<div class="section level2">
<h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references">
<div id="ref-abadieetal2017">
<p>Abadie, Alberto, Susan Athey, Guido W Imbens, and Jeffrey Wooldridge. 2017. “A Class of Unbiased Estimators of the Average Treatment Effect in Randomized Experiments.” <em>arXiv Pre-Print</em>. <a href="https://arxiv.org/abs/1710.02926v2" class="external-link">https://arxiv.org/abs/1710.02926v2</a>.</p>
</div>
<div id="ref-aronowmiddleton2013">
<p>Aronow, Peter M, and Joel A Middleton. 2013. “A Class of Unbiased Estimators of the Average Treatment Effect in Randomized Experiments.” <em>Journal of Causal Inference</em> 1 (1): 135–54. <a href="https://doi.org/10.1515/jci-2012-0009" class="external-link">https://doi.org/10.1515/jci-2012-0009</a>.</p>
</div>
<div id="ref-aronowsamii2017">
<p>Aronow, Peter M, and Cyrus Samii. 2017. “Estimating Average Causal Effects Under Interference Between Units.” <em>Annals of Applied Statistics</em>, forthcoming. <a href="https://arxiv.org/abs/1305.6156v3" class="external-link">https://arxiv.org/abs/1305.6156v3</a>.</p>
</div>
<div id="ref-bellmccaffrey2002">
<p>Bell, Robert M, and Daniel F McCaffrey. 2002. “Bias Reduction in Standard Errors for Linear Regression with Multi-Stage Samples.” <em>Survey Methodology</em> 28 (2): 169–82.</p>
</div>
<div id="ref-freedman2008">
<p>Freedman, David A. 2008. “On Regression Adjustments in Experiments with Several Treatments.” <em>The Annals of Applied Statistics</em>, 176–96. <a href="https://doi.org/10.1214/07-AOAS143" class="external-link">https://doi.org/10.1214/07-AOAS143</a>.</p>
</div>
<div id="ref-gerbergreen2012">
<p>Gerber, Alan S, and Donald P Green. 2012. <em>Field Experiments: Design, Analysis, and Interpretation</em>. New York: W.W. Norton.</p>
</div>
<div id="ref-imaietal2009">
<p>Imai, Kosuke, Gary King, and Clayton Nall. 2009. “The Essential Role of Pair Matching in Cluster-Randomized Experiments, with Application to the Mexican Universal Health Insurance Evaluation.” <em>Statistical Science</em> 24 (1): 29–53. <a href="https://doi.org/10.1214/08-STS274" class="external-link">https://doi.org/10.1214/08-STS274</a>.</p>
</div>
<div id="ref-imbenskolesar2016">
<p>Imbens, Guido W, and Michal Kolesar. 2016. “Robust Standard Errors in Small Samples: Some Practical Advice.” <em>Review of Economics and Statistics</em> 98 (4): 701–12. <a href="https://doi.org/10.1162/REST_a_00552" class="external-link">https://doi.org/10.1162/REST_a_00552</a>.</p>
</div>
<div id="ref-lin2013">
<p>Lin, Winston. 2013. “Agnostic Notes on Regression Adjustments to Experimental Data: Reexamining Freedman’s Critique.” <em>The Annals of Applied Statistics</em> 7 (1): 295–318. <a href="https://doi.org/10.1214/12-AOAS583" class="external-link">https://doi.org/10.1214/12-AOAS583</a>.</p>
</div>
<div id="ref-mackinnonwhite1985">
<p>MacKinnon, James, and Halbert White. 1985. “Some Heteroskedasticity-Consistent Covariance Matrix Estimators with Improved Finite Sample Properties.” <em>Journal of Econometrics</em> 29 (3): 305–25. <a href="https://doi.org/10.1016/0304-4076(85)90158-7" class="external-link">https://doi.org/10.1016/0304-4076(85)90158-7</a>.</p>
</div>
<div id="ref-middletonaronow2015">
<p>Middleton, Joel A, and Peter M Aronow. 2015. “Unbiased Estimation of the Average Treatment Effect in Cluster-Randomized Experiments.” <em>Statistics, Politics and Policy</em> 6 (1-2): 39–75. <a href="https://doi.org/10.1515/spp-2013-0002" class="external-link">https://doi.org/10.1515/spp-2013-0002</a>.</p>
</div>
<div id="ref-pustejovskytipton2016">
<p>Pustejovsky, James E, and Elizabeth Tipton. 2018. “Small-Sample Methods for Cluster-Robust Variance Estimation and Hypothesis Testing in Fixed Effects Models.” <em>Journal of Business &amp; Economic Statistics</em> 36 (4). <a href="https://doi.org/10.1080/07350015.2016.1247004" class="external-link">https://doi.org/10.1080/07350015.2016.1247004</a>.</p>
</div>
<div id="ref-romanowolf2017">
<p>Romano, Joseph P, and Michael Wolf. 2017. “Resurrecting Weighted Least Squares.” <em>Journal of Econometrics</em> 197 (1): 1–19. <a href="https://doi.org/10.1016/j.jeconom.2016.10.003" class="external-link">https://doi.org/10.1016/j.jeconom.2016.10.003</a>.</p>
</div>
<div id="ref-samiiaronow2012">
<p>Samii, Cyrus, and Peter M Aronow. 2012. “On Equivalencies Between Design-Based and Regression-Based Variance Estimators for Randomized Experiments.” <em>Statistics and Probability Letters</em> 82 (2). <a href="https://doi.org/10.1016/j.spl.2011.10.024" class="external-link">https://doi.org/10.1016/j.spl.2011.10.024</a>.</p>
</div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Graeme Blair, Jasper Cooper, Alexander Coppock, Macartan Humphreys, Luke Sonnet.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

    </footer>
</div>





  </body>
</html>
