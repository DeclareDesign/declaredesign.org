<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Simulations - OLS and Variance • estimatr</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Simulations - OLS and Variance">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">estimatr</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="Released version">1.0.4</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../articles/getting-started.html">Getting started</a></li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/getting-started.html">Getting started using estimatr</a></li>
    <li><a class="dropdown-item" href="../articles/absorbing-fixed-effects.html">Absorbing Fixed Effects with estimatr</a></li>
    <li><a class="dropdown-item" href="../articles/estimatr-in-the-tidyverse.html">estimatr in the Tidyverse</a></li>
    <li><a class="dropdown-item" href="../articles/benchmarking-estimatr.html">Benchmarking estimatr</a></li>
    <li><a class="dropdown-item" href="../articles/emmeans-examples.html">Examples with emmeans</a></li>
    <li><a class="dropdown-item" href="../articles/mathematical-notes.html">Mathematical notes for estimatr</a></li>
    <li><a class="dropdown-item" href="../articles/regression-tables.html">Regression Tables with estimatr</a></li>
    <li><a class="dropdown-item" href="../articles/simulations-debiasing-dim.html">Simulations - Debiasing Difference-in-Means</a></li>
    <li><a class="dropdown-item" href="../articles/simulations-ols-variance.html">Simulations - OLS and Variance</a></li>
    <li><a class="dropdown-item" href="../articles/stata-wls-hat.html">How Stata's hat matrix differs with weights</a></li>
  </ul>
</li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-software" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Software</button>
  <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="dropdown-software">
<li><a class="external-link dropdown-item" href="http://declaredesign.org/r/declaredesign/">DeclareDesign</a></li>
    <li><a class="external-link dropdown-item" href="https://declaredesign.org/r/randomizr/">randomizr</a></li>
    <li><a class="external-link dropdown-item" href="https://declaredesign.org/r/fabricatr/">fabricatr</a></li>
    <li><a class="dropdown-item" href="https://declaredesign.org/r/estimatr/">estimatr</a></li>
    <li><a class="external-link dropdown-item" href="https://declaredesign.org/r/designlibrary/">DesignLibrary</a></li>
    <li><a class="external-link dropdown-item" href="https://eos.wzb.eu/ipi/DDWizard/">DesignWizard</a></li>
  </ul>
</li>
<li class="nav-item"><a class="external-link nav-link" href="https://declaredesign.org">declaredesign.org</a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">



<script src="simulations-ols-variance_files/accessible-code-block-0.0.1/empty-anchor.js"></script><div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Simulations - OLS and Variance</h1>
                        <h4 data-toc-skip class="author">Luke Sonnet</h4>
            
      
      <small class="dont-index">Source: <a href="https://github.com/DeclareDesign/estimatr/blob/main/vignettes/simulations-ols-variance.Rmd" class="external-link"><code>vignettes/simulations-ols-variance.Rmd</code></a></small>
      <div class="d-none name"><code>simulations-ols-variance.Rmd</code></div>
    </div>

    
    
<p>This document exposes the properties of different variance estimators using <a href="/r/declaredesign/"><code>DeclareDesign</code></a> and <a href="/r/estimatr/"><code>estimatr</code></a>. More details about the variance estimators with references can be found in the <a href="/r/estimatr/articles/mathematical-notes.html">mathematical notes</a>.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://declaredesign.org/r/declaredesign/" class="external-link">DeclareDesign</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyverse.tidyverse.org" class="external-link">tidyverse</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://yihui.org/knitr/" class="external-link">knitr</a></span><span class="op">)</span></span></code></pre></div>
<div class="section level2">
<h2 id="homoskedastic-errors">Homoskedastic errors<a class="anchor" aria-label="anchor" href="#homoskedastic-errors"></a>
</h2>
<p>Under simple conditions with homoskedasticity (i.e., all errors are drawn from a distribution with the same variance), the classical estimator of the variance of OLS should be unbiased. In this section I demonstrate this to be true using <a href="/r/declaredesign/"><code>DeclareDesign</code></a> and <a href="/r/estimatr/"><code>estimatr</code></a>.</p>
<p>First, let’s take a simple set up:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right"><mstyle mathvariant="bold"><mi>𝐲</mi></mstyle></mtd><mtd columnalign="left"><mo>=</mo><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mi>β</mi><mo>+</mo><mi>ϵ</mi><mo>,</mo></mtd></mtr><mtr><mtd columnalign="right"><msub><mi>ϵ</mi><mi>i</mi></msub></mtd><mtd columnalign="left"><mover><mo>∼</mo><mrow><mi>i</mi><mi>.</mi><mi>i</mi><mi>.</mi><mi>d</mi><mi>.</mi></mrow></mover><mi>N</mi><mo stretchy="false" form="prefix">(</mo><mn>0</mn><mo>,</mo><msup><mi>σ</mi><mn>2</mn></msup><mo stretchy="false" form="postfix">)</mo><mi>.</mi></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
\mathbf{y} &amp;= \mathbf{X}\beta + \epsilon, \\
\epsilon_i &amp;\overset{i.i.d.}{\sim} N(0, \sigma^2).
\end{aligned}
</annotation></semantics></math></p>
<p>For our simulation, let’s have a constant and one covariate, so that <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mo>=</mo><mo stretchy="false" form="prefix">[</mo><mstyle mathvariant="bold"><mn>1</mn></mstyle><mo>,</mo><mstyle mathvariant="bold"><msub><mi>𝐱</mi><mn>1</mn></msub></mstyle><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathbf{X} = [\mathbf{1}, \mathbf{x_1}]</annotation></semantics></math>, where <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mstyle mathvariant="bold"><msub><mi>𝐱</mi><mn>1</mn></msub></mstyle><annotation encoding="application/x-tex">\mathbf{x_1}</annotation></semantics></math> is a column vector of a covariate drawn from a standard normal distribution. Let’s also assume that are covariates are fixed, rather than stochastic. Let’s draw the data we will use.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">41</span><span class="op">)</span></span>
<span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="fl">50</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>The function</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ϵ</mi><mi>i</mi></msub><mover><mo>∼</mo><mrow><mi>i</mi><mi>.</mi><mi>i</mi><mi>.</mi><mi>d</mi><mi>.</mi></mrow></mover><mi>N</mi><mo stretchy="false" form="prefix">(</mo><mn>0</mn><mo>,</mo><msup><mi>σ</mi><mn>2</mn></msup><mo stretchy="false" form="postfix">)</mo><mo>,</mo></mrow><annotation encoding="application/x-tex">
\epsilon_i \overset{i.i.d.}{\sim} N(0, \sigma^2),
</annotation></semantics></math> encodes the assumption of homoskedasticity. Because of these homoskedastic errors, we know that the true variance of the coefficients with fixed covariates is</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathvariant="double-struck"><mi>𝕍</mi></mstyle><mo stretchy="false" form="prefix">[</mo><mover><mi>β</mi><mo accent="true">̂</mo></mover><mo stretchy="false" form="postfix">]</mo><mo>=</mo><msup><mi>σ</mi><mn>2</mn></msup><mo stretchy="false" form="prefix">(</mo><msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mi>⊤</mi></msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><msup><mo stretchy="false" form="postfix">)</mo><mrow><mo>−</mo><mn>1</mn></mrow></msup><mo>,</mo></mrow><annotation encoding="application/x-tex">
\mathbb{V}[\widehat{\beta}] = \sigma^2 (\mathbf{X}^\top \mathbf{X})^{-1},
</annotation></semantics></math></p>
<p>where I hide conditioning on <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><annotation encoding="application/x-tex">\mathbf{X}</annotation></semantics></math> for simplicity.</p>
<p>Let’s compute the true variance for our dataset.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">sigmasq</span> <span class="op">&lt;-</span> <span class="fl">4</span></span>
<span><span class="co"># Build the X matrix with intercept</span></span>
<span><span class="va">Xmat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="fl">1</span>, <span class="va">dat</span><span class="op">$</span><span class="va">x</span><span class="op">)</span></span>
<span><span class="co"># Invert XtX</span></span>
<span><span class="va">XtX_inv</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/solve.html" class="external-link">solve</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/crossprod.html" class="external-link">crossprod</a></span><span class="op">(</span><span class="va">Xmat</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co"># Get full variance covariance matrix</span></span>
<span><span class="va">true_var_cov_mat</span> <span class="op">&lt;-</span> <span class="va">sigmasq</span> <span class="op">*</span> <span class="va">XtX_inv</span></span></code></pre></div>
<p>But for this example, we are only going to focus on the variance for the covariate, not the intercept, so let’s store that variance.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">true_varb</span> <span class="op">&lt;-</span> <span class="va">true_var_cov_mat</span><span class="op">[</span><span class="fl">2</span>, <span class="fl">2</span><span class="op">]</span></span>
<span><span class="va">true_varb</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 0.07831866</span></span></code></pre>
<p>Now, using <a href="/r/declaredesign/"><code>DeclareDesign</code></a>, let’s specify the rest of the data generating process (DGP). Let’s set <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi><mo>=</mo><mo stretchy="false" form="prefix">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><msup><mo stretchy="false" form="postfix">]</mo><mi>⊤</mi></msup></mrow><annotation encoding="application/x-tex">\beta = [0, 1]^\top</annotation></semantics></math>, so that the true DGP is <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathvariant="bold"><mi>𝐲</mi></mstyle><mo>=</mo><mstyle mathvariant="bold"><msub><mi>𝐱</mi><mn>1</mn></msub></mstyle><mo>+</mo><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">\mathbf{y} = \mathbf{x_1} + \epsilon</annotation></semantics></math>.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">simp_pop</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://declaredesign.org/r/declaredesign/reference/declare_model.html" class="external-link">declare_model</a></span><span class="op">(</span></span>
<span>  epsilon <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">N</span>, sd <span class="op">=</span> <span class="fl">2</span><span class="op">)</span>,</span>
<span>  y <span class="op">=</span> <span class="va">x</span> <span class="op">+</span> <span class="va">epsilon</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>Now let’s tell DeclareDesign that our target, our estimand, is the true variance.</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">varb_estimand</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://declaredesign.org/r/declaredesign/reference/declare_inquiry.html" class="external-link">declare_inquiry</a></span><span class="op">(</span>true_varb <span class="op">=</span> <span class="va">true_varb</span><span class="op">)</span></span></code></pre></div>
<p>Our estimator for this estimand will be the classical OLS variance estimator, which we know should be unbiased:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mrow><mstyle mathvariant="double-struck"><mi>𝕍</mi></mstyle><mo stretchy="false" form="prefix">[</mo><mover><mi>β</mi><mo accent="true">̂</mo></mover><mo stretchy="false" form="postfix">]</mo></mrow><mo accent="true">̂</mo></mover><mo>=</mo><mfrac><mrow><msup><mstyle mathvariant="bold"><mi>𝐞</mi></mstyle><mi>⊤</mi></msup><mstyle mathvariant="bold"><mi>𝐞</mi></mstyle></mrow><mrow><mi>N</mi><mo>−</mo><mi>K</mi></mrow></mfrac><mo stretchy="false" form="prefix">(</mo><msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mi>⊤</mi></msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><msup><mo stretchy="false" form="postfix">)</mo><mrow><mo>−</mo><mn>1</mn></mrow></msup><mo>,</mo></mrow><annotation encoding="application/x-tex">
\widehat{\mathbb{V}[\widehat{\beta}]} = \frac{\mathbf{e}^\top\mathbf{e}}{N - K} (\mathbf{X}^\top \mathbf{X})^{-1},
</annotation></semantics></math></p>
<p>where the residuals <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathvariant="bold"><mi>𝐞</mi></mstyle><mo>=</mo><mstyle mathvariant="bold"><mi>𝐲</mi></mstyle><mo>−</mo><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mover><mi>β</mi><mo accent="true">̂</mo></mover></mrow><annotation encoding="application/x-tex">\mathbf{e} = \mathbf{y} - \mathbf{X}\widehat{\beta}</annotation></semantics></math>, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics></math> is the number of observations, and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>K</mi><annotation encoding="application/x-tex">K</annotation></semantics></math> is the number of regressors—two in our case. We can easily get this estimate of the variance by squaring the standard error we get out from <code>lm_robust</code> in <a href="/r/estimatr/"><code>estimatr</code></a>. Let’s tell <a href="/r/declaredesign/"><code>DeclareDesign</code></a> to use that estimator and get the coefficient on the <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mstyle mathvariant="bold"><mi>𝐱</mi></mstyle><mn>1</mn></msub><annotation encoding="application/x-tex">\mathbf{x}_1</annotation></semantics></math> variable.</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">lmc</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://declaredesign.org/r/declaredesign/reference/declare_estimator.html" class="external-link">declare_estimator</a></span><span class="op">(</span></span>
<span>  <span class="va">y</span> <span class="op">~</span> <span class="va">x</span>,</span>
<span>  model <span class="op">=</span> <span class="va">lm_robust</span>,</span>
<span>  se_type <span class="op">=</span> <span class="st">"classical"</span>,</span>
<span>  inquiry <span class="op">=</span> <span class="va">varb_estimand</span>,</span>
<span>  term <span class="op">=</span> <span class="st">"x"</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>Now, we want to test for a few results using Monte Carlo simulation. Our main goal is to show that our estimated variance is unbiased for the true variance (our estimand). We can do this by comparing the mean of our estimated variances across our Monto Carlo simulations to the true variance. We can also show that the standard error of our coefficient estimate is the same as the standard deviation of the sampling distribution of our coefficient. Lastly, we also measure the coverage of our 95 percent confidence intervals across simulations to test whether the they cover the true coefficient 95 percent of the time.</p>
<p>Let’s first set up the design and our diagnosands.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># First declare all the steps of our design, starting with our fixed data</span></span>
<span><span class="va">classical_design</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://declaredesign.org/r/declaredesign/reference/declare_model.html" class="external-link">declare_model</a></span><span class="op">(</span><span class="va">dat</span><span class="op">)</span> <span class="op">+</span> <span class="va">simp_pop</span> <span class="op">+</span> <span class="va">varb_estimand</span> <span class="op">+</span> <span class="va">lmc</span></span>
<span></span>
<span><span class="co"># Declare a set of diagnosands that help us check if</span></span>
<span><span class="co"># we have unbiasedness</span></span>
<span><span class="va">my_diagnosands</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://declaredesign.org/r/declaredesign/reference/declare_diagnosands.html" class="external-link">declare_diagnosands</a></span><span class="op">(</span></span>
<span>  `Bias of Estimated Variance` <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">std.error</span><span class="op">^</span><span class="fl">2</span> <span class="op">-</span> <span class="va">estimand</span><span class="op">)</span>,</span>
<span>  `Bias of Standard Error` <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">std.error</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/stats/sd.html" class="external-link">sd</a></span><span class="op">(</span><span class="va">estimate</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  `Coverage Rate` <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="fl">1</span> <span class="op">&lt;=</span> <span class="va">conf.low</span> <span class="op">&amp;</span> <span class="fl">1</span> <span class="op">&gt;=</span> <span class="va">conf.high</span><span class="op">)</span>,</span>
<span>  `Mean of Estimated Variance` <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">std.error</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span>,</span>
<span>  `True Variance` <span class="op">=</span> <span class="va">estimand</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>, </span>
<span>  keep_defaults <span class="op">=</span> <span class="cn">FALSE</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>Now let’s run the simulations!</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">42</span><span class="op">)</span></span>
<span><span class="va">dx1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://declaredesign.org/r/declaredesign/reference/diagnose_design.html" class="external-link">diagnose_design</a></span><span class="op">(</span></span>
<span>  <span class="va">classical_design</span>,</span>
<span>  sims <span class="op">=</span> <span class="va">sims</span>,</span>
<span>  diagnosands <span class="op">=</span> <span class="va">my_diagnosands</span></span>
<span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/knitr/man/kable.html" class="external-link">kable</a></span><span class="op">(</span><span class="fu"><a href="https://declaredesign.org/r/declaredesign/reference/reshape_diagnosis.html" class="external-link">reshape_diagnosis</a></span><span class="op">(</span><span class="va">dx1</span>, digits <span class="op">=</span> <span class="fl">3</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>Our diagnosands can help us see if there is any bias. As we can see the bias is very close to zero. Because the standard error of the bias is much larger than the estimated bias, we can be reasonably certain that the only reason the bias is not exactly zero is due to simulation error. We can also see the unbiasedness visually, using a density plot of estimated variances with a line for the true variance.</p>
<p><img src="simulations-ols-variance_files/figure-html/unnamed-chunk-9-1.png" width="480"></p>
</div>
<div class="section level2">
<h2 id="heteroskedastic-errors">Heteroskedastic errors<a class="anchor" aria-label="anchor" href="#heteroskedastic-errors"></a>
</h2>
<p>Let’s use the same fixed data set-up, but introduce heteroskedasticity. In this case, the variance of the errors is different across units:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ϵ</mi><mi>i</mi></msub><mo>∼</mo><mi>N</mi><mo stretchy="false" form="prefix">(</mo><mn>0</mn><mo>,</mo><msubsup><mi>σ</mi><mi>i</mi><mn>2</mn></msubsup><mo stretchy="false" form="postfix">)</mo><mo>,</mo></mrow><annotation encoding="application/x-tex">
\epsilon_i \sim N(0, \sigma_i^2),
</annotation></semantics></math></p>
<p>where <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>σ</mi><mi>i</mi><mn>2</mn></msubsup><mo>≠</mo><msubsup><mi>σ</mi><mi>j</mi><mn>2</mn></msubsup></mrow><annotation encoding="application/x-tex">\sigma^2_i \neq \sigma^2_j</annotation></semantics></math> for some units <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math> and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math>. If the variance of the errors is not independent of the regressors, the “classical” variance will be biased and inconsistent. Meanwhile, heteroskedastic-consistent variance estimators, such as the HC2 estimator, are consistent and normally less biased than the “classical” estimator. Let’s demonstrate this using <a href="/r/declaredesign/"><code>DeclareDesign</code></a>. First, let’s specify the variance of the errors to be strongly correlated with <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math>.</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html" class="external-link">mutate</a></span><span class="op">(</span><span class="va">dat</span>, noise_var <span class="op">=</span> <span class="fl">1</span> <span class="op">+</span> <span class="op">(</span><span class="va">x</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">min</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span></span>
<span><span class="op">)</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="va">dat</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">noise_var</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html" class="external-link">geom_point</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">ggtitle</a></span><span class="op">(</span><span class="st">"The variance of errors increases with x"</span><span class="op">)</span></span></code></pre></div>
<p><img src="simulations-ols-variance_files/figure-html/unnamed-chunk-10-1.png" width="384"></p>
<p>Note that the general form of the true variance with fixed covariates is:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathvariant="double-struck"><mi>𝕍</mi></mstyle><mo stretchy="false" form="prefix">[</mo><mover><mi>β</mi><mo accent="true">̂</mo></mover><mo stretchy="false" form="postfix">]</mo><mo>=</mo><mo stretchy="false" form="prefix">(</mo><msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mi>⊤</mi></msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><msup><mo stretchy="false" form="postfix">)</mo><mrow><mo>−</mo><mn>1</mn></mrow></msup><msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mi>⊤</mi></msup><mstyle mathvariant="bold"><mi>𝚽</mi></mstyle><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mo stretchy="false" form="prefix">(</mo><msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><mi>⊤</mi></msup><mstyle mathvariant="bold"><mi>𝐗</mi></mstyle><msup><mo stretchy="false" form="postfix">)</mo><mrow><mo>−</mo><mn>1</mn></mrow></msup><mo>,</mo></mrow><annotation encoding="application/x-tex">
\mathbb{V}[\widehat{\beta}] = (\mathbf{X}^\top \mathbf{X})^{-1} \mathbf{X}^\top \mathbf{\Phi} \mathbf{X} (\mathbf{X}^\top \mathbf{X})^{-1},
</annotation></semantics></math></p>
<p>where <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mstyle mathvariant="bold"><mi>𝚽</mi></mstyle><annotation encoding="application/x-tex">\mathbf{\Phi}</annotation></semantics></math> is the variance covariance matrix of the errors, or <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathvariant="bold"><mi>𝚽</mi></mstyle><mo>=</mo><mstyle mathvariant="double-struck"><mi>𝔼</mi></mstyle><mo stretchy="false" form="prefix">[</mo><mi>ϵ</mi><msup><mi>ϵ</mi><mi>⊤</mi></msup><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">\mathbf{\Phi} = \mathbb{E}[\epsilon\epsilon^\top]</annotation></semantics></math>. In the above case with homoskedasticity, we assumed <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathvariant="bold"><mi>𝚽</mi></mstyle><mo>=</mo><msup><mi>σ</mi><mn>2</mn></msup><mstyle mathvariant="bold"><mi>𝐈</mi></mstyle></mrow><annotation encoding="application/x-tex">\mathbf{\Phi} = \sigma^2 \mathbf{I}</annotation></semantics></math> and were able to simplify. Now, as in the standard set up for heteroskedasticity, we set <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mstyle mathvariant="bold"><mi>𝚽</mi></mstyle><annotation encoding="application/x-tex">\mathbf{\Phi}</annotation></semantics></math> to be a diagonal matrix where <code>noise_var</code>, the variance for each unit’s error, is on the diagonal, like so:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathvariant="bold"><mi>𝚽</mi></mstyle><mo>=</mo><mrow><mo stretchy="true" form="prefix">[</mo><mtable><mtr><mtd columnalign="center"><msubsup><mi>σ</mi><mn>1</mn><mn>2</mn></msubsup></mtd><mtd columnalign="center"><mn>0</mn></mtd><mtd columnalign="center"><mi>⋯</mi></mtd><mtd columnalign="center"><mn>0</mn></mtd></mtr><mtr><mtd columnalign="center"><mn>0</mn></mtd><mtd columnalign="center"><msubsup><mi>σ</mi><mn>2</mn><mn>2</mn></msubsup></mtd><mtd columnalign="center"><mi>⋯</mi></mtd><mtd columnalign="center"><mn>0</mn></mtd></mtr><mtr><mtd columnalign="center"><mi>⋮</mi></mtd><mtd columnalign="center"><mi>⋮</mi></mtd><mtd columnalign="center"><mi>⋱</mi></mtd><mtd columnalign="center"><mi>⋮</mi></mtd></mtr><mtr><mtd columnalign="center"><mn>0</mn></mtd><mtd columnalign="center"><mn>0</mn></mtd><mtd columnalign="center"><mi>⋯</mi></mtd><mtd columnalign="center"><msubsup><mi>σ</mi><mi>n</mi><mn>2</mn></msubsup></mtd></mtr></mtable><mo stretchy="true" form="postfix">]</mo></mrow></mrow><annotation encoding="application/x-tex">
\mathbf{\Phi} = \begin{bmatrix}
\sigma_1^2 &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; \sigma_2^2 &amp; \cdots &amp; 0 \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; \sigma_n^2
\end{bmatrix}
</annotation></semantics></math></p>
<p>Using that error structure and the error for each unit, we can estimate the true variance.</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">Xmat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/with.html" class="external-link">with</a></span><span class="op">(</span><span class="va">dat</span>, <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="fl">1</span>, <span class="va">x</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">XtX_inv</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/solve.html" class="external-link">solve</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/crossprod.html" class="external-link">crossprod</a></span><span class="op">(</span><span class="va">Xmat</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">varb</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/crossprod.html" class="external-link">tcrossprod</a></span><span class="op">(</span><span class="va">XtX_inv</span>, <span class="va">Xmat</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/diag.html" class="external-link">diag</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/with.html" class="external-link">with</a></span><span class="op">(</span><span class="va">dat</span>, <span class="va">noise_var</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">Xmat</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">XtX_inv</span></span>
<span><span class="va">true_varb_het</span> <span class="op">&lt;-</span> <span class="va">varb</span><span class="op">[</span><span class="fl">2</span>, <span class="fl">2</span><span class="op">]</span></span>
<span><span class="va">true_varb_het</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 0.1473923</span></span></code></pre>
<p>Now let’s use <a href="/r/declaredesign/"><code>DeclareDesign</code></a> to test whether HC2 is less biased in this example than classical standard errors. HC2 is the <code>estimatr</code> default; we’ll also throw in HC1, which is Stata’s default robust standard error estimator. I’m going to make a “designer,” which is a function that returns a design.</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">het_designer</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">N</span><span class="op">)</span> <span class="op">{</span></span>
<span>  </span>
<span>  <span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://declaredesign.org/r/fabricatr/reference/fabricate.html" class="external-link">fabricate</a></span><span class="op">(</span>N <span class="op">=</span> <span class="va">N</span>, x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">N</span><span class="op">)</span>, noise_var <span class="op">=</span> <span class="fl">1</span> <span class="op">+</span> <span class="op">(</span><span class="va">x</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">min</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span></span>
<span></span>
<span>  <span class="co"># Get true variance for this data</span></span>
<span>  <span class="va">Xmat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/with.html" class="external-link">with</a></span><span class="op">(</span><span class="va">dat</span>, <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="fl">1</span>, <span class="va">x</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="va">XtX_inv</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/solve.html" class="external-link">solve</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/crossprod.html" class="external-link">crossprod</a></span><span class="op">(</span><span class="va">Xmat</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="va">varb</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/crossprod.html" class="external-link">tcrossprod</a></span><span class="op">(</span><span class="va">XtX_inv</span>, <span class="va">Xmat</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/diag.html" class="external-link">diag</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/with.html" class="external-link">with</a></span><span class="op">(</span><span class="va">dat</span>, <span class="va">noise_var</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">Xmat</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">XtX_inv</span></span>
<span>  <span class="va">true_varb_het</span> <span class="op">&lt;-</span> <span class="va">varb</span><span class="op">[</span><span class="fl">2</span>, <span class="fl">2</span><span class="op">]</span></span>
<span></span>
<span>  <span class="co"># Population function now has heteroskedastic noise</span></span>
<span>  <span class="va">simp_pop</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://declaredesign.org/r/declaredesign/reference/declare_model.html" class="external-link">declare_model</a></span><span class="op">(</span></span>
<span>    <span class="va">dat</span>,</span>
<span>    epsilon <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">N</span>, sd <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">sqrt</a></span><span class="op">(</span><span class="va">noise_var</span><span class="op">)</span><span class="op">)</span>,</span>
<span>    y <span class="op">=</span> <span class="va">x</span> <span class="op">+</span> <span class="va">epsilon</span></span>
<span>  <span class="op">)</span></span>
<span></span>
<span>  <span class="va">varb_het_estimand</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://declaredesign.org/r/declaredesign/reference/declare_inquiry.html" class="external-link">declare_inquiry</a></span><span class="op">(</span>true_varb_het <span class="op">=</span> <span class="va">true_varb_het</span><span class="op">)</span></span>
<span></span>
<span>  <span class="co"># Now we declare all three estimators</span></span>
<span>  <span class="va">lm1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://declaredesign.org/r/declaredesign/reference/declare_estimator.html" class="external-link">declare_estimator</a></span><span class="op">(</span></span>
<span>    <span class="va">y</span> <span class="op">~</span> <span class="va">x</span>,</span>
<span>    model <span class="op">=</span> <span class="va">lm_robust</span>,</span>
<span>    se_type <span class="op">=</span> <span class="st">"classical"</span>,</span>
<span>    inquiry <span class="op">=</span> <span class="va">varb_het_estimand</span>,</span>
<span>    term <span class="op">=</span> <span class="st">"x"</span>,</span>
<span>    label <span class="op">=</span> <span class="st">"classical"</span></span>
<span>  <span class="op">)</span></span>
<span></span>
<span>  <span class="va">lm2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://declaredesign.org/r/declaredesign/reference/declare_estimator.html" class="external-link">declare_estimator</a></span><span class="op">(</span></span>
<span>    <span class="va">y</span> <span class="op">~</span> <span class="va">x</span>,</span>
<span>    model <span class="op">=</span> <span class="va">lm_robust</span>,</span>
<span>    se_type <span class="op">=</span> <span class="st">"HC1"</span>,</span>
<span>    inquiry <span class="op">=</span> <span class="va">varb_het_estimand</span>,</span>
<span>    term <span class="op">=</span> <span class="st">"x"</span>,</span>
<span>    label <span class="op">=</span> <span class="st">"HC1"</span></span>
<span>  <span class="op">)</span></span>
<span>  </span>
<span>  <span class="va">lm3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://declaredesign.org/r/declaredesign/reference/declare_estimator.html" class="external-link">declare_estimator</a></span><span class="op">(</span></span>
<span>    <span class="va">y</span> <span class="op">~</span> <span class="va">x</span>,</span>
<span>    model <span class="op">=</span> <span class="va">lm_robust</span>,</span>
<span>    se_type <span class="op">=</span> <span class="st">"HC2"</span>,</span>
<span>    inquiry <span class="op">=</span> <span class="va">varb_het_estimand</span>,</span>
<span>    term <span class="op">=</span> <span class="st">"x"</span>,</span>
<span>    label <span class="op">=</span> <span class="st">"HC2"</span></span>
<span>  <span class="op">)</span></span>
<span>  </span>
<span></span>
<span>  <span class="co"># We return the design so we can diagnose it</span></span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="va">simp_pop</span> <span class="op">+</span> <span class="va">varb_het_estimand</span> <span class="op">+</span> <span class="va">lm1</span> <span class="op">+</span> <span class="va">lm2</span> <span class="op">+</span> <span class="va">lm3</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre></div>
<p>So let’s use the same diagnosands as above to test the properties of our estimators with heteroskedasticity.</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Create a design using our template and the data we have been using</span></span>
<span><span class="va">het_design</span> <span class="op">&lt;-</span> <span class="fu">het_designer</span><span class="op">(</span>N <span class="op">=</span> <span class="fl">50</span><span class="op">)</span></span>
<span><span class="va">dx2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://declaredesign.org/r/declaredesign/reference/diagnose_design.html" class="external-link">diagnose_design</a></span><span class="op">(</span></span>
<span>  <span class="va">het_design</span>,</span>
<span>  diagnosands <span class="op">=</span> <span class="va">my_diagnosands</span>,</span>
<span>  sims <span class="op">=</span> <span class="va">sims</span></span>
<span>  <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/knitr/man/kable.html" class="external-link">kable</a></span><span class="op">(</span><span class="fu"><a href="https://declaredesign.org/r/declaredesign/reference/reshape_diagnosis.html" class="external-link">reshape_diagnosis</a></span><span class="op">(</span><span class="va">dx2</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>The bias for the HC2 errors is much closer to zero, whereas the bias for the classical error is much larger, especially when compared to the standard error of the bias diagnosand. How does this bias change as the sample size changes? As the HC2 variance estimate is consistent under heteroskedasticity, it should converge to zero.</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">designs</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://declaredesign.org/r/declaredesign/reference/expand_design.html" class="external-link">expand_design</a></span><span class="op">(</span><span class="va">het_designer</span>, N <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">100</span>, <span class="fl">200</span>, <span class="fl">300</span>, <span class="fl">500</span>, <span class="fl">1000</span>, <span class="fl">2500</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">42</span><span class="op">)</span></span>
<span><span class="va">dx3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://declaredesign.org/r/declaredesign/reference/diagnose_design.html" class="external-link">diagnose_design</a></span><span class="op">(</span><span class="va">designs</span>, sims <span class="op">=</span> <span class="va">sims</span>, diagnosands <span class="op">=</span> <span class="va">my_diagnosands</span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="va">dx3</span><span class="op">$</span><span class="va">diagnosands_df</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">N</span>, y <span class="op">=</span> <span class="va">`Bias of Estimated Variance`</span>, color <span class="op">=</span> <span class="va">estimator</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html" class="external-link">geom_point</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html" class="external-link">geom_line</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html" class="external-link">geom_hline</a></span><span class="op">(</span>yintercept <span class="op">=</span> <span class="fl">0</span>, linetype <span class="op">=</span> <span class="fl">2</span>, color <span class="op">=</span> <span class="st">"grey"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">labs</a></span><span class="op">(</span>color <span class="op">=</span> <span class="st">"Estimator"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html" class="external-link">theme_bw</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<p><img src="simulations-ols-variance_files/figure-html/unnamed-chunk-15-1.png" width="480"></p>
<p>As you can see, the HC2 variance tends to have less bias and is consistent, converging to the true value as the sample size increases. The classical standard error estimator is neither unbiased nor consistent. The HC1 variance is also “robust” to heteroskedasiticity but exhibits greater bias than HC2 in this example.</p>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Graeme Blair, Jasper Cooper, Alexander Coppock, Macartan Humphreys, Luke Sonnet.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

    </footer>
</div>





  </body>
</html>
